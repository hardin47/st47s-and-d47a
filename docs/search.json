[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "blog",
    "section": "",
    "text": "Let’s teach them what they need to know\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2025\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s teach them what they need to know\n\n\n\n\n\nIn our data-driven world, it benefits all of us to provide training in statistics and data science for high school students. However, historical forces and momentum in the curriculum are keeping mathematics curricula focused on a calculus pinacle. I argue that it is in our national interest to help our young people become smart data consumers as they enter into a world optimized to take advantage of them.\n\n\n\n\n\nMar 1, 2025\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nLearning is humbling… and necessary for educators\n\n\n\n\n\nThrough two recent pursuits, I reflect on what it is like to be a student. When I’m in a tap dancing class that is too hard for me, I find it hard to focus on what I’m supposed to be learning. When I try to learn SQL I recognize the power of generative AI. I’ve been teaching for 22 years, and it is refreshing and humbling to be in the student role again. I recommend that all educators find a way to put themselves in the student role. It will make you a better teacher.\n\n\n\n\n\nMar 1, 2024\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nResources for JEDI-Informed Teaching of Statistics and Data Science\n\n\n\n\n\nA collaborative venture between the American Statistical Association’s JEDI Outreach Group and Section on Statistics and Data Science Education (supported by the Consortium for the Advancement of Undergraduate Statistics Education), the JEDI-CAUSE website provides resources for teaching with a mindset toward Justice, Equity, Diversity, and Inclusion.\n\n\n\n\n\nJan 1, 2024\n\n\nJennifer Ward & Jo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nCURV - connecting, uplifting, and recognizing voices\n\n\n\n\n\nCURV is a database which seeks to celebrate scholars who are traditionally under represented in statistics and data science. The scholars represent the diversity of undergraduate students; they are individuals who are working to make statistics more accessible; and their works leads to making the world a better place.\n\n\n\n\n\nAug 11, 2023\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nDear Data - Solitude\n\n\n\n\n\nContribution to “In Here: Solitude”, a project to display part of the permanent collection of the Benton Art Museum at Pomona College.\n\n\n\n\n\nJul 31, 2022\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nTeaching with The Islands\n\n\n\n\n\nOne of my favorite class activities involves the virtual world known as The Islands. Students, too, love the project.\n\n\n\n\n\nJun 2, 2022\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Modern Statistics\n\n\n\n\n\nAnnouncing Introduction to Modern Statistics by Mine Çetinkaya-Rundel and Jo Hardin\n\n\n\n\n\nJun 27, 2021\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nRelative Risk and Odds Ratios\n\n\n\n\n\nWhy relative risk should not be calculated on data sampled using a case control study.\n\n\n\n\n\nJun 10, 2021\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nKeeping busy with data science\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2020\n\n\nJo Hardin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "courses/M154-compstat/index.html",
    "href": "courses/M154-compstat/index.html",
    "title": "Math 154: Computational Statistics",
    "section": "",
    "text": "Art by @allison_horst\n\n\nComputational Statistics is an introduction to statistical methods that rely heavily on the use of computers. The course can be broadly broken down into three sections. The first section will include communicating and working with data in a modern era. We will cover data wrangling, data visualization, data ethics, and collaborative research (via GitHub). The second part of the course will focus on traditional statistical inference done through computational methods (e.g., permutation tests and bootstrapping). The last part of the course will focus on machine learning ideas such as classification, clustering, and (possibly) dimension reduction techniques. Some of the methods were invented before the ubiquitous use of personal computers, but only because the calculus used to solve the problem was relatively straightforward (or because the method wasn’t actually ever used). Many of the methods have been developed quite recently."
  },
  {
    "objectID": "courses/M154-compstat/index.html#the-course",
    "href": "courses/M154-compstat/index.html#the-course",
    "title": "Math 154: Computational Statistics",
    "section": "",
    "text": "Art by @allison_horst\n\n\nComputational Statistics is an introduction to statistical methods that rely heavily on the use of computers. The course can be broadly broken down into three sections. The first section will include communicating and working with data in a modern era. We will cover data wrangling, data visualization, data ethics, and collaborative research (via GitHub). The second part of the course will focus on traditional statistical inference done through computational methods (e.g., permutation tests and bootstrapping). The last part of the course will focus on machine learning ideas such as classification, clustering, and (possibly) dimension reduction techniques. Some of the methods were invented before the ubiquitous use of personal computers, but only because the calculus used to solve the problem was relatively straightforward (or because the method wasn’t actually ever used). Many of the methods have been developed quite recently."
  },
  {
    "objectID": "courses/M154-compstat/index.html#student-learning-outcomes.",
    "href": "courses/M154-compstat/index.html#student-learning-outcomes.",
    "title": "Math 154: Computational Statistics",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the semester, students will be able to:\n\nwork through the entire computational statistics flow chart as a data analyst.\nuse graphical representations of data to communicate ideas about the data.\nidentify, understand, and describe the uses and misuses of algorithms and data collection from an ethical lens with the purpose of preventing harms from data science.\ncritically evaluate analyses / graphics of data (typically big data or dynamic data).\ncommunicate results effectively."
  },
  {
    "objectID": "courses/M154-compstat/index.html#course-website",
    "href": "courses/M154-compstat/index.html#course-website",
    "title": "Math 154: Computational Statistics",
    "section": "Course website",
    "text": "Course website\nComputational Statistics was last taught in Fall 2024, and materials can be found on the course website where you will find:\n\nsyllabus\nclass notes\nschedule\nassignments and due dates\nresources\nproject information\nGitHub help"
  },
  {
    "objectID": "courses/M154-compstat/index.html#github-classroom",
    "href": "courses/M154-compstat/index.html#github-classroom",
    "title": "Math 154: Computational Statistics",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nAs part of the learning goals of the class, we will be working with GitHub for all of the course assignments. Many of the assignments will be individual, but some of the homework assignments and the semester project will be done collaboratively. The GitHub classroom is private; please send me your GitHub username so that you can be added to the site."
  },
  {
    "objectID": "courses/M154-compstat/index.html#sakai",
    "href": "courses/M154-compstat/index.html#sakai",
    "title": "Math 154: Computational Statistics",
    "section": "Sakai",
    "text": "Sakai\nWe will also use the Sakai course management system. Sakai will be used for materials which are not publicly available. This includes:\n\nyour current grades\nsolutions to assignments\nsolutions to exams\nall the important links"
  },
  {
    "objectID": "courses/data-sources/index.html",
    "href": "courses/data-sources/index.html",
    "title": "Data Sources",
    "section": "",
    "text": "Art by @allison_horst"
  },
  {
    "objectID": "courses/data-sources/index.html#data-for-equity-inclusion",
    "href": "courses/data-sources/index.html#data-for-equity-inclusion",
    "title": "Data Sources",
    "section": "Data for Equity & Inclusion",
    "text": "Data for Equity & Inclusion\n\nNational Police Index “The National Police Index is a project and data tool showing police employment history data obtained from state police training and certification boards across the U.S. In total, 27 states have released centralized employment history data, 23 of which are currently represented on the data tool.”\nResponsibe Datasets in Context “Understanding the social and historical context of data is essential for all responsible data work. We host datasets that are paired with rich documentation, data essays, and teaching resources, all of which draw on context and humanities perspectives and methods. We provide models for responsible data curation, documentation, story-telling, and analysis.”\nSlaveVoyages: “The SlaveVoyages website is a collaborative digital initiative that compiles and makes publicly accessible records of the largest slave trades in history. Search these records to learn about the broad origins and forced relocation of more than 12 million African people who were sent across the Atlantic in slave ships, and hundreds of thousands more who were trafficked within the Americas.”\n\ngibboda: Gender Isn’t Binary But Other Data Are!\n\nhate speak corpora: particularly interesting for training NLP models\nPolice Scorecard is the first nationwide public evaluation of policing in the United States. The Scorecard calculates levels of police violence, accountability, racial bias and other policing outcomes for over 16,000 municipal and county law enforcement agencies, covering nearly 100% of the US population."
  },
  {
    "objectID": "courses/data-sources/index.html#data-challenges",
    "href": "courses/data-sources/index.html#data-challenges",
    "title": "Data Sources",
    "section": "Data Challenges",
    "text": "Data Challenges\n\nTidyTuesday A weekly data project aimed at the R ecosystem. I’ve written some suggestions and included a lot of resources for getting started with TidyTuesday\ndata for social good provides real data and structures (similar to Kaggle) for working through models and coming up with predictions – all on data which benefits the social good.\nASA DataFest The American Statistical Association (ASA) DataFest is a celebration of data in which teams of undergraduates work around the clock to find and share meaning in a large, rich, and complex data set.\nFall Data Challenge Each year, the contest challenges undergraduate and high school students to work in teams to analyze real-world data and make recommendations to combat critical issues.\nASA Data Expo The Annual Data Challenge Expo is open to anyone who is interested in participating — including government, industry, academia, retirees, and students. Each year, this contest challenges participants to analyze a core data set using statistical and visualization tools and methods. Student awards at three levels of $1,500, $1,000, and $500. (An annual spring competition, with presentations at the Joint Statistical Meetings.)\nkaggle competitions Many different data challenges with cash prizes. Alternatively, compete in a competition that has already closed for practice creating a a full data analysis.\nOther data science competitions"
  },
  {
    "objectID": "courses/data-sources/index.html#r-packages-for-connecting-to-apis",
    "href": "courses/data-sources/index.html#r-packages-for-connecting-to-apis",
    "title": "Data Sources",
    "section": "R packages for connecting to APIs:",
    "text": "R packages for connecting to APIs:\n\ncoinmarketcapr: Connecting to Coin Market Cap to get Cryptocurrencies Market Cap Prices .\nrtweet: R client for accessing Twitter (stream and REST) API.\nepidata: R package to link to the API. The Economic Policy Institute provides researchers, media, and the public with easily accessible, up-to-date, and comprehensive historical data on the American labor force. It is compiled from Economic Policy Institute analysis of government data sources. Use it to research wages, inequality, and other economic indicators over time and among demographic groups. Data is usually updated monthly.\nacs: R package to link to the API. Provides a general toolkit for downloading, managing, analyzing, and presenting data from the U.S. Census, including SF1 (Decennial short-form), SF3 (Decennial long-form), and the American Community Survey (ACS).\ntidyhydat: Canadian hydrometric data — Historical data is contained within HYDAT, the Canadian national Water Data Archive, which is published quarterly by the Government of Canada’s Department of Environment and Climate Change. Data in this archive range from 1850 to 2017. tidyhydat also provides functions to access real-time data over the web. This package would be of interest to anyone who has need for Canadian hydrometric data in R.\nipumsr: An easy way to import census, survey and geographic data provided by ‘IPUMS’ into R plus tools to help use the associated metadata to make analysis easier. ‘IPUMS’ data describing 1.4 billion individuals drawn from over 750 censuses and surveys is available free of charge from their website.\nessurvey: Download data from the European Social Survey directly from their website. There are two families of functions that allow you to download and interactively check all countries and rounds available.\ndata360r: Makes it easy to engage with the Application Program Interface (API) of the TCdata360 and Govdata360 platforms. These APIs provide access to over 5000 trade, competitiveness, and governance indicator data, metadata, and related information from sources both inside and outside the World Bank Group. Package functions include easier download of data sets, metadata, and related information, as well as searching based on user-inputted query.\nlahman: Provides the tables from the ‘Sean Lahman Baseball Database’ as a set of R data.frames. It uses the data on pitching, hitting and fielding performance and other tables from 1871 through 2015, as recorded in the 2016 version of the database.\nwbstats: Women in Parliament dataset and link to worldbank"
  },
  {
    "objectID": "courses/data-sources/index.html#r-packages-containing-multiple-datasets",
    "href": "courses/data-sources/index.html#r-packages-containing-multiple-datasets",
    "title": "Data Sources",
    "section": "R packages containing multiple datasets:",
    "text": "R packages containing multiple datasets:\n\nrefugees facilitates access to the Refugee Data Finder to access data on displacements of people tracked since 1951.\nlterdatasampler Data samples with features that are useful in introductory environmental data science and statistics courses.\ngibboda: Gender Isn’t Binary But Other Data Are!\nopenintro an R package for data and supplemental functions for OpenIntro resources\ntidyverse is a suite of R packages that contain some fantastic datasets\nfivethirtyeight: an R package that pulls in data that 538 has already publicly posted\nmosaicData\nThe R package dslabs has some great datasets, described in this Simply Statistics blog"
  },
  {
    "objectID": "courses/data-sources/index.html#dynamic-data-sets-databases",
    "href": "courses/data-sources/index.html#dynamic-data-sets-databases",
    "title": "Data Sources",
    "section": "Dynamic Data Sets / Databases:",
    "text": "Dynamic Data Sets / Databases:\n\nThe amazing TidyTuesday datasets. For example, data on Juneteenth or Wealth Inequality\nLarge compilation of survey data\nAwesome Public Datasets, a huge number of datasets automatically generated from blogs, answers, and user responses.\nWorld Atlas is a public database with 2,500 datasets. The datasets come from places like Gapminder, United Nations Data, Worldbank, and Open numbers, and it is described here in detail.\nCollege Scorecard. A tremendous amount of information about all universities (though some of it collected only from students on financial aid).\nNational Park Service Visitor Use Statistics\nFinancial and Economic data\nBehavioral Risk Factor Surveillance System\nGeneral Social Survey\nNational Health and Nutrition Examination Survey from the CDC also available in two different R packages: nhanesA and NHANES\nMedicare dataset (discussed on whitehouse.gov)\nState Health Facts\ngapminder.org – a fascinating website with amazing graphics (social and economic data broken down by country). Click on the spreadsheet links to download the data.\nWolfram/Alpha is billed as a computational search engine. Put in “nachos” you get a detailed nutritional analysis, put in “GDP of Albania”and you get several forms of GDP, a historical graph and other economic variables, put in your favorite college and get lots of info (including number of degrees in mathematics in 2009, location on a map and link to a satellite view of campus). While the case by case data display is not so convenient for building datasets there are pretty good links to the sources that Wolfram is pulling data from. For example, the Wolfram/Alpha page of info on a college or university has a data source link at the bottom to the National Center For Educational Statistics website where you can download your own custom data files from the IPSEDS (Integrated Post Secondary Education Data System) – want to know the average faculty salary by rank for all the schools in your comparison group? or the nacho search gives a link to the USDA’s National Nutrient database and a few clicks later I’ve got a spreadsheet with data on 50+ nutrients in 7400+ foods (and that’s the abbreviated data!)\nThe Census Bureau including guide to getting the most out of the Census.gov website.\nBaby names (popularity by year and state), compiled by the Social Security Administration"
  },
  {
    "objectID": "courses/data-sources/index.html#new-continuously-revised-static-data-sets-databases",
    "href": "courses/data-sources/index.html#new-continuously-revised-static-data-sets-databases",
    "title": "Data Sources",
    "section": "New & Continuously Revised Static Data Sets / Databases:",
    "text": "New & Continuously Revised Static Data Sets / Databases:\n\nCMU S&SD Data Repository\nNational Survey of Children’s Health including a dozen or so variables on 85,000 kids.\nBoston College COVID-19 Sleep and Well-Being Dataset\nCollection of datasets compiled by Robin Donatello at CSU Chico.\nHarvard Dataverse\nhate speak corpora, particularly interesting for training NLP models\nThe R package dslabs has some great datasets, described in this Simply Statistics blog\nCDC health datasets which are freely available and formatted. To be analyzed correctly, these survey data require proper weighting, clustering and stratification adjustments. There are many such datasets available, including NHAMCS (OPD and ED), NAMCS, BRFSS, NSFG, NHIS, NIS-Child, NIS-Teen, NHANES, NVSS. A quick Google of any of these acronyms will take you directly to each webpage.\nkaggle.com is a repository for data used in analysis competitions.\nUC Irvine’s Machine Learning Repository (huge and fantastic database!).\nThe GitHub site and other info for many of 538’s analyses.\nFiveThirtyEight.com has been very forward thinking in making the data and code used in many of their articles accessible on GitHub. With consultation from Andrew Flowers and Andrei Scheinkman of FiveThirtyEight, we go one step further in our package by pre-processing the data so that it more accessible statistics and data science novices and providing ample documentation in the help files.\nSee a usage example and R package called fivethirtyeight. For a more detailed outline of all data sets and a discussion on our motivation and data guidelines, see the package vignette.\nAnd this: How to explore data from 538\nData is Plural set of fun and interesting new datasets and the spreadsheet with all relevant info\nThe StudentLife Study. In 2013, four dozen Dartmouth College students agreed to let a custom smartphone app surveil them for the StudentLife Study. During the 10 weeks of the spring academic term, the app collected data on the students’ physical activity, GPS coordinates, eating schedule, sleep habits, phone usage, and more. The study combined all that information with a slew of other data, including the students’ class deadlines, academic performance, and their responses to surveys about stress, depression, personality, and sleep quality. The study’s public (and anonymized) dataset clocks in at 53 gigabytes.\nShonda Kuiper’s (Grinnell College) many data resources\nrealclimate.org keeps an up to date catalog of many different types of climate data\nAn analysis of Denny’s vs LaQuinta restaurants\nAmerican Time Use survey\nFEC contributions data (as part of Hadley Wickham’s dplyr package)\nYahoo big data datasets\nSF OKCupid Users Everett Wetchler wrote a python script back in the day to rip the public profiles of San Francisco OkCupid users. He pulled one snapshot (June 26, 2012) of all OkCupid users who lived within 25 miles of San Francisco along with other caveats. It might be of interest to students given the recent press that data-driven approaches to online dating have been getting, specifically the Wired article “How a Math Genius Hacked OkCupid to Find True Love” and Amy Webb’s Ted Talk “How I hacked online dating”.\nThis growing dataset repository presents raw data from real medical studies and offers (a) a vignette summarizing the study, research question and study design; (b) a data dictionary with clear documentation of variables and codes; (c) a complete citation for the associated study publication; and (d) a variety of data formats compatible with the majority of statistical packages.\nClinical Trials datasets from Teaching Statistics in the Health Sciences \nDASL (Data and Story Library) – a collection of datasets and related documentation which may be searched by data subjects or by statistical techniques\nBessie Chu‘s compilation of datasets\n 21 Places to Find Free Datasets for Data Science Projects\nLots of fun data from OpenIntro"
  },
  {
    "objectID": "courses/data-sources/index.html#journals-journal-articles-that-provide-corresponding-data",
    "href": "courses/data-sources/index.html#journals-journal-articles-that-provide-corresponding-data",
    "title": "Data Sources",
    "section": "Journals / Journal articles that provide corresponding data:",
    "text": "Journals / Journal articles that provide corresponding data:\n\nThe GitHub site and other info for many of 538’s analyses.\nFiveThirtyEight.com has been very forward thinking in making the data and code used in many of their articles accessible on GitHub. With consultation from Andrew Flowers and Andrei Scheinkman of FiveThirtyEight, we go one step further in our package by pre-processing the data so that it more accessible statistics and data science novices and providing ample documentation in the help files.\nSee a usage example and R package called fivethirtyeight. For a more detailed outline of all data sets and a discussion on our motivation and data guidelines, see the package vignette.\nAnd this: How to explore data from 538\nNature – Many articles have a “Data availability” section. See Hurricane-induced selection on the morphology of an island lizard which includes a link to the data.\nJournal of Statistics and Data Science Education (check the archive) or more recent papers"
  },
  {
    "objectID": "courses/data-sources/index.html#static-data-sets-databases",
    "href": "courses/data-sources/index.html#static-data-sets-databases",
    "title": "Data Sources",
    "section": "Static Data Sets / Databases:",
    "text": "Static Data Sets / Databases:\n\nDASL in Australia\nStatlib Dataset Archive – one of the original sources for archived data\nNational Institute of Standards and Technology (NIST) education data sets\nCHANCE Project Datasets – data from recent media coverage of current events. Only a few datasets here, but many excellent references to teaching applications of statistics in the news can be found at the main CHANCE page\nA data repository from statsci.org – a statistics and bioinformatics group in Australia"
  },
  {
    "objectID": "courses/data-sources/index.html#visualizing-data",
    "href": "courses/data-sources/index.html#visualizing-data",
    "title": "Data Sources",
    "section": "Visualizing Data:",
    "text": "Visualizing Data:\n\nInformation is Beautiful\nFrom Mark Ward at Purdue: Websites for Visualizing Data\nNathan Yau’s amazing visualizations: FlowingData, most of which include corresponding datasets.\nKerry Lock Morgan has posted a compilation data visualizations\nCaitlin Hudon’s GitHub site of Data Viz Resources\nNo data here, but I have to link to these amazing gifs which get cleaner as they go, by Darkhorse Analytics."
  },
  {
    "objectID": "courses/M58B-introbiostats/index.html",
    "href": "courses/M58B-introbiostats/index.html",
    "title": "Math 058B: Introduction to Biostatistics",
    "section": "",
    "text": "Art by @allison_horst\n\n\nIntroduction to Biostatistics is an introduction to statistical ideas using R. We will cover the majority of statistical methods which are used in standard analyses (e.g., t-tests, chi-squared analysis, regression, confidence intervals, binomial tests, etc.). The main inferential techniques will be covered using both theoretical approximations (e.g., the central limit theorem) as well as computational methods (e.g., permutation tests and bootstrapping). Focus will be on understanding the methods and interpreting results."
  },
  {
    "objectID": "courses/M58B-introbiostats/index.html#the-course",
    "href": "courses/M58B-introbiostats/index.html#the-course",
    "title": "Math 058B: Introduction to Biostatistics",
    "section": "",
    "text": "Art by @allison_horst\n\n\nIntroduction to Biostatistics is an introduction to statistical ideas using R. We will cover the majority of statistical methods which are used in standard analyses (e.g., t-tests, chi-squared analysis, regression, confidence intervals, binomial tests, etc.). The main inferential techniques will be covered using both theoretical approximations (e.g., the central limit theorem) as well as computational methods (e.g., permutation tests and bootstrapping). Focus will be on understanding the methods and interpreting results."
  },
  {
    "objectID": "courses/M58B-introbiostats/index.html#student-learning-outcomes.",
    "href": "courses/M58B-introbiostats/index.html#student-learning-outcomes.",
    "title": "Math 058B: Introduction to Biostatistics",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the semester, students will be able to do the following:\n\nGiven a study, identify population, sample, parameter, statistic, observational unit, and variable.\nDescribe the differences between, benefits of each, and conclusions which can be drawn in observational studies versus experiments.\nGiven a dataset and research query, create an appropriate figure in R.\nGiven a dataset and research query, compute appropriate statistics in R.\nDescribe the difference between the distribution of a sample of data and a sampling distribution of a particular statistic.\nFor a particular research question, identify whether the task requires descriptive analysis / model, graphic, confidence interval, or hypothesis test,\nApply the empirical rule to as an approximation to confidence intervals and hypothesis testing in settings of means and proportions.\nBe able to describe in words what a p-value is and what it is not.\nWrite down appropriate null and alternative hypotheses, and choose the correct analysis technique.\nRun the hypothesis test / confidence interval analysis in R.\nIdentify when it is and when it is not appropriate to summarize the relationship between two variables using a least squares line. Describe the optimization procedure the leads to a least squares fit (although not necessarily to do the calculations).\nProvide the settings in which a causal claim is warranted, and when a strong correlation is possibly due to spurious relationships.\nUse a regression line to make predictions and distinguish between a prediction interval for an independent response as compared to a confidence interval for the slope parameter.\nFor each descriptive analysis, visualization, confidence interval, or hypothesis test, in words communicate the conclusion of the analysis in the original context of the data.\nUse R Markdown to run reproducible analyses that include all aspects of the data analysis."
  },
  {
    "objectID": "courses/M58B-introbiostats/index.html#course-website",
    "href": "courses/M58B-introbiostats/index.html#course-website",
    "title": "Math 058B: Introduction to Biostatistics",
    "section": "Course website",
    "text": "Course website\nIntroduction to Biostatistics was last taught in Spring 2023, materials can be found on the course website."
  },
  {
    "objectID": "courses/M150-methbiostat/index.html",
    "href": "courses/M150-methbiostat/index.html",
    "title": "Math 150: Methods in Biostatistics",
    "section": "",
    "text": "Art by @allison_horst\n\n\nMethods in Biostatistics is a second course in biostatistics, designed to follow either an Introduction to Statistics or Introduction to Biostatistics course. No biology background is needed, but examples and methods will be focused on those found in the life sciences. In particular, the main statistical topics covered include a logistic regression, survival analysis, and methods to ameliorate multiple comparison issues."
  },
  {
    "objectID": "courses/M150-methbiostat/index.html#the-course",
    "href": "courses/M150-methbiostat/index.html#the-course",
    "title": "Math 150: Methods in Biostatistics",
    "section": "",
    "text": "Art by @allison_horst\n\n\nMethods in Biostatistics is a second course in biostatistics, designed to follow either an Introduction to Statistics or Introduction to Biostatistics course. No biology background is needed, but examples and methods will be focused on those found in the life sciences. In particular, the main statistical topics covered include a logistic regression, survival analysis, and methods to ameliorate multiple comparison issues."
  },
  {
    "objectID": "courses/M150-methbiostat/index.html#student-learning-outcomes.",
    "href": "courses/M150-methbiostat/index.html#student-learning-outcomes.",
    "title": "Math 150: Methods in Biostatistics",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the semester, students will be able to:\n\nevaluate quantitative information with regards to clinical and biological data. We’ll be sure to keep in mind:\n\nCareful presentation of data\nConsideration of variability\nMeaningful comparisons\n\ncritically evaluate the medical literature with respect to design, analysis, and interpretation of results.\nunderstand the role of inherent variability and keep it in perspective when inferring results to a population.\ncritically evaluate medical results given in the mainstream media.\nread published studies with skepticism. Some people (in all fields!) wrongly believe that all studies published in a peer review publication must be 100% accurate and/or well designed studies. In this course, you will learn the tools to recognize, interpret, and critique statistical results in medical literature."
  },
  {
    "objectID": "courses/M150-methbiostat/index.html#course-website",
    "href": "courses/M150-methbiostat/index.html#course-website",
    "title": "Math 150: Methods in Biostatistics",
    "section": "Course website",
    "text": "Course website\nMethods in Biostatistics was last taught in Spring 2025, materials can be found on the course website."
  },
  {
    "objectID": "courses/M151-prob/index.html",
    "href": "courses/M151-prob/index.html",
    "title": "Math 151: Probability Theory",
    "section": "",
    "text": "Art by @allison_horst\n\n\nProbability Theory is an introduction to probability for students with a calculus background and no prerequisites of probability or statistics. Though the course will be focused on the theoretical aspects of the material, there will be some real world applications in class and in the homework assignments. The idea is to have a strong mathematical understanding of the concepts while also understanding how the concepts are applied in the real world."
  },
  {
    "objectID": "courses/M151-prob/index.html#the-course",
    "href": "courses/M151-prob/index.html#the-course",
    "title": "Math 151: Probability Theory",
    "section": "",
    "text": "Art by @allison_horst\n\n\nProbability Theory is an introduction to probability for students with a calculus background and no prerequisites of probability or statistics. Though the course will be focused on the theoretical aspects of the material, there will be some real world applications in class and in the homework assignments. The idea is to have a strong mathematical understanding of the concepts while also understanding how the concepts are applied in the real world."
  },
  {
    "objectID": "courses/M151-prob/index.html#student-learning-outcomes.",
    "href": "courses/M151-prob/index.html#student-learning-outcomes.",
    "title": "Math 151: Probability Theory",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nAt the completion of this course, students will:"
  },
  {
    "objectID": "courses/M151-prob/index.html#course-website",
    "href": "courses/M151-prob/index.html#course-website",
    "title": "Math 151: Probability Theory",
    "section": "Course website",
    "text": "Course website\nProbability Theory was last taught in Fall 2020, materials can be found on the course website."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jo Hardin",
    "section": "",
    "text": "Welcome to my website! I’m a Professor of Mathematics & Statistics at Pomona College. I love data and teaching. Find out about my interests by perusing the site."
  },
  {
    "objectID": "about/header/index.html",
    "href": "about/header/index.html",
    "title": "Jo Hardin",
    "section": "",
    "text": "Hi and welcome to my site!\nSince 2002, I have been at Pomona College where I teach lots of different kinds of statistics, taught a little bit of math once, love teaching writing with statistics, and hope to soon teach some data science.\n\nBackground\n\nMy undergraduate degree in Mathematics is also from Pomona College, where I worked with Don Bentley. I did my PhD in Statistics at UC Davis with David Rocke. I was interviewed (August 2020) for Pomona College’s Sagecast where you can hear me talk about my path.\n\nHere to learn?\n\nMe too! So many good things to learn. I’ve posted all of my course materials freely, and I hope they give you inspiration either as a teacher or a student. I’ve also written an OpenIntro  textbook with the fantastic Mine Çentinkaya-Rundel. Introduction to Modern Statistics focuses on computational inference and multivariable modeling & visualizing, and it is available for free online.\n\nInterested in my research?\n\nOne of the best things about being a statistician is the many different subject areas to pursue. My research projects are posted, but if you have time, it’s really my students’ research projects that are worth investigating. I highly recommend working with undergraduates on research as it is among the most fun and rewarding parts of my day.\nMy areas of expertise include statistical analysis of high-throughput genetic data which don’t conform to technical conditions in standard methods. I work on problems of normalizing data structures, clustering and classifying time course profiles, and creating metrics to measure a variety of signals.\nI chose to become a statistician because of the myriad potential collaborations across many fields. I have worked with medical doctors, biologists, geologists, and physicists in my research. Through new ventures into data science (both research and teaching), I am currently exploring ways that today’s extensive data (both in scale and in occurrence) are shaping science and the world around us.\n\nWant to know what I’m up to?\n\nBeyond teaching and research, I am fortunate to be able to fit in a few hours here and there on some of my passion projects. Almost every Tuesday, I wrangle a bit of TidyTuesday data. I’m also compiling a list of scholars who are traditionally underrepresented in the statistics and data science curriculum. Feel free to use the list for your own “scholar of the day” classroom activity. And please submit a pull request or a GitHub issue if you have names to add to the database!"
  },
  {
    "objectID": "about/sidebar/index.html",
    "href": "about/sidebar/index.html",
    "title": "Jo Hardin",
    "section": "",
    "text": "** index doesn’t contain a body, just front matter above. See about/list.html in the layouts folder **"
  },
  {
    "objectID": "projects/tidytuesday/index.html",
    "href": "projects/tidytuesday/index.html",
    "title": "TidyTuesday adventures",
    "section": "",
    "text": "https://hardin47.github.io/TidyTuesday/\nI try my best to put in a few Tuesday hours working on a TidyTuesday dataset when I can. If you are in Claremont, I hope you will join us; reach out to me for information on time and place."
  },
  {
    "objectID": "projects/tidytuesday/index.html#novice",
    "href": "projects/tidytuesday/index.html#novice",
    "title": "TidyTuesday adventures",
    "section": "Novice",
    "text": "Novice\n\nLog in to https://posit.cloud/.\n\nIf you go to Pomona College, log in to Pomona’s RStudio server at https://rstudio.pomona.edu/\nOr download R and RStudio (both free) onto your own computer. R is available at http://www.r-project.org/. Additionally, install the RStudio IDE in order to use RMarkdown, https://posit.co/downloads/.\n\nTo load the data in, create an R chunk and copy in the lines of code which are just below the phrase: # Or read in the data manually on the tidytuesday GitHub site for the particular day of interest. It will look something like this:\n```{r}\ndataset_1 &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/some_date/dataset_1.csv')\n\ndataset_2 &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/some_date/dataset_2.csv')\n```"
  },
  {
    "objectID": "projects/tidytuesday/index.html#beginner",
    "href": "projects/tidytuesday/index.html#beginner",
    "title": "TidyTuesday adventures",
    "section": "Beginner",
    "text": "Beginner\nTry out these interactive tutorials to get started.\n\nIntroduction to Tidyverse: https://malooflab.ucdavis.edu/apps/tidyverse-tutorial/ and ggplot tutorial https://malooflab.ucdavis.edu/apps/ggplot-tutorial/ from the Maloof Lab.\nThe introverse package is truly meant for beginners to the tidyverse. https://sjspielman.github.io/introverse/index.html\nA fantastic ggplot2 tutorial"
  },
  {
    "objectID": "projects/tidytuesday/index.html#intermediate",
    "href": "projects/tidytuesday/index.html#intermediate",
    "title": "TidyTuesday adventures",
    "section": "Intermediate",
    "text": "Intermediate\n\nGo through the R for Data Science book (highly recommended!): https://r4ds.had.co.nz/\nAll of the fantastic cheatsheets"
  },
  {
    "objectID": "projects/tidytuesday/index.html#experienced",
    "href": "projects/tidytuesday/index.html#experienced",
    "title": "TidyTuesday adventures",
    "section": "Experienced",
    "text": "Experienced\n\nMore Advanced R for data science: https://adv-r.hadley.nz/\nGreat idea to get started with GitHub: https://happygitwithr.com/\nTidy Modeling with R by Max Kuhn and Juli Silge.\nText Mining with R by Julia Silge and David Robinson."
  },
  {
    "objectID": "projects/TDS/index.html",
    "href": "projects/TDS/index.html",
    "title": "Teach Data Science",
    "section": "",
    "text": "In the summers of 2019 and 2020, Jo Hardin (Pomona College), Hunter Glanz (Cal Poly San Luis Obsipo), and Nick Horton (Amherst College) blogged daily about topics relevant to teaching data science. Below are a list of the blog topics with links to the entries. Of note, during the summer of 2020, the majority of entries were related to data science ethics."
  },
  {
    "objectID": "projects/TDS/index.html#blog-topics-in-2019",
    "href": "projects/TDS/index.html#blog-topics-in-2019",
    "title": "Teach Data Science",
    "section": "Blog topics in 2019",
    "text": "Blog topics in 2019\n\ndata science software\n\nGetting Started with R Markdown\nProjects in RStudio\nGithub for Fun and Profit\nUsing GitHub in R\nGitHub Classroom\nRStudio Server Pro and Rstudio.cloud installations\nGetting Started with Jupyter and JupyterHub\n\ndata ingestation\n\nIngesting Data\nSQL 101 in R\nCounting commits and code review\nWriting R data packages\n\ndata technologies\n\nLeaflet for mapping\ninfer\nLess Volume More Creativity in R\nStyle Guides for Coding\nCreating Tutorials and Lessons in R using learnr\nFive Quick Tips for Coding in the Classroom\nTeaching refactoring to improve code\nUsing CODAP to teach data science\nreprex: Help me help you\nParallel processing and sparklyr\nreticulate: running Python within RStudio\nWriting R data packages\ntestthat\nCounting commits and code review\nOne model to rule them all\nCloud computing redux\n\ndata wrangling\n\nThe Tidyverse\npandas\nreticulate: running Python within RStudio\n\nvisualization and exploration\n\nTeaching Data Visualization\nAn Introduction to R Shiny\nUsing Shiny in the Classroom\n\ncommunication\n\nWatching an expert work through a data analysis using the tidyverse\nNot So Standard Deviations: not your average data science podcast\nDiversity in Data Science & Statistics\nPractical Data Science: an introduction to the PeerJ collection\nPair Programming for Data Science and Statistics\nData Science for Good\nThe Conversation Around p-values\nuseR!\ndata8\ndata100\nThe Python Community\nAlgorithmic Bias\n\nkey reports and findings\n\nData Science for Undergraduates\nGuidelines for Assessment and Instruction in Statistics Education\nRoundtable on Data Science Post Secondary Education\nUndergraduate Curriculum Guidelines\nBreiman’s Two Cultures"
  },
  {
    "objectID": "projects/TDS/index.html#blog-topics-in-2020",
    "href": "projects/TDS/index.html#blog-topics-in-2020",
    "title": "Teach Data Science",
    "section": "Blog topics in 2020",
    "text": "Blog topics in 2020\n\ncurricula and structure\n\nRe-Introduction: Ethics in Data Science Education\nKeeping Busy with Data Science\nIntegrating ethics training into any quantitative course\nRoundtable on Data Science Post Secondary Education (2019)\nData Science for Undergraduates (2019)\n\ndata sets and case studies\n\nEngaging data science students with COVID-19 data\nSocial Justice & Data Science\nData Sources\nEthical Data Viz\nData Science for Good (2019)\nAlgorithmic Bias (2019)\n\nphilosophy\n\nPhilosophical Ethics for Data Science\nHippocratic Oath\nData Privacy\n\ndiscourse\n\nBookclub on Data Science Ethics\nData Feminism\nA preview of the JSM, with focus on ethics relates session in 2020\nDiversity in Data Science & Statistics (2019)"
  },
  {
    "objectID": "projects/research/index.html",
    "href": "projects/research/index.html",
    "title": "research interests",
    "section": "",
    "text": "From Cruz et al., 2024.\nLink to Jo Hardin’s CV"
  },
  {
    "objectID": "projects/research/index.html#my-background",
    "href": "projects/research/index.html#my-background",
    "title": "research interests",
    "section": "my background",
    "text": "my background\nI have been at Pomona College since 2002 where I teach lots of different kinds of statistics, taught a little bit of math once, love teaching writing with statistics, and hope to soon teach some data science.\nMy undergraduate degree is also from Pomona College, in Mathematics where I worked with Don Bentley. I did my PhD in Statistics at UC Davis with David Rocke.\nMy current research interests include:\n\n   Statistical methods for high-throughput data\n\n\n   Inference in machine learning\n\n\n   Statistics and data science education\n\n\n   Equity and flourising in statistics and data science"
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "courses",
    "section": "",
    "text": "where can I find things?\n\n\n\n\nArt by @allison_horst\n\nMost of the course materials are on the dedicated course website. For many classes, there is also a textbook (typically available online for free). All solutions (HW, exams, etc.) will be posted on Canvas.\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDS 002R: Foundations of Data Science in R\n\n\n\n\n\nFoundations of Data Science in R is a first course in data science focused on all aspects of the data science pipeline.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Sources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID1: Statistics in the World\n\n\n\n\n\nHeadline: ‘Company Charged with Gender Bias in Hiring.’ Is the company biased? How can we tell? What do we measure? The research supporting the headline is probably less definitive than you’d expect. In this course, we will investigate the practical, ethical, and philosophical issues raised by the use of statistics and algorithmic thinking in realms such as medicine, sports, the law, genetics, and economics. We will explore issues from the mainstream media (newspapers, webpages, TV) as well as scientific articles in peer-reviewed journals. To do all of this, we will consider a wide range of statistical topics as well as encountering a range of uses and abuses of statistics in the world today.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 057: Thinking with Data\n\n\n\n\n\nThinking with Data is a general audience statistics courses taught as part of the Inside-Out Prison Exchange Program. With half of the students coming from the Claremont Collegea and half coming from the California Rehabilitation Center, students learn statistical ideas side-by-side.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 058B: Introduction to Biostatistics\n\n\n\n\n\nIntroduction to Biostatistics is a first course in statistics focused on topics and data found in the life sciences. No biological background is needed, but interest in the life sciences is important.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 150: Methods in Biostatistics\n\n\n\n\n\nMethods in Biostatistics is a second course in statistics focused on topics and data found in the life sciences. No biology background is needed, but interest in the life sciences is important.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 151: Probability Theory\n\n\n\n\n\nMath 151 is an introduction to probability for students with a calculus background and no prerequisites of probability or statistics. Though the course will be focused on the theoretical aspects of the material, there will be some real world applications in class and in the homework assignments. The idea is to have a strong mathematical understanding of the concepts while also understanding how the concepts are applied in the real world.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 152: Statistical Theory\n\n\n\n\n\nStatistical Theory is the course where the Introductory Statistics concepts are developed using first principles, probability theory, calculus, and linear algebra. Optimality of procedures is derived and discussed: which measure of ‘best’ should be used to evaluate a method?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 154: Computational Statistics\n\n\n\n\n\nComputational Statistics can be thought of as an advanced data science course. We will work with many different types of data to become fluent in wrangling, visualizing, simulating, modeling, predicting, and most importantly communicating results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath 158: Linear Models\n\n\n\n\n\nLinear models is a second course in statistics which extends a basic statistical linear model in many ways. The mathematics in the course moves quickly, and there will also be extended focus on good modeling practices and interpretation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSDS 261: Data Science, the SQL\n\n\n\n\n\nData Science, the SQL is a second course in data science focused on using SQL in the data science pipeline.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "All my web content is released under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "blogs/2020-05-18-keep-busy-with-data-science/index.html",
    "href": "blogs/2020-05-18-keep-busy-with-data-science/index.html",
    "title": "Keeping busy with data science",
    "section": "",
    "text": "Teach Data Science\n\n\nThe following entry originally appeared on May 18, 2020 at https://teachdatascience.com/keepbusy/, a blog written by Nick Horton (twitter), Hunter Glanz (twitter), and Jo Hardin (mastodon).\n\n\n\n\n\n Teach Data Science\n\n\nhttps://teachdatascience.com/\n\n\n\nIt has become increasingly clear that many college students have found themselves without summer plans. Unfortunately, this blog entry is not a list of possible employment opportunities. Instead, it is a compilation of statistics and data science projects to enhance a summer spent socially distant.\nThe list below represents opportunities at a variety of levels. If you are just beginning or quite advanced, there are many ideas for you.\n\na note on data science: as a college professor, I am often queried by my students for advice on what they should do if they want to pursue data science after their undergraduate degree. My best advice is to: do data science. That is, worry less about which classes to take or which graduate schools to apply to. Instead, worry more about learning data science skills, becoming proficient in data wrangling, and thinking critically about problem solving. Take some statistics, math, and CS classes (it doesn’t matter hugely which classes). If you have a solid background in statistics, math, and CS + some decent data science chops you will be able to accomplish whatever you want.\na note on software: The majority of the resources / links below are for doing data science in R. There are many good software options, however the resources for getting started in R are outstanding, and you are highly encouraged to check them out.\n\n\n1. GitHub\n\n\n\nWhile not necessarily the first task that you should undertake this summer, the first recommendation is to set up a GitHub account and use it to post anything you do. Each project should be a separate repository, and you should make sure to always have a README file so that others (and you six months from now) can easily see what you’ve done.\nIf you are at all serious about doing data science at any point down the road, now is the time to start collecting your data projects into a single place so that your work can be highlighted.\n\nThe ultimate site for getting GitHub up and running (and talking with RStudio) is: https://happygitwithr.com/\nIf you’d like to set up your own website, try using https://rstudio.github.io/distill/website.html\n\nAre you more advanced?\n\nmake your own website using bookdown, https://bookdown.org/yihui/bookdown/\nor a blog using blogdown, https://bookdown.org/yihui/blogdown/\n\n\n\n2. Starting with R\n\n\n\nParticularly if you are new to R, an amazing book to work through is called “R for Data Science” by Grolemund & Wickham (https://r4ds.had.co.nz/). There are many problems you can try out, and the text provides a wealth of ideas for working through data analysis problems. Even if you have been using R for many years, my guess is that the text contains many opportunities to learn how to work with new data structures.\n\ninteractive tutorials for working through “R for Data Science” at https://rstudio.cloud/learn/primers\nfor a good start to R in general, check out https://education.rstudio.com/learn/\nThere is a more advanced version to the Grolemund & Wickham text that you might want to try out if you are an advanced R user (“Advanced R” by Wickham, https://adv-r.hadley.nz/). The advanced version includes quite a bit on programming and why R works the way it does.\n\n\n\n3. Modeling Data\n\n\n\nInterested in modeling?\n\nfor modeling in R, visit the new tidymodels Get Started page: https://www.tidymodels.org/start/\narguably the best text on statistical learning models (and freely available!) is “An Introduction to Statistical Learning with Applications in R” by James et al. http://faculty.marshall.usc.edu/gareth-james/ISL/\n\n\n\n4. Natural Language Processing\n\n\n\nInterested in text analysis / natural language processing?\n\nTidytext tutorials: https://computational.journalism.wisc.edu/2018/11/16/tidytext-tutorials/\nChapter 11: tidy text: https://datascienceineducation.com/c11.html\nstringr cheat sheet: https://github.com/rstudio/cheatsheets/raw/master/strings.pdf\nText datasets to get started with: https://github.com/EmilHvitfeldt/R-text-data\nBlog post(s) by Julia Silge: https://juliasilge.com/blog/evaluating-stm/\nJulia Silge & David Robinson’s book: https://www.tidytextmining.com/\nImplementation of Google’s BERT framework into R: https://github.com/jonathanbratt/RBERT\n\n\n\n5. Practice doing data science\n\n\n\nOne of the most fun things you can do is to practice doing data science. Below are ideas you could work on for one afternoon or that you could commit a few weeks to figuring out. You should choose projects that seem fun and to which you might be able to provide a creative approach to solving.\n\nTidy Tuesday: every Tuesday a new dataset is posted, and individuals (separately and collaboratively) work to visualize the dataset. Details at https://github.com/rfordatascience/tidytuesday.\nKaggle.com: is an online community of data scientists who build models, working together to come up with optimal predictions. You can compete in an ongoing Kaggle competition, or you can work through an old competition where many teams have shared their work and their ideas.\nWork through a COVID-19 analysis. It is worth noting that the current available case data is likely to be under-reported (both cases and deaths across most countries) which makes modeling the actual data somewhat problematic. Instead, you might try to model COVID-19 related data (e.g., flights in the US, unemployment, emissions, weather patterns, etc.).\n\n\n\nTwo good resources that have been collecting analyses and other information are: http://www.stat.cmu.edu/~kass/covid.html and https://github.com/mine-cetinkaya-rundel/covid19-r\n\n\n\ndata for social good: https://www.drivendata.org/competitions/ provides real data and structures (similar to Kaggle) for working through models and coming up with predictions – all on data which benefits the social good.\nOther data science competitions: https://towardsdatascience.com/top-competitive-data-science-platforms-other-than-kaggle-2995e9dad93c\n\n\n\n6. Interactive graphics\n\n\n\nRegister for a (free) shiny account, and create a shiny dashboard to highlight the work you are doing!\n\naccount: https://shiny.rstudio.com/\ngallery: https://shiny.rstudio.com/gallery/\nShiny contest 2020 (deadline passed, but you can practice for next year!):\n\nhttps://blog.rstudio.com/2020/02/12/shiny-contest-2020-is-here/\n\n\n7. Art and R\n\n\n\nInterested in art? Make art with data and R!\n\nGetting started with generative art in R: https://djnavarro.net/post/unpredictable-paintings/\nNo code, but inspiration: https://www.data-imaginist.com/art\nFollow posts on Twitter:\n\nhttps://twitter.com/search?q=%23generative%20%23rstats&src=typed_query\n\nIllustrations — don’t want to code but draw instead? Illustrate your learnings! See https://github.com/allisonhorst/stats-illustrations for inspiration.\nHand drawn data visualizations? See http://www.dear-data.com/theproject for inspiration.\n\n\n\n8. Watch videos and take classes\n\n\n\nLearn some new stuff from videos & webinars!\n\nRStudio has a wealth of amazing videos https://resources.rstudio.com/\nDave on Data’s youtube channel:\n\nhttps://www.youtube.com/channel/UCRhUp6SYaJ7zme4Bjwt28DQ\n\nCoursera + Johns Hopkins Data Science Specialization: https://www.coursera.org/specializations/jhu-data-science\n\n\n\n9. Participate in the data science community\n\n\n\nEngage on RStudio Community (https://community.rstudio.com/) or https://stackoverflow.com/ – platforms for asking and answering all the questions. StackOverflow is more comprehensive, but it can be aggressive and unhelpful at times. RStudio Community is a great place for beginners and way less intimidating than SO.\n\nbe sure you know how to make a minimal reproducible example:\n\nhttps://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example\n\nuse the reprex package in R: https://teachdatascience.com/reprex/\n\n\n\n10. Write an R package!\n\n\n\nYou’ll be surprised to learn that creating your own R package can be reasonably straightforward. Fantastic step-by-step instructions help facilitate putting the R package together.\n\nhow to do it: https://r-pkgs.org/\nreally great example to walk through: https://www.erikhoward.net/blog/how-to-create-an-r-data-package/\nwrite a package that contains (only) a cool dataset: https://teachdatascience.com/datapackage/"
  },
  {
    "objectID": "blogs/2023-08-11-curv/index.html",
    "href": "blogs/2023-08-11-curv/index.html",
    "title": "CURV - connecting, uplifting, and recognizing voices",
    "section": "",
    "text": "In most of my courses, I’ve introduced a weekly activity of “Statistician of the Day.” The scholars who I present are those traditionally underrepresented in statistics and data science. Many of them are people of color, but they also represent individuals who are pushing boundaries to make statistics and data science more accessible and inclusive, often because they themselves have navigated a world which was not accessible or not inclusive.\nThe database is called CURV - connecting, uplifting, and recognizing voices. You can see the source code and/or contribute to the database by exploring the CURV GitHub repo."
  },
  {
    "objectID": "blogs/2023-08-11-curv/index.html#david-blackwell",
    "href": "blogs/2023-08-11-curv/index.html#david-blackwell",
    "title": "CURV - connecting, uplifting, and recognizing voices",
    "section": "David Blackwell",
    "text": "David Blackwell\nArguably, the most famous/influential/brilliant African American statistician is David Blackwell. Statisticians may know Blackwell from the Rao-Blackwell theorem which says that after conditioning on a sufficient statistic, the new estimator will have smaller (or equal to) mean squared error than the original estimator.\nBlackwell was the 1st African American elected to the National Academies of Science and the 1st African American tenured at UC Berkeley. He was the 7th African American to receive a PhD in mathematics. In 2012, President Obama posthumously awarded Blackwell the National Medal of Science.\nThe majority of Blackwell’s career in statistics was spent at UC Berkeley (1954-1988). However, his start at UC Berkeley was postponed due to racism in the Department of Mathematics. Hear Blackwell describe the situation in his own words in the following video:\n\nThe full interview with David Blackwell can be found at https://www.youtube.com/watch?v=Mqpf9tw44Xw/."
  },
  {
    "objectID": "blogs/2023-08-11-curv/index.html#why-does-representation-matter",
    "href": "blogs/2023-08-11-curv/index.html#why-does-representation-matter",
    "title": "CURV - connecting, uplifting, and recognizing voices",
    "section": "Why does representation matter?",
    "text": "Why does representation matter?\nWhen individuals don’t feel a part of the community, their identity gets mixed up with their ability. The following xkcd comic encapsulates what can happen when individuals of the non-dominant demographic group engage with the content of the course / curriculum / minor / major.\n\n\n\n\n\nimage credit – https://xkcd.com/385/\n\n\n\n\n\nResearch indicates that many young people may be deterred from pursuing STEM fields due to prominent stereotypes regarding who best fits and belongs in such fields.1\n\n\nWhat are some reasons that representation impacts participation in engaging in STEM?\n\nstereotypes about innate abilities\nstereotypes about images in the field"
  },
  {
    "objectID": "blogs/2023-08-11-curv/index.html#liz-hare",
    "href": "blogs/2023-08-11-curv/index.html#liz-hare",
    "title": "CURV - connecting, uplifting, and recognizing voices",
    "section": "Liz Hare",
    "text": "Liz Hare\nLiz Hare is not a statistician. Indeed, she is a geneticist, working primarily in dog / animal genetics. However, as someone who is very active in the Minorities in R (MiR) Community, she works regularly with statisticians.\nLiz Hare is visually impaired and has focused her work on communicating the value and ease with which statisticians and data scientists can add alt text to their reports. In the alt text, she asks us to consider and report:\n\nWhat kind of graph or chart is it?\nWhat variables are on the axes?\nWhat are the ranges of the variables?\nWhat does the appearance tell you about the relationships between the variables?\n\n\n\nAfter presenting Liz Hare and her work to my students, I am able to teach them how to include alt text in their own work, a process which is extremely straightforward if students are using R markdown or Quarto documents.\nIn R, including alt text is done by providing information for the relevant R chunk. After introducing students to Liz Hare’s work, it takes very little overhead to communicate to them the ways that a graphic can be made more accessible by adding alt text to each figure.\n\n\n\n\n\nR code for Ibo tweets in TidyTuesday analysis.\n\n\n\n\n\n\n\n\n\nDifferent ways to annotate a figure include alt text, figure captions for the full file, and figure captions for the ggplot."
  },
  {
    "objectID": "blogs/2023-08-11-curv/index.html#rafael-irizarry",
    "href": "blogs/2023-08-11-curv/index.html#rafael-irizarry",
    "title": "CURV - connecting, uplifting, and recognizing voices",
    "section": "Rafael Irizarry",
    "text": "Rafael Irizarry\nRafael Irizarry is a well known biostatistician, having done his PhD at Berkeley, worked for many years at Johns Hopkins University, and currently running a lab at Harvard as Professor of Biostatistics and at the Dana-Farber Cancer Institute as Professor of Biostatistics and Computational Biology. He has dozens of online courses through the edX platform and over a hundred publications via Google scholar.\nRelevant to the CURV database however is the work that Rafael Irizarry has done in Puerto Rico. Having graduated from the University of Puerto Rico, Rafael Irizarry had a vested interest in the community that was ravaged in 2017 when Hurricane Maria, a category 5 hurricane, ravaged the island. With collaborators, Professor Irizarry performed a representative stratified sample to measure neighborhoods based on how easily accessible they were in the aftermath of the hurricane.\nThe original news reports months after the hurricane was that the official death report from Hurricane Maria was 64 people. Professor Irizarry and colleagues estimated that the number of excess deaths was 4645, with a 95% confidence interval of 793 to 8498.\nTheir work provides a myriad of topics to unpack in a statistics classroom. Some of the discussions I have had with my students include: who is doing the work to understand climate change at a global level; how is stratified sampling different from simple random samples and why can’t we always take simple random samples; and why is the CI so wide?"
  },
  {
    "objectID": "blogs/2023-08-11-curv/index.html#footnotes",
    "href": "blogs/2023-08-11-curv/index.html#footnotes",
    "title": "CURV - connecting, uplifting, and recognizing voices",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNguyen and Riegle-Crumb. Who is a scientist? The relationship between counter-stereotypical beliefs about scientists and the STEM major intentions of Black and Latinx male and female students. International Journal of STEM Education, volume 8, Article number: 28 (2021), https://doi.org/10.1186/s40594-021-00288-x↩︎"
  },
  {
    "objectID": "blogs/2022-06-06-the-islands/index.html",
    "href": "blogs/2022-06-06-the-islands/index.html",
    "title": "Teaching with The Islands",
    "section": "",
    "text": "The Islands is a virtual environment designed to engage students in experimental design and data collection. The basic idea is that people (and their pets!) live on villages spread out along three different islands. They go to school, get sick, have friends, have jobs, etc. The individuals are able to do tasks (e.g., drink vodka or run a mile or both!) and to answer questions. They sleep at night (to the dismay of your night-owl students who want to do their data collection in the wee hours); they sometimes back out of the study; and they sometimes lie to you (e.g., about their age).\nIf now is the first time you are hearing about The Islands, I recommend that you read what others have written and ask to explore them on your own. You will be amazed at the sophistication of the virtual world contained on The Islands.\n\nMichael Bulmer created The Islands and describes them on causeweb.org, The Islands – Learning about Experiment Design on a Virtual Population as well as through the Islands in Schools Project.\nMichael Bulmer and Kimberly Haladyn (from the University of Queensland, Australia) first published their work creating the virtual world in TISE, Life on an Island: a Simulated Population to Support Student Projects in Statistics.\n\nCauseweb.org has hosts multiple past webinars describing different educators use of The Islands in their own classrooms. Ann Brearley and Laura Le from the University of Minnesota spoke at USCOTS 2017 1G: Life on an Island: Using a Virtual World to Make Statistics Real; Ryne VanKrevelen, Lisa Rosenberg, and Laura Taylor from Elon University gave a webinar in 2018 Introductory Statistics Projects Using ‘The Islands’ Virtual World Versus Student-Collected Data."
  },
  {
    "objectID": "blogs/2022-06-06-the-islands/index.html#the-islands",
    "href": "blogs/2022-06-06-the-islands/index.html#the-islands",
    "title": "Teaching with The Islands",
    "section": "",
    "text": "The Islands is a virtual environment designed to engage students in experimental design and data collection. The basic idea is that people (and their pets!) live on villages spread out along three different islands. They go to school, get sick, have friends, have jobs, etc. The individuals are able to do tasks (e.g., drink vodka or run a mile or both!) and to answer questions. They sleep at night (to the dismay of your night-owl students who want to do their data collection in the wee hours); they sometimes back out of the study; and they sometimes lie to you (e.g., about their age).\nIf now is the first time you are hearing about The Islands, I recommend that you read what others have written and ask to explore them on your own. You will be amazed at the sophistication of the virtual world contained on The Islands.\n\nMichael Bulmer created The Islands and describes them on causeweb.org, The Islands – Learning about Experiment Design on a Virtual Population as well as through the Islands in Schools Project.\nMichael Bulmer and Kimberly Haladyn (from the University of Queensland, Australia) first published their work creating the virtual world in TISE, Life on an Island: a Simulated Population to Support Student Projects in Statistics.\n\nCauseweb.org has hosts multiple past webinars describing different educators use of The Islands in their own classrooms. Ann Brearley and Laura Le from the University of Minnesota spoke at USCOTS 2017 1G: Life on an Island: Using a Virtual World to Make Statistics Real; Ryne VanKrevelen, Lisa Rosenberg, and Laura Taylor from Elon University gave a webinar in 2018 Introductory Statistics Projects Using ‘The Islands’ Virtual World Versus Student-Collected Data."
  },
  {
    "objectID": "blogs/2022-06-06-the-islands/index.html#introductory-statistics-project",
    "href": "blogs/2022-06-06-the-islands/index.html#introductory-statistics-project",
    "title": "Teaching with The Islands",
    "section": "Introductory Statistics Project",
    "text": "Introductory Statistics Project\nFor the last few years, I’ve used The Islands as a way to tie together many of the topics I cover in my introductory statistics course at Pomona College. I start the project early in the semester (the first exploration is done before spring break, and the pilot study is due a week after).1 When we start, there is still a lot of material left to cover, so in some ways the students are in the dark. One of the requirements is that they must choose a continuous response variable; they also need a few explanatory variables (some numeric, some categorical) and a treatment variable of interest. The treatment doesn’t have to be randomly assigned (the study could be observational), but almost every group uses a randomly assigned treatment variable in order to be able to assess causation at the end.\nAmong the very cool things on The Islands (really, go check it out yourself, there are way too many things to tell you about) is the Academy which includes journal articles describing studies that have taken place on The Islands in the last few years.\n\nIn what remains, I’ll describe some of the unique aspects of the project. Additionally, from both my perspective as well as from my students’ perspectives, I provide some of the feedback on successes and challenges of the project.\n\nPower Analysis\nOne of my favorite aspects of The Islands project is the ability for students to do a power analysis on pilot data. I find power to be a difficult concept to teach. Not only are the technical aspects usually pretty hard, but the intuition is also really hard (especially for students who haven’t yet done any data collection of their own). The power analysis part of the project allows me, the instructor, to do all of the work, and the students just need to wrap their heads around what is happening. I have each group post their data to a Google sheet, and then I pull in the data and run a quick power analysis assuming the difference in \\(\\mu\\) values is the same as what we saw with the pilot data (the difference in \\(\\bar{x}\\) values). The students then change the sample size and the effect size to come up with scenarios that would give them a power of 0.7. Their reflection has them questioning whether or not the effect size is real and whether or not they have the resources to collect the number of observations needed for a power of 0.7.\nBelow I’ve laid out the code and instruction that I give to students so that they can determine the needed sample size that would give their experiment a power of 0.7. In the sample data I’ve had half of the participants take 10g of Psilocybin Mushrooms (the other half is the control), then I have the participants balance on one leg for as long as they can (before and after the treatment, the response variable is the difference in time spent balancing).\n\n\nCode\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(googlesheets4)\ngs4_deauth()\n# a fake data collection made up for this blog entry\npilot_data &lt;- googlesheets4::read_sheet(\"https://docs.google.com/spreadsheets/d/1U0KcehbSQkEjwDaFpUSklKmIkUTUv-C_5q2kyO1vn24/edit?usp=sharing0\") %&gt;%\n  janitor::clean_names()\n\npilot_summary &lt;- pilot_data %&gt;%\n  group_by(treatment) %&gt;%\n  summarize(n(), mean_resp = mean(difference, na.rm = TRUE),\n            s_resp = sd(difference, na.rm = TRUE))\n\npilot_summary\n\n\n# A tibble: 2 × 4\n  treatment                 `n()` mean_resp s_resp\n  &lt;chr&gt;                     &lt;int&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Control                      12      1.25   12.6\n2 Psilocybin Mushrooms 10 g    12     13.8    15.3\n\n\nFor use in the sample size calculations, pull out each number from the summary:\n\nn1 &lt;- pilot_summary[1,2] %&gt;% pull()\nn2 &lt;- pilot_summary[2,2] %&gt;% pull()\n\nxbar1 &lt;- pilot_summary[1,3] %&gt;% pull()\nxbar2 &lt;- pilot_summary[2,3] %&gt;% pull()\n\ns1 &lt;- pilot_summary[1,4] %&gt;% pull()\ns2 &lt;- pilot_summary[2,4] %&gt;% pull()\n\n1xbar1 - xbar2\n\n2sqrt(s1^2 / n1 + s2^2/n2)\n\n\n1\n\nThe observed difference in means.\n\n2\n\nThe estimated variability for the difference in sample means.\n\n\n\n\n[1] -12.52948\n[1] 5.709265\n\n\n\nHow big should the sample size be?\nThe task is to figure out how big the sample size should be in order to reject \\(H_0: \\mu_1 = \\mu_2\\) with power of 0.7. Reasonable assumptions will be made based on the information above.\n\nStep 1. How far will \\(\\overline{X}_1 - \\overline{X}_2\\) need to be to reject \\(H_0\\)?\nIn order to reject \\(H_0\\) at the 0.05 level (two-sided test),\n\\[\\mbox{Z-score} &gt; 1.96\\]\nWhich means: \\[\\overline{X}_1 - \\overline{X}_2 &gt; 1.96 \\mbox{ SE}\\]\n\n\nStep 2. Assume that the variability is as calculated above from the data but with new sample sizes.\nThe \\(SE(\\overline{X}_1 - \\overline{X}_2)\\) will change based on the values of \\(n_1\\) and \\(n_2\\). Continue to use \\(s_1\\) and \\(s_2\\) calculated from the pilot data.\nChange the values of n1_test and n2_test to see that SE_diff changes!\n\n3n1_test &lt;- 10\n4n2_test &lt;- 10\nSE_diff &lt;- sqrt(s1^2 / n1_test + s2^2/n2_test)\nSE_diff\n\n\n3\n\ntry different numbers here!\n\n4\n\ntry different numbers here!\n\n\n\n\n[1] 6.254187\n\n\n\n\nStep 3. Use a normal curve to estimate power.\nFor a very rough approximation, use the normal curve to find out how often the difference in means will be above the cutoff (from Steps 1 and 2) for various true alternative hypotheses.\nIf the true alternative difference is 0.1, then xpnorm() centered at 0.1 (the curve below is not centered at zero) provides the probability that the sample difference will be above the cutoff.\nUnder the setting: \\(H_A: \\mu_1 - \\mu_2 = 0.1\\)\n\nThe alternative value of 0.1 is made up. What types of reasonable differences are suggested by the pilot data? Use those!\nDo the pilot data suggest that a reasonable difference is actually negative? If so, make sure your power calculation finds probability in the “less” direction instead of the “greater” direction (or alternatively, subtract \\(\\mu_2 - \\mu_1\\) instead of \\(\\mu_1 - \\mu_2\\)).\n\n\nlibrary(mosaic)\ncutoff &lt;- 1.96 * SE_diff\n\n5true_alt_diff &lt;- 0.1\n                       \nmosaic::xpnorm(cutoff, mean = true_alt_diff, sd = SE_diff, lower.tail = FALSE) \n\n\n5\n\ntry different numbers here!\n\n\n\n\n\n\n\n\n\n\n\n[1] 0.02594708\n\n\nWith samples of size 10 each, the probability of rejecting \\(H_0\\) is 0.0259471 (= the power!). Re-do steps 2 and 3 with different \\(n_1\\) and \\(n_2\\) values. What sample sizes produce a power of 0.7?\n\n\n\n\nReproducibility\nAll of the assignments are due as .pdf files which have been compiled from .Rmd files. The analyses start by pulling in the data directly from the Google sheet, and each student in the group is able to run the entire analysis from start to end. The students are comfortable working with RMarkdown, but this is the first time that their compiled analysis is a full report.\nThe project described here is for a first course in Introductory Statistics. We do not use GitHub (yet!), but we do work entirely in RMarkdown documents. We have some difficulties in getting each individual in the group to work on one .Rmd document. We use RStudio PRO, but we have not been able to set-up group sharing projects. RStudio has described products that allow groups to work simultaneously on a single document.\nRegardless, working on one report that is reproducible allowed students to bring together not only the statistical ideas from the course but also the larger ideas on how data collection, analysis, and communication all combines into a single effort.\n\n\nEthical considerations\nWhile the context, people, and data are all completely fabricated, there is still room to bring ethical considerations into the project.\nThe University of Arizona Native Nations Institute has created a policy brief on Indigenous Data Sovereignty in the United States. More materials can be found at US Indigenous Data Sovereignty Network.\nThe ethical considerations may be as simple as having the class read the policy brief and talk about how, historically, data collection has disproportionately affected different groups. In particular, collecting data is often used as a way to sustain systems of power and privilege. Although the Islands do not represent actual humans, the way we talk and think about them could impact our students directly. Additionally, for students who are soon to be data practitioners, a conversation about the power of information can help them bring positive nuance into their future work as data scientists.\nOf course, one conversation about data sovereignty will not change all systems of oppression or even, necessarily, how a group of students approaches a dataset. However, the more often the ethical considerations can be infused as part of the data analysis, the more the students will reflect on the larger and humanistic aspects of the process. Indeed, the ethical considerations could be much expanded into written reflection, student presentations, or a research project.\n\n\nPulling everything together from the entire semester\nOne of the strengths of the project is its ability to pull together many of the topics covered from throughout the semester. The students are able to use hypothesis testing to assess whether or not their randomization scheme worked. They run a power analysis and see in real time what the “next” sample (i.e., the full dataset after the pilot study) looks like in terms of spread, center, and shape.\nThe students practice making data visualizations and running tests. The last topic of the semester, multiple linear regression, shows up as a way for them to consider all of the variables collected.\nMost students are quite curious about connections to the existing literature (both in The Islands and in the real world). Some of the experiments pan out as expected, and some give strikingly different result from what is seen in the literature.\nAnd last, students get a taste for what it is like to work with data in the wild. For example, you might have noticed that the data provided had gender coded with capitals and lower-case starts. Non-systematic data coding was ubiquitous both within individual students and across group members. By making mistakes with the variable coding and writing code to clean the data, students deeply understand why having clean data to start with is so important.\n\npilot_data %&gt;%\n  group_by(treatment, gender) %&gt;%\n  summarize(mean_age = mean(age), sd_age = sd(age))\n\n# A tibble: 7 × 4\n# Groups:   treatment [2]\n  treatment                 gender mean_age sd_age\n  &lt;chr&gt;                     &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Control                   Female     34.6   22.8\n2 Control                   Male       42.7   33.2\n3 Control                   male       50.5   27.6\n4 Psilocybin Mushrooms 10 g Female     62.5   43.8\n5 Psilocybin Mushrooms 10 g Male       47.5   25.7\n6 Psilocybin Mushrooms 10 g female     77     NA  \n7 Psilocybin Mushrooms 10 g male       63     NA"
  },
  {
    "objectID": "blogs/2022-06-06-the-islands/index.html#observations",
    "href": "blogs/2022-06-06-the-islands/index.html#observations",
    "title": "Teaching with The Islands",
    "section": "Observations",
    "text": "Observations\nI conclude with some feedback provided by the students (and me) on the project. Overall, it was an excellent experience with mostly positive comments. Of course, there is always room for improvement in all the things we do.\n\nStudent Reflections\n\npositive\n\nthere are so many cool options for what to study in the Islands.\nlike the idea of humans but not actually humans (freeing from the existing literature).\nit was fun to make the islanders do unethical activities.\nthe project encouraged a mindset of curiosity and exploration.\nnext time, they would collect more demographic or related variables.\nmany students had personal motivation for their experiment choices.\nthe students enjoyed working together with peers.\nthe project reinforced skills that will transfer to other classes and future research.\n\n\n\nnegative\n\nthe power analysis was hard.\nbecause it wasn’t “real-world”, they couldn’t necessarily build on the literature.\nit took a long time to do tasks.\nthe students forgot that they needed to come back to record follow-up.\nstaying focused to get the right data was a challenge.\ncoming up with a good research question was hard.\n\n\n\n\nMy reflections\n\npositive\n\nstudents were able to reflect on needing bigger sample sizes (although for most of the non-significant studies, \\(H_0\\) was probably true, making sample size almost a moot point)\nin-class presentations, the other students asked great questions about the experimental design or other nuances of the study.\nacross the groups, there was an investigation of many different sampling types.\n\nsystematic sampling by looking at every 4th house\ncluster sampling by collecting all students on a particular island in a particular high school\nmulti-stage sampling (systematically choosing a house and randomly choosing a person in a house)\n\nstudents reflected on whether the variables were realistic, e.g., the number of times a ball could be bounced in a minute seemed to be about half of what would be realistic for human students with a basketball.\n\nthe project reinforced working with R to code, make graphs, and present work in a reproducible format.\nthe students were able to recognize that the data collection part:\n\ntakes a huge amount of time (way more than the analysis!),\nis really hard to do well, and\nmatters more than the choice of analysis technique.\n\n\n\n\nnegative\n\nstudents want quick experiments (e.g., weight loss on a given diet isn’t realistic over a few days).\nalmost all the project results are not significant.\nthere is a tendency to do a paired analysis (before and after).\nthe power analysis above uses a Z score, but the analysis uses a t-test (which can be confusing for students who are only just being introduced to the topics).\nthe tools do not yet exist to synchronously do group work in a shared Rmd file. hopefully this is changing with new tools from RStudio. (Note, for classes which use GitHub, synchronous work is more accessible for students.)"
  },
  {
    "objectID": "blogs/2022-06-06-the-islands/index.html#footnotes",
    "href": "blogs/2022-06-06-the-islands/index.html#footnotes",
    "title": "Teaching with The Islands",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe details of each assignment as well as their due dates can be found at: https://m58-intro-stats.netlify.app/project.html.↩︎"
  },
  {
    "objectID": "research/papers/index.knit.html",
    "href": "research/papers/index.knit.html",
    "title": "papers + projects",
    "section": "",
    "text": "From Lu and Hardin, 2021.\n\n\n\nLink to Jo Hardin’s CV\n\n\n(links to preprints, arXiv, or journal website)\n\n\n\nIndicates work done as an undergraduate student.\n\n\n2023\n\n\nCruz, M., Wei, A., Hardin, J., Radunskaya, A. Long-term Averages of the Stochastic Logistic Map, submitted, 2023.\n\n\n Adams, J., Hoang, J., Petroni, E., Ashby, E., Hardin, J., Stoebel, D. The timing of transcription of RpoS-dependent genes varies across multiple stresses, submitted, 2023.\n\n\n Ashby, E., Havens, J., Hardin, J., Schulz, D. Chemical inhibition of bromodomain proteins in insect stage African trypanosomes perturbs silencing of the Variant Surface Glycoprotein repertoire and results in widespread changes in the transcriptome, Microbiology Spectrum, accepted, 2023.\n\n\n Hardin, J., Shahriari, S. Community, Collaboration, and Climate, PRIMUS: Problems, Resources, and Issues in Mathematics Undergraduate Studies, 33(5), 2023.\n\n\n2022\n\n\n Çetinkaya-Rundel, M., Hardin, J., Baumer, B., McNamara, A., Horton, N., Rundel, C. An Educator’s Perspective on the Tidyverse, Technology Innovations in Statistics Education, 14 2022.\n\n\n Ashby, E., Paddock, L., Rollosson, L., Tang, E., Miller, G., Wade, S., Betts, H., Porter, A., *Saada, C., Hardin, J., Schulz, D. Genomic occupancy of the bromodomain protein Bdf3 is dynamic during differentiation of African trypanosomes from bloodstream to procyclic forms, mSphere, 7 (3), 2022.\n\n\n2021\n\n\n Çetinkaya-Rundel, M., Hardin, J. Introduction to Modern Statistics OpenIntro, 2021.\n\n\n Kim, A.Y., Hardin, J. “Playing the whole game”: A data collection and analysis exercise with Google Calendar, Journal of Statistics and Data Science Education, 29(S1), 2021.\n\n\n *Lu, B., Hardin, J. A Unified Framework for Random Forest Prediction Error Estimation, Journal of Machine Learning Research, 22(8), 2021.\n\n\nPrediction intervals for random forests with applications to high throughput data (Computational Genomics Summer Institute @ IPAM, 2017)\n\n\n\n\n Hardin, J. 9 out of 10 Seniors Recommend this First-Year Seminar: Statistics in the World, In Mathematical Themes in a First-Year Seminar, eds. J. Schaefer, J. Bowen, M. Kozek, and P. Pierce,  MAA Notes Series; 2021.\n\n\n2020\n\n\n Hardin, J., Haushalter, K., Yong, D.Turning STEM Education Inside-Out: Teaching and Learning Inside of Prisons, Science Education and Civic Engagement: An International Journal, 12 (2); 2020.\n\n\nAllison, K., Hallman, M., *Koskelo E., Radunskaya, A., Hardin, J., Hudgings, J. Increasing the speed of CCD-based thermoreflectance imaging, Review of Scientific Instruments, 91: 044901, 2020. https://doi.org/10.1063/1.5135922.\n\n\n Baumer, B., Bray, A., Çetinkaya-Rundel, M., and Hardin, J.  Teaching Introductory Statistics with DataCamp, Journal of Statistics Education, 28(1); 89-97, 2020.\n\n\n2019\n\n\n Fiksel, J., Jager, L., Hardin, J., Taub, M. Using GitHub Classroom To Teach Statistics, Journal of Statistics Education, 27(2): 110-119, 2019.\n\n\n Duron, C., Pan, Y., D. Gutmann, Hardin, J., Radunskaya, A.Variability of Betweenness Centrality and Its Effect on Identifying Essential Genes, Bulletin of Mathematical Biology, 81(9): 3655-3673, 2019. (also here)\n\n\n2018\n\n\n Horton, N., Hardin, J. Challenges and Opportunities for Statistics and Data Science Undergraduate Major and Minor Degree Programs. Proceedings of the Tenth International Conference on Teaching Statistics, 2018.\n\n\n *Evans, C., Hardin, J., Stoebel, D. Selecting between-sample RNA-Seq normalization methods from the perspective of their assumptions. Briefings in Bioinformatics, 19(5): 776–792, 2018.  (paper @ arxiv.org)\n\n\nTutorial on RNASeq Normalization and Differential Expression (Computational Genomics Summer Institute @ IPAM, 2016)\n\n\nAssumptions in Normalizing RNASeq Data (Computational Genomics Summer Institute @ IPAM, 2016)\n\n\n\n\n Hardin, J. Fun, Not Competition: The Story of My Math Club, Journal of Humanistic Mathematics, 8(1): 350-358, 2018.\n\n\n Pan, Y., Duron, C., Bush, E., Sims, P., Hardin, J., Radunskaya, A., Gutmann, D. Graph Complexity Analysis Identifies an ETV5 Tumor-Specific Network in Human and Murine Low-Grade Glioma, PLoS ONE, 13(5): e0190001, 2018. \n\n\n Hardin, J.  Dynamic Data in the Statistics Classroom. Technological Innovations in Statistics Education, 11(1), 2018.  (paper @ arxiv.org, full worked-out examples)\n\n\nDynamic Data in the Classroom (eCOTS 2016)\n\n\nDynamic Data in the Statistics Classroom (useR 2016)\n\n\n\n\n2017\n\n\n Wong, G., Bonocora, R., Schep, A., Beeler, S., Lee, A., Shull, L., Batachari, L., Dillon, M., Evans, C., Becker, C., Bush, E., Hardin, J., Wade, J., Stoebel, D. The genome-wide transcriptional response to varying RpoS levels in Escherichia coli K-12. Journal of Bacteriology, 199:e00755-16, 2017.   (paper @ biorxiv.org)\n\n\n Hardin, J., Kloke, J. “Statistical Analyses” in Current Protocols in Molecular Biology, Appendix 4A, John Wiley & Sons, 2017.\n\n\n Evans, C., Hardin, J., Huber, M., Stoebel, D., Wong, G.  Differential expression analysis for multiple conditions, unpublished, 2017. (paper @ arxiv.org)\n\n\n2016\n\n\n Coleman, J., Replogle, J., Chandler, G., Hardin, J. Resistant Multiple Sparse Canonical Correlation. Statistical Applications in Genetics and Molecular Biology;15 (2): 123-38, 2016. (paper @ arxiv.org)\n\n\n2015\n\n\n Hardin, J., Hoerl, R., Horton, N.J., Nolan, D. Data Science in Statistics Curricula: Preparing Students to ‘Think with Data’. The American Statistician, 69(4):343-353, 2015. (paper @ arxiv.org)\n\n\n Hardin, J., Sarkis, G., *URC, P.C. Network Analysis with the Enron Email Corpus. Journal of Statistics Education, 23(2), 2015. (P.C. URC stands for the Pomona College Undergraduate Research Circle whose members for this project were Timothy Kaye, David Khatami, Daniel Metz, and Emily Proulx.) (paper @ arxiv.org)\n\n\n2013\n\n\n Hardin, J., Garcia, S.R., Golan, D.  A method for generating realistic correlation matrices   Annals of Applied Statistics, 7: 1733-1762, 2013. (paper @ arxiv.org)\n\n\n2012\n\n\n *Brieger, K, J. Hardin.  Medicine and Statistics: the inextricable link    Chance, 25: 31-34, 2012.\n\n\n*Head, A., Hardin, J., Adolph, S. New methods for estimating maximum performance and the correlation of sample measures, Environmental and Ecological Statistics, 19: 127-137, 2012.\n\n\n2011\n\n\nKarnovsky, N.J., *Brown, Z.W., Welcker, J., Harding, A.M.A., Walkusz, W., Cavalcanti, A., Hardin, J., Kitaysky, A., Gabrielsen, G., Grémillet, D. Inter-colony comparison of diving behavior of an Arctic top predator: implications for warming in the Greenland Sea, Marine Ecology Progress Series, 440: 229-240, 2011.  DOI: 10.3354/meps0935.\n\n\nGrosfils, E.B., Long, S.M., Venechuk, E.M.,* Hurwitz, D.M., Richards, J.W., Kastl, Brian, *Drury, D.E., Hardin, J., 2011, Geologic map of the Ganiki Planitia quadrangle (V-14), Venus: U.S. Geological Survey Scientific Investigations Map 3121.Now available at USGS as an interactive map.\n\n\n2010\n\n\n*Richards, J., Hardin, J., Grosfils, E. Weighted Model-Based Clustering for Remote Sensing Image Analysis, Computational Geosciences, 14: 125-136, 2010.\n\n\n \n2009\n\n\n Hardin, J., Wilson, J. A note on oligonucleotide expression values not being normally distributed, Biostatistics, 10: 446-450, 2009. (full manuscript at Supplementary Material to A note onoligonucleotide expression values not being normally distributed)\n\n\n \n2008\n\n\n Yiu, G., McCord, A., Wise, A.,  Jindal, R., Hardee, J., Kuo, A., *Yuen Shimogawa, M., Cahoon, L., Wu, M., Kloke, J., Hardin, J., Mays Hoopes, L.L.; Pathways Change in Expression During Replicative Aging in Saccharomyces cerevisiae, Journal of Gerontology, 63A: 21-34, 2008.\n\n\n \n2007\n\n\n Hardin, J., Mitani, A., Hicks, L., *VanKoten, B.; A Robust Measure of Correlation Between Two Genes on a Microarray, BMC Bioinformatics, 8:220, 2007. (R code: biwt.r)\n\n\nAdolph, S., Hardin, J.; Estimating Phenotypic Correlations: Correcting for Bias Due to Intraindividual Variability, Functional Ecology, 21: 178-184, 2007.\n\n\n \n2006\n\n\n *Wise, A., Hardin, J., Hoopes, L.; Yeast Through the Ages: a statistical analysis of genetic changes in aging yeast, Chance, 19, 39-44, 2006.\n\n\n Hardin, J., Hoopes, L., *Murphy, R.; Analyzing DNA Microarrays with Undergraduate Statisticians, Proceedings of the Seventh International Conference on Teaching Statistics, 2006.\n\n\n \n2005\n\n\n Altman, N., Banks, D., Hardwick, J., Roeder, K., Craigmile, P., Hardin, J., Gupta, M.  The IMS New Researchers’ Survival Guide, Institute of Mathematical Statistics; 2005.\n\n\n Hardin, J., Rocke, D.; The Distribution of Robust Distances, Journal of Computational and Graphical Statistics, 14: 1-19, 2005.  (R code: to estimate the MCD – mcd.est.r and to estimate c and m – cm.r.)\n\n\n Hardin, J.; Microarray Data from a Statistician’s Point of View, STATS, 42:4-13, 2005.\n\n\n \n2004\n\n\n Hardin, J., Waddell, M., Page, D., Zhan, F., Barlogie, B., Crowley, J., Shaughnessy, J.; Evaluation of Multiple Models to Distinguish Closely Related Forms of Disease Using DNA Microarray Data: an Application to Multiple Myeloma,  Statistical Applications in Genetics and Molecular Biology, 3 (article 10), 2004.\n\n\n Hardin, J., Rocke, D.;  Outlier Detection in the Multiple Cluster Setting Using the Minimum Covariance Determinant Estimator, Computational Statistics and Data Analysis, 44: 625-638, 2004.\n\n\n Pauler, D., Hardin, J., Faulkner, J., Leblanc, M., Crowley, J.; Survival Analysis with Gene Expression Arrays. In Handbook of Statistics 23: Advances in Survival Analysis, eds. N.Balakrishnan and C.R. Rao, Elsevier Science: Amsterdam; 2004.\n\n\n \n2002\n\n\n Durbin, B., Hardin, J., Hawkins, D., Rocke, D.;  A Variance-Stabilizing Transformation for Gene-Expression Microarray Data; Bioinformatics, 18: S105-S110, 2002.\n\n\n Zhan, F., Hardin, J., Kordsmeier, B., Bumm, K., Zheng, M., Tian, E., Sanderson, R., Yang, Y., Wilson, C., Zangari, M., Anaissie, E., Morris, C., Muwalla, F., van Rhee, F., Fassas, A., Crowley, J., Tricot, G., Barlogie, B., Shaughnessy, J.; Global Gene Expression Profiling of Multiple Myeloma, Monoclonal Gammopathy of Undetermined Significance, and Normal Bone Marrow Plasma Cells; Blood, 99: 1745-1757, 2002.\n\n\n \n1999-2000\n\n\n Hardin, J.; Multivariate Outlier Detection and Robust Clustering with Minimum Covariance Determinant Estimation and S-Estimation.  Ph.D. thesis, Statistics; University of California, Davis.  2000.\n\n\n Coleman, D., Dong, X., Hardin, J., Rocke, D.M., Woodruff, D.L.; Some Computational Issues in Cluster Analysis with no à priori Metric; Computational Statistics and Data Analysis, 31: 1-11, 1999.\n\n\n \n\n   Statistical methods for high-throughput data\n\n\n   Inference in machine learning\n\n\n   Statistics and data science education\n\n\n   Equity and flourising in statistics and data science"
  },
  {
    "objectID": "research/student-work/index.html",
    "href": "research/student-work/index.html",
    "title": "student work",
    "section": "",
    "text": "Undergraduate projects are the most fun and the most rewarding part of my day.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaricela & Madison, Women in Statistics and Data Science 2017\n\n\n\n\n\n\n\nAssociation for Women in Mathematics (AWM), 2020\n\n\n\n\n\n\n\nAlejandra, Maria, & Ruby, DataFest 2016\n\n\n\n\n\n\n\n10th anniversary DataFest 2022\n\n\n\n\n\n\n\nHilary (who makes R mugs!)\n\n\n\n\n\n\n\nPomona Scholars of Math (PSM8), 2022\n\n\n\n\n\n\n\nChristina, PhD & Ami Radunskaya, 2019\n\n\n\n\n\nPrevoius\n\n\n\nNext\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\nSenior Thesis ProjectsStudent Successes\n\n\n\n2024:\n\n\n\nSara Colando (2024): “Selecting ChIP-Seq Normalization Methods from the Perspective of their Technical Conditions”; Currently: PhD candidate, Carnegie Mellon University, Statistics.\n\n\n\n2023:\n\n\n\nIan Krupkin (2023): “Prediction Error Estimation in Random Forests”; Currently: Boston Consulting Group.\n\n\nOlivia Leu (2023): “Mathematics of Redistricting: Identifying Gerrymandering Through Outlier Analysis”; Currently: Data Analyst, Democracy Program at The Carter Center.\n\n\nSummer Will (2023): “Theoretical Properties of Oversampling Techniques”; Currently: Digital Analytics Intern, CVS Health.\n\n\nJulie Ye (2023): “Permutation Tests for Multiple Linear Regression Models”; Currently: MS candidate, Yale University, Statistics & Data Science.\n\n\n\n2022:\n\n\n\nWill Gray (2022): “Detecting Rotation Periods of Near-Earth Asteroids: An investigation of Fourier Analysis and the Lomb-Scargle Periodogram”;\n\n\nLauren Quesada (2022): “Permutation Tests: A Deep Dive into Applications in Multiple Linear Regression”; Currently: PhD candidate, Colorado School of Mines, Statistics.\n\n\nMoe Sunami (2022): “Conformal Prediction Intervals”; Currently: Carbon Data Analyst, Watershed\n\n\nNick Waalkes (2022): “Simulation and Application Study of Online False Discovery Control Methods”; Currently: Analyst, Ridgepeak Partners.\n\n\n\n2021:\n\n\n\nEthan Ashby (2021): “Extracting hitherto unseen variant signals from the cancer genome using data de-sparsification strategies”; Currently: PhD candidate, University of Washington, Biostatistics.\n\n\nAnnie Cohen (2021, Scripps): “Investigating changes in the SEIRMD model applied to COVID-19”; Currently: PhD candidate, University of Michigan, Biostatistics.\n\n\nEmma Godfrey (2021): “Non-parametric Alternative Techniques for Propensity Score Estimation”; Currently: Statistical Analyst, ZipRecruiter\n\n\nNat Serrurier (2021, PPA Biology): “Palliative Care and Dementia: An Underutilized Method in the Fight Against a Health Crisis”; Currently: Doctor of Physical Therapy candidate, Columbia University, Vagelos College of Physicians and Surgeons.\n\n\n\n2020:\n\n\n\nHelen Lan (2020): “Multiple Comparison Test”; Currently: MBA candidate, University of Pennsylvania, The Wharton School.\n\n\nNolan McCafferty (2020): “Style Transfer with Neural Networks”; Currently: Software Engineer, Omnistrate\n\n\nZach Senator (2020): “Random Forests and Beyond”; Currently: Investment Banking Associate, J.P. Morgan.\n\n\nAmy Watt (2020): “The Expectation Maximization Algorithm in RNA-Sequencing Read Alignment”; Currently: PhD candidate, University of Washington, Biostatistics.\n\n\n\n2019:\n\n\n\nAlex Gui (2019): “Local Prediction Confidence for Classification Random Forests”; MS 2021, Stanford University, Statistics: Data Science, Currently: Data Scientist, Meta.\n\n\nFrances Hung (2019): “Active Learning Experimental Design of Bayesian Networks”; MS 2021, Duke University, Statistics, Currently: JD candidate, UCLA\n\n\nVedant Vohra (2019): “Estimating the proportion who benefit from a treatment in a Randomized Controlled Trial”; Currently: PhD candidate, UC San Diego, Economics\n\n\nJustin Weltz (2019): “Over-Policing and Fairness in Machine Learning”; Currently: PhD candidate, Duke University, Statistics\n\n\n\n\nChristina Duron (2019, PhD CGU): “The Distribution of Betweenness Centrality in Exponential Random Graph Models”; Currently: Assistant Professor of Mathematics, Pepperdine University\n\n\n\n2018:\n\n\n\nChris Barnes (2018): “Artistic Style Transfer using Deep Learning”; Currently: Partner, Skye Global Management.\n\n\nKalyan Chadalavada (2018): “Partial Least Squares Regression in Football Projections”; MS 2019, Tulane University, Pharmacology, Currently: Practice Manager, Springfield Pulmonary Medicine and Sleep Clinic.\n\n\nLuis Espino (2018): “Racism without a Face: Predictive Statistics in the Criminal Justice System”; Currently: Director of Product Management, fwd.us, Community Department.\n\n\nKashvi Tibrewal (2018): “Evaluating Splitting Criteria in Classification Trees”; MBA 2024, University of Michigan, Stephen Ross School of Business.\n\n\n\n2017:\n\n\n\nBenji Lu (2017): “Constructing Prediction Intervals for Random Forests”; Ph.D. 2024, UC Berkeley, Statistics, JD 2024, Yale University. Currently: .\n\n\nMaria Martinez Lainez (2017): “The EM algorithm and RNA sequencing”; Currently: Software Engineer II, Intuit.\n\n\nYenny Zhang (2017): “Integrating Random Forests into the Bag of Little Bootstraps”; Currently: Senior Software Engineer, Medallion.\n\n\n\n2016:\n\n\n\nIsaiah Boone (2016): “SVM and the Application of Prediction Rules”; Currently: Partner, Sequoia Capital.\n\n\nJohn Bryan (2016): “Developing Inference Frameworks for Random Forests Using Bag of Little Bootstraps and Related Methods”; M.D. 2023, Northwestern University Feinberg School of Medicine. Currently: ophthalmology resident, Northwestern University Department of Ophthalmology\n\n\nCiaran Evans (2016): “Normalization of RNA-Seq data in the case of asymmetric differential expression”; Ph.D. 2021, Carnegie Mellon University, Statistics. Currently: Assistant Professor of Mathematics & Statistics, Wake Forest University.\n\n\nDylan Quantz (2016): “Analyzing Centrality in Complex Gene Networks”; Currently: Player Development Trainee, Atlanta Braves.\n\n\n\n2015:\n\n\n\nRebecca Baiman (2015): “A Critical Comparison of Methods in Statistical Inference Education”; Masters of Education 2017, Math Secondary Education, Vanderbilt University; Currently: Ph.D. candidate, CU Boulder, Atmospheric Science.\n\n\nJacob Fiksel (2015): “Differential Gene Expression Analysis with Microarray and RNA-seq Data”; Ph.D. 2020, Johns Hopkins Bloomberg School of Public Health, Biostatistics; Currently: Senior Preclinical Research Statistician, Vertex Pharmaceuticals.\n\n\n\nJacob’s blog (about grad school and data science, among other things)\n\n\nInterview of Jacob as part of the The Johns Hopkins #100 Alumni Voices Project\n\n\n\nChris Garnatz (2015): “Trusting the Black Box: Confidence with Bag of Little Bootstraps”; Currently: Data Engineer, TRM Labs\n\n\nCaroline Zaia (2015): “Multilevel Regression in Value Added Modeling for Teacher Assessment”; Currently: Revenue & Margin Manager, Stitch Fix\n\n\n\n2014:\n\n\n\nMaricela Cruz (2014): “Long-term Averages of the Stochastic Logistic Map”; Ph.D. 2019, University of California, Irvine, Statistics; Currently: Assistant Investigator at Kaiser Permanente Washington Health Research Institute\n\n\nThalia Rodriguez (2014): “Towards a More Conceptual Way of Understanding and Implementing Inferential Rules”; MEd 2015, the University of Southern California Rossier School of Education; Currently: Mathematics Teacher, Heninger Elementary.\n\n\nBrian Williamson (2014): “Shrinkage Estimators for High-Dimensional Covariance Matrices”; Ph.D. 2019, University of Washington, Biostatistics; Currently: Assistant Investigator, Kaiser Permanente Washington Health Research Institute\n\n\n\n2013:\n\n\n\nMelinda Borello (2013, Pitzer): “Standardization and Singular Value Decomposition in Canonical Correlation Analysis”;\n\n\nJacob Coleman (2013): “Robust Sparse Canonical Correlation Analysis and PITCHf/x”; Ph.D. 2019, Duke University, Statistics; Currently: .\n\n\nKarl Kumbier (2013): “Detecting and Estimating Filamentary Structures in the Presence of Background Noise”; Ph.D. 2019, UC Berkeley, Statistics; Currently: Data Scientist, Pharmaceutical Chemistry, School of Pharmacy, UCSF.\n\n\nGuy Stevens (2013): “Bayesian Statistics and Baseball” ; Currently: Owner & CEO, Winning Insight Consulting.\n\n\nYuanxi Zhang (2013): “How Does a Bayesian Investor Time the Market”; M.S. 2018, U Chicago, Economics.\n\n\n\n2012:\n\n\n\nTim Stutz (2012): “Modeling the Evolution of Sexual Diploid Populations via a Stochastic Moran Process”; Ph.D. 2020, UCLA, Biomathematics. Currently: .\n\n\n\n2011:\n\n\n\nKate Brieger (2011, EA, independent study): “The Evolution of Statistics in Medicine” ; M.D. / Ph.D. 2022, University of Michigan, Epidemiology; Currently: Clinical Fellow in Psychiatry, Brigham and Women’s Hospital, Harvard Medical School.\n\n\nChristine Ju (2011, Scripps): “Determining Overrepresentation of Gene Ontology Terms using the Hypergeometric Distribution”; M.S. 2013, Duke, Biostatistics; Currently: Associate Director, Biostatistics, ALX Oncology.\n\n\n\n2010:\n\n\n\nMinsoo Kim (2010): “Statistical Classification”; M.S. 2015, U Georgia, Statistics; Currently: Scientific Computing Professional Associate, Carl Vinson Institute of Government.\n\n\nMary Owen (2010): “Tukey’s Biweight Correlation and the Breakdown”; Currently: Operations Assistant, Jennie’s Kitchen.\n\n\nMark Simon (2010): “Randomly Generating Computationally Stable Correlation Matrices”; Currently: Senior Investment Analyst, Taal Capital Management.\n\n\n\n2009:\n\n\n\nPatrick Kimes (2009): “Understanding q-values as a More Intuitive Alternative to p-values”; Ph.D. 2015 (“New Statistical Learning Approaches with Applications to RNA-Sequencing Data.” Advisor: J.S. Marron), UNC, Statistics; Currently: Principal Statistical Scientist, Genentech.\n\n\nAlison Kosel (2009): “Simulating Correlated Multivariate Normal Data”; Ph.D. 2016 (“Local Estimation of Patient Prognosis” Advisor: Patrick Heagerty), U Washington, Biostatistics; Currently: Data Scientist, Facebook.\n\n\nDaniel Scinto (2009): “Stock Ranking and Portfolio Selection: Revising and Developing Z-scores”; Currently: Portfolio Manager, Alphadyne Asset Management.\n\n\n\n2008:\n\n\n\nBrianna Pasco (2008, Scripps): “A Basic Introduction and Comparison of Linear Discriminant Analysis and Support Vector Machines”.\n\n\nNick Conway (2008): “A Resistant Measure of Distance in DNA Microarrays”.\n\n\nAusten Head (2008): “Correlation Correction of Sample Measures from Bivariate Distributions”; Ph.D. 2014, Stanford, Statistics; Currently: Staff Machine Learning Engineer, PayJoy.\n\n\nRobert Kurtzman (2008): “The Advantages of a Biweight Metric in Clustering Microarray Data”; Ph.D. 2015, UCLA, Economics; Currently: Group Manager, Federal Reserve Board.\n\n\n\n2007:\n\n\n\nJeffery Joe Nanda (2007): “Correcting for Bias in Correlation Coefficients Due to Intraindividual Variability”; MBA 2011, Stanford; Currently: Head of Investments, American Triple.\n\n\nAndrea Vijverberg Seo (2007): “Clustering Microarray Data”; M.S. Computational Finance 2008; Currently: Quantitative Model Analyst, Counterparty Risk, US Bank\n\n\nJonathan Buster Zalkind (2007): “Four Colors is not Enough: Visualizations of Simulated Spatial-Model Elections Under Different Voting Methods”; MBA, The University of Chicago Booth School of Business, Currently: Vice President, Playco.\n\n\n\n2006:\n\n\n\nAya Mitani (2006, Pitzer): “Biweight Correlation as a Measure of Distance between Genes on a Microarray” (abstract, presentation); MPH 2008, Yale, Biostatistics; Ph.D. 2019, Boston University, Biostatistics; Currently: Assistant Professor of Biostatistics, Dalla Lana School of Public Health, University of Toronto.\n\n\n\n2005:\n\n\n\nJoseph Richards (2005): “Classification of Geologic Units on Ganiki Planitia Quadrangle (V14) Venus Using Statistical Clustering Methods”, Ph.D. 2010, Carnegie Mellon University, Statistics; Currently: COO, Down to Cook.\n\n\nAlison Wise (2005): “Statistical Analysis of Microarrays to Determine Genetic Changes in Aging Yeast”; Ph.D. candidate, UNC, Biostatistics.\n\n\n\n2004:\n\n\n\nLee (Strassenburg) Shanahan (2004): “A Statistical Comparison of the Average Waiting Times Between Flares in Lupus Patients”, Currently: Technical Solutions Engineer at findhelp.\n\n\n\n2003:\n\n\n\nVeronica (Montes De Oca) Aispuro (2003): “Methods for Evaluating Health Care Claims Data” (an application of Bootstrapping); Ph.D. 2008, University of California, Riverside, Applied Statistics; Currently: Senior Director of Stars Survey Analytics, UnitedHealth Group.\n\n\n\n\n\n\n2024:\n\n\n\nJazelle Saligumba ’26, Kellie Au ’26, Julianne Louie ’26, Chau Vu ’26, Yunju Song ’26 DataFest - The Don Ylvisaker Best Insight Award (Honorable Mention)\n\n\nSara Colando ’24 compilation of data science ethics curricula, to accompany our joint paper Philosophy within Data Science Ethics Courses.\n\n\n\n2022:\n\n\n\nPipi Gao ’22 Finalist in the MD++ Datathon 2022 as part of team WeLoveRData. The Datathon was founded and organized by Lathan Liou ’19.\n\n\nXuehuai He ’25, Saatvik Kher ’24, Samson Zhang ’25 DataFest - The Don Ylvisaker Best Insight Award (Honorable Mention)\n\n\nAditya Bhalla ’23, Alan Zhou ’23 DataFest - Best Use of Statistical Models (Honorable Mention)\n\n\n\n2021:\n\n\n\nEthan Ashby ’21 A Regularized Cox Regression Approach to the Health Evaluation and Linkage to Primary Care (HELP) Clinical Trial 2nd place Paper Undergraduate Statistics Class (intermediate) Project Competition\n\n\nHannah Mandel ‘23, Emily Tomz ’23, Adeena Liang ’23, Chloe Sun ’23, Ian Krupkin ’23 DataFest - Judges’ Choice Award\n\n\n\n2020:\n\n\n\nAmber Lee ’22 Exploring Missingness and its Implications on Traffic Stop Data 2nd place Paper Undergraduate Statistics Research Project Competition\n\n\nAmber Lee ’22, Arm Wonghirundacha ’22, Emma Godfrey ’21, Ethan Ong ’21, Ivy Yuan ’21, Oliver Chang ’22, and Will Gray ’22;  Data Exploration of US Police Stops, Data Science Research Circle, supervised by Jo Hardin and Ghassan Sarkis\n\n\nGuy Thampakkul ‘23, Tai Xiang ’23; DataFest - Judges’ Choice Award\n\n\n\n2019:\n\n\n\nChristina Duron, PhD Claremont Graduate University 2019 The Distribution of Betweenness Centrality in Exponential Random Graph Models\n\n\nAmy Watt ’20, Adam Rees ’20, Ethan Ashby ’21, Connor Ford ’20, Madelyn Andersen ’22 (HMC); DataFest – Best Use of External Data\n\n\n\n2018:\n\n\n\nVedant Vohra ’19, Zihao Xu ’19, Madison Hobbs ’19 (Scripps), Xiaotong Gui ’19 DataFest - Best Insight, honorable mention\n\n\n\n2017:\n\n\n\nZihao Xu ’19 Bag of Little Random Bootstraps Winning Paper Undergraduate Statistics Research Project Competition\n\n\nJeff Carney ‘18, Hyeong Shin ’19, Adam Starr ’18  DataFest - Judges’ Choice Award\n\n\n\n2014:\n\n\n\nTim Kaye ’15, David Khatami ’16, Daniel Metz ’16, Emily Proulx ’16  Quantifying and Comparing Centrality Measures for Network Individuals as Applied to the Enron Corpus Winning Paper Undergraduate Statistics Research Project Competition, Data Science Research Circle, supervised by Jo Hardin and Ghassan Sarkis\n\n\nTim Kaye ’15, David Khatami ’16, Daniel Metz ’16, Emily Proulx ’16 Quantifying and Comparing Centrality Measures for Network Individuals as Applied to the Enron Corpus; SIAM Undergraduate Research Online, 7: 2014.\n\n\n\n2013:\n\n\n\nJacob Coleman ’13, Maricela Cruz ’14, Bill DeRose ’15, Ciaran Evans ’15, Rob Knickerbocker ’15, Kevin Lu ’14, Derek Owens-Oas ’13, Ben Shand ’14, Brian Williamson ’14; DataFest - Best Insight\n\n\n\n2012:\n\n\n\nKarl Kumbier ’13, Erika Parks ’13, Joseph Replogle ’13 DataFest - Best Use of External Data\n\n\nDrew DiPalma ’13, Tim Stutz ’12; DataFest - Best Visualization, honorable mention"
  },
  {
    "objectID": "research/papers/index.html",
    "href": "research/papers/index.html",
    "title": "papers + projects",
    "section": "",
    "text": "From Lu and Hardin, 2021.\n\n\n\nLink to Jo Hardin’s CV\n\n\n(links to preprints, arXiv, or journal website)\n\n\n# Indicates work done as an undergraduate student.\n\n\n   Statistical methods for high-throughput data\n\n\n   Inference in machine learning\n\n\n   Statistics and data science education\n\n\n   Equity and flourishing in statistics and data science\n\n\n\n\n\n2025\n\n\n#Kher, S., #Lee, A., and Hardin, J. Measuring the Impact of Missingness on Racial Bias in Traffic Stop Data. Submitted, 2025.\n\n\n #Colando, S., Schulz, D., and Hardin, J. Selecting ChIP-Seq Normalization Methods from the Perspective of their Technical Conditions. Submitted, 2025.\n\n\n Hardin, J., #Quesada, L., #Ye, J., and Horton, N.J. The Exchangeability Assumption for Permutation Tests of Multiple Regression Models: Implications for Statistics and Data Science. Submitted, 2025.\n\n\n2024\n\n\n Hardin, J. CURV - connecting, uplifting, and recognizing voices, Chance Magazine, Statistics Education Column, Taking a Chance in the Classroom 37(2), 2024.\n\n\n #Colando, S., Hardin, J. Philosophy within Data Science Ethics Courses, Journal of Statistics and Data Science Education 32(4), 2024.\n\n\n#Cruz, M., #Wei, A., Hardin, J., Radunskaya, A. Long-term Averages of the Stochastic Logistic Map, Journal of Difference Equations and Applications 30(6), 2024.\n\n\n Çetinkaya-Rundel, M., Hardin, J. Introduction to Modern Statistics OpenIntro, 2nd edition, 2024.\n\n\n2023\n\n\n #Adams, J., #Hoang, J., #Petroni, E., #Ashby, E., Hardin, J., Stoebel, D. The timing of transcription of RpoS-dependent genes varies across multiple stresses in Escherichia coli K-12, mSystems 8(5), 2023.\n\n\n #Ashby, E., #Havens, J., Hardin, J., Schulz, D. Chemical inhibition of bromodomain proteins in insect stage African trypanosomes perturbs silencing of the Variant Surface Glycoprotein repertoire and results in widespread changes in the transcriptome, Microbiology Spectrum 11(3), 2023.\n\n\n Hardin, J., Shahriari, S. Community, Collaboration, and Climate, PRIMUS: Problems, Resources, and Issues in Mathematics Undergraduate Studies, 33(5), 2023.\n\n\n2022\n\n\n Çetinkaya-Rundel, M., Hardin, J., Baumer, B., McNamara, A., Horton, N., Rundel, C. An Educator’s Perspective on the Tidyverse, Technology Innovations in Statistics Education, 14 2022.\n\n\n #Ashby, E., #Paddock, L., #Rollosson, L., #Tang, E., #Miller, G., #Wade, S., #Betts, H., #Porter, A., #Saada, C., Hardin, J., Schulz, D. Genomic occupancy of the bromodomain protein Bdf3 is dynamic during differentiation of African trypanosomes from bloodstream to procyclic forms, mSphere, 7 (3), 2022.\n\n\n2021\n\n\n Çetinkaya-Rundel, M., Hardin, J. Introduction to Modern Statistics OpenIntro, 1st edition, 2021.\n\n\n Kim, A.Y., Hardin, J. “Playing the whole game”: A data collection and analysis exercise with Google Calendar, Journal of Statistics and Data Science Education, 29(S1), 2021.\n\n\n #Lu, B., Hardin, J. A Unified Framework for Random Forest Prediction Error Estimation, Journal of Machine Learning Research, 22(8), 2021.\n\n\nPrediction intervals for random forests with applications to high throughput data (Computational Genomics Summer Institute @ IPAM, 2017)\n\n\n\n\n Hardin, J. 9 out of 10 Seniors Recommend this First-Year Seminar: Statistics in the World, In Mathematical Themes in a First-Year Seminar, eds. J. Schaefer, J. Bowen, M. Kozek, and P. Pierce,  MAA Notes Series; 2021.\n\n\n2020\n\n\n Hardin, J., Haushalter, K., Yong, D.Turning STEM Education Inside-Out: Teaching and Learning Inside of Prisons, Science Education and Civic Engagement: An International Journal, 12 (2); 2020.\n\n\n#Allison, K., #Hallman, M., #Koskelo E., Radunskaya, A., Hardin, J., Hudgings, J. Increasing the speed of CCD-based thermoreflectance imaging, Review of Scientific Instruments, 91: 044901, 2020. https://doi.org/10.1063/1.5135922.\n\n\n Baumer, B., Bray, A., Çetinkaya-Rundel, M., and Hardin, J.  Teaching Introductory Statistics with DataCamp, Journal of Statistics Education, 28(1); 89-97, 2020.\n\n\n2019\n\n\n Fiksel, J., Jager, L., Hardin, J., Taub, M. Using GitHub Classroom To Teach Statistics, Journal of Statistics Education, 27(2): 110-119, 2019.\n\n\n Duron, C., Pan, Y., D. Gutmann, Hardin, J., Radunskaya, A.Variability of Betweenness Centrality and Its Effect on Identifying Essential Genes, Bulletin of Mathematical Biology, 81(9): 3655-3673, 2019. (also here)\n\n\n2018\n\n\n Horton, N., Hardin, J. Challenges and Opportunities for Statistics and Data Science Undergraduate Major and Minor Degree Programs. Proceedings of the Tenth International Conference on Teaching Statistics, 2018.\n\n\n #Evans, C., Hardin, J., Stoebel, D. Selecting between-sample RNA-Seq normalization methods from the perspective of their assumptions. Briefings in Bioinformatics, 19(5): 776–792, 2018.  (paper @ arxiv.org)\n\n\nTutorial on RNASeq Normalization and Differential Expression (Computational Genomics Summer Institute @ IPAM, 2016)\n\n\nAssumptions in Normalizing RNASeq Data (Computational Genomics Summer Institute @ IPAM, 2016)\n\n\n\n\n Hardin, J. Fun, Not Competition: The Story of My Math Club, Journal of Humanistic Mathematics, 8(1): 350-358, 2018.\n\n\n Pan, Y., Duron, C., Bush, E., Sims, P., Hardin, J., Radunskaya, A., Gutmann, D. Graph Complexity Analysis Identifies an ETV5 Tumor-Specific Network in Human and Murine Low-Grade Glioma, PLoS ONE, 13(5): e0190001, 2018. \n\n\n Hardin, J.  Dynamic Data in the Statistics Classroom. Technological Innovations in Statistics Education, 11(1), 2018.  (paper @ arxiv.org, full worked-out examples)\n\n\nDynamic Data in the Classroom (eCOTS 2016)\n\n\nDynamic Data in the Statistics Classroom (useR 2016)\n\n\n\n\n2017\n\n\n #Wong, G., Bonocora, R., #Schep, A., #Beeler, S., Lee, A., #Shull, L., #Batachari, L., #Dillon, M., #Evans, C., #Becker, C., Bush, E., Hardin, J., Wade, J., Stoebel, D. The genome-wide transcriptional response to varying RpoS levels in Escherichia coli K-12. Journal of Bacteriology, 199:e00755-16, 2017.   (paper @ biorxiv.org)\n\n\n Hardin, J., Kloke, J. “Statistical Analyses” in Current Protocols in Molecular Biology, Appendix 4A, John Wiley & Sons, 2017.\n\n\n #Evans, C., Hardin, J., Huber, M., Stoebel, D., #Wong, G.  Differential expression analysis for multiple conditions, unpublished, 2017. (paper @ arxiv.org)\n\n\n2016\n\n\n #Coleman, J., #Replogle, J., Chandler, G., Hardin, J. Resistant Multiple Sparse Canonical Correlation. Statistical Applications in Genetics and Molecular Biology;15 (2): 123-38, 2016. (paper @ arxiv.org)\n\n\n2015\n\n\n Hardin, J., Hoerl, R., Horton, N.J., Nolan, D. Data Science in Statistics Curricula: Preparing Students to ‘Think with Data’. The American Statistician, 69(4):343-353, 2015. (paper @ arxiv.org)\n\n\n Hardin, J., Sarkis, G., #URC, P.C. Network Analysis with the Enron Email Corpus. Journal of Statistics Education, 23(2), 2015. (P.C. URC stands for the Pomona College Undergraduate Research Circle whose members for this project were Timothy Kaye, David Khatami, Daniel Metz, and Emily Proulx.) (paper @ arxiv.org)\n\n\n2013\n\n\n Hardin, J., Garcia, S.R., Golan, D.  A method for generating realistic correlation matrices , Annals of Applied Statistics, 7: 1733-1762, 2013.\n\n\n2012\n\n\n #Brieger, K, J. Hardin.  Medicine and Statistics: the inextricable link    Chance, 25: 31-34, 2012.\n\n\n#Head, A., Hardin, J., Adolph, S. New methods for estimating maximum performance and the correlation of sample measures, Environmental and Ecological Statistics, 19: 127-137, 2012.\n\n\n2011\n\n\nKarnovsky, N.J., #Brown, Z.W., Welcker, J., Harding, A.M.A., Walkusz, W., Cavalcanti, A., Hardin, J., Kitaysky, A., Gabrielsen, G., Grémillet, D. Inter-colony comparison of diving behavior of an Arctic top predator: implications for warming in the Greenland Sea, Marine Ecology Progress Series, 440: 229-240, 2011.  DOI: 10.3354/meps0935.\n\n\nGrosfils, E.B., #Long, S.M., #Venechuk, E.M.,# Hurwitz, D.M., #Richards, J.W., #Kastl, Brian, #Drury, D.E., Hardin, J., 2011, Geologic map of the Ganiki Planitia quadrangle (V-14), Venus: U.S. Geological Survey Scientific Investigations Map 3121.Now available at USGS as an interactive map.\n\n\n2010\n\n\n #Richards, J., Hardin, J., Grosfils, E. Weighted Model-Based Clustering for Remote Sensing Image Analysis, Computational Geosciences, 14: 125-136, 2010.\n\n\n \n2009\n\n\n Hardin, J., Wilson, J. A note on oligonucleotide expression values not being normally distributed, Biostatistics, 10: 446-450, 2009. (full manuscript at Supplementary Material to A note onoligonucleotide expression values not being normally distributed)\n\n\n \n2008\n\n\n #Yiu, G., #McCord, A., #Wise, A.,  #Jindal, R., #Hardee, J., #Kuo, A., #Yuen Shimogawa, M., Cahoon, L., Wu, M., Kloke, J., Hardin, J., Mays Hoopes, L.L.; Pathways Change in Expression During Replicative Aging in Saccharomyces cerevisiae, Journal of Gerontology, 63A: 21-34, 2008.\n\n\n \n2007\n\n\n Hardin, J., #Mitani, A., #Hicks, L., #VanKoten, B.; A Robust Measure of Correlation Between Two Genes on a Microarray, BMC Bioinformatics, 8:220, 2007. (R code: biwt.r)\n\n\nAdolph, S., Hardin, J.; Estimating Phenotypic Correlations: Correcting for Bias Due to Intraindividual Variability, Functional Ecology, 21: 178-184, 2007.\n\n\n \n2006\n\n\n #Wise, A., Hardin, J., Hoopes, L.; Yeast Through the Ages: a statistical analysis of genetic changes in aging yeast, Chance, 19, 39-44, 2006.\n\n\n Hardin, J., Hoopes, L., #Murphy, R.; Analyzing DNA Microarrays with Undergraduate Statisticians, Proceedings of the Seventh International Conference on Teaching Statistics, 2006.\n\n\n \n2005\n\n\n Altman, N., Banks, D., Hardwick, J., Roeder, K., Craigmile, P., Hardin, J., Gupta, M.  The IMS New Researchers’ Survival Guide, Institute of Mathematical Statistics; 2005.\n\n\n Hardin, J., Rocke, D.; The Distribution of Robust Distances, Journal of Computational and Graphical Statistics, 14: 1-19, 2005.  (R code: to estimate the MCD – mcd.est.r and to estimate c and m – cm.r.)\n\n\n Hardin, J.; Microarray Data from a Statistician’s Point of View, STATS, 42:4-13, 2005.\n\n\n \n2004\n\n\n Hardin, J., Waddell, M., Page, D., Zhan, F., Barlogie, B., Crowley, J., Shaughnessy, J.; Evaluation of Multiple Models to Distinguish Closely Related Forms of Disease Using DNA Microarray Data: an Application to Multiple Myeloma,  Statistical Applications in Genetics and Molecular Biology, 3 (article 10), 2004.\n\n\n Hardin, J., Rocke, D.;  Outlier Detection in the Multiple Cluster Setting Using the Minimum Covariance Determinant Estimator, Computational Statistics and Data Analysis, 44: 625-638, 2004.\n\n\n Pauler, D., Hardin, J., Faulkner, J., Leblanc, M., Crowley, J.; Survival Analysis with Gene Expression Arrays. In Handbook of Statistics 23: Advances in Survival Analysis, eds. N.Balakrishnan and C.R. Rao, Elsevier Science: Amsterdam; 2004.\n\n\n \n2002\n\n\n Durbin, B., Hardin, J., Hawkins, D., Rocke, D.;  A Variance-Stabilizing Transformation for Gene-Expression Microarray Data; Bioinformatics, 18: S105-S110, 2002.\n\n\n Zhan, F., Hardin, J., Kordsmeier, B., Bumm, K., Zheng, M., Tian, E., Sanderson, R., Yang, Y., Wilson, C., Zangari, M., Anaissie, E., Morris, C., Muwalla, F., van Rhee, F., Fassas, A., Crowley, J., Tricot, G., Barlogie, B., Shaughnessy, J.; Global Gene Expression Profiling of Multiple Myeloma, Monoclonal Gammopathy of Undetermined Significance, and Normal Bone Marrow Plasma Cells; Blood, 99: 1745-1757, 2002.\n\n\n \n1999-2000\n\n\n Hardin, J.; Multivariate Outlier Detection and Robust Clustering with Minimum Covariance Determinant Estimation and S-Estimation.  Ph.D. thesis, Statistics; University of California, Davis.  2000.\n\n\n Coleman, D., Dong, X., Hardin, J., Rocke, D.M., Woodruff, D.L.; Some Computational Issues in Cluster Analysis with no à priori Metric; Computational Statistics and Data Analysis, 31: 1-11, 1999."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "research projects",
    "section": "",
    "text": "Art by Federica Domecq Lacroze\n\n\nOne of the best things about being a statistician is the many different subject areas to pursue. My research projects are posted, but if you have time, it’s really my students’ research projects that are worth investigating. I highly recommend working with undergraduates on research as it is among the most fun and rewarding parts of my day.\nMy areas of expertise include statistical analysis of high-throughput genetic data which don’t conform to technical conditions in standard methods. I work on problems of normalizing data structures, clustering and classifying time course profiles, and creating metrics to measure a variety of signals. I chose to become a statistician because of the myriad potential collaborations across many fields. I have worked with medical doctors, biologists, geologists, and physicists in my research.\nAnother area of my research focuses on the statistics and data science undergraduate curriculum – making it more modern and more accessible. Through new ventures into data science (both research and teaching), I am currently exploring ways that today’s extensive data (both in scale and in occurrence) are shaping science and the world around us.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npapers + projects\n\n\nso many fun projects, so little time\n\n\nA collection of research papers, many of which were done primarily by undergraduate collaborators.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresearch interests\n\n\n\n\n\nso many fun problems, so little time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudent work\n\n\nnice job everyone!\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blogs/2021-06-27-ims/index.html",
    "href": "blogs/2021-06-27-ims/index.html",
    "title": "Introduction to Modern Statistics",
    "section": "",
    "text": "Super excited to share the news that Mine Çetinkaya-Rundel and I have finished and published Introduction to Modern Statistics, made possible by @openintroorg.\n\n\n\nWhile we personally love the html version, you can also get the book in pdf or paperback.\nOne new aspect of the book is a focus on computational methods, presented in parallel to mathematical models. We wrote about the approach here.\nBut there are so many other fun things about the book… including emphasis on multivariable relationships through data visualization and modeling, case studies, and compelling datasets and examples.\nWe’ve organized the book into six parts: 1. Intro to data, 2. EDA, 3. regression modeling, 4. foundations of inference, 5. statistical inference, and 6. inferential modeling.\nThe R Tutorials are written using the learnr package with much of the work due to @baumerben, Andrew Bray, @yabellini, @cantoflor_87, @data_datum.\nThe R Labs have been recently updated, thanks much to @benjamin_feder.\nThere are a total of 339 exercises. Answers to the odd questions are at the end of the text, and solutions are available for instructors.\nWe are extremely appreciative to @MT_statistics, Melinda Yager, and Randy Prium for their valuable feedback and review of the book.\nIMS builds on the @openintroorg text: Introduction to Statistics with Randomization and Simulation, written with David Diez and Christopher Barr.\nWhile we know that there is still work to do, we’ve added a first pass of alternative text tags to the diagrams in the html version of the text.\nThe book uses many of the OpenIntro datasets. The OpenIntro package has recently been updated on CRAN.\nThe book aligns with many of the OpenIntro education resources.\n\n\n\nThe source code for the text of the book is available on GitHub.\nWhile the Labs and Tutorials are written in the statistical software R, the text itself is software agnostic and can be used with your favorite classroom statistical software.\nFor their amazing art and creative vision, we are indebted to Meenal Patel, @iowio, Muge Cetinkaya, and Will Gray.\nThanks @rundel for the many ways you’ve supported the project.\nShout out to #rstats and RStudio (er, posit) for making amazing products on which our work is based.\nAnd last, thanks to @minebocek for writing my favorite exercise of the text:\n\n\n\nWe hope you enjoy using the text as much as we’ve enjoyed writing it. Have fun!"
  },
  {
    "objectID": "blogs/2022-07-31-dear-diary-solitude/index.html",
    "href": "blogs/2022-07-31-dear-diary-solitude/index.html",
    "title": "Dear Data - Solitude",
    "section": "",
    "text": "In Spring / Summer 2022, the Benton Museum of Art at Pomona College set out to create a unique way to display the permanent collection.\n\nIn Here: Solitude through the Benton Museum of Art at Pomona College is an interdisciplinary creative project, culminating in a book that showcases the imagination and talents of the Pomona College community. Structured as an encyclopedia/abecedarium, the collection consists of meditations on the concept of solitude, all based in the art collection of the College and written by students, faculty, administrators, and museum staff and interns. Fresh, synthetic, and provocative, In Here is a thoughtful reflection through art on the past few years and an exploration of an ancient topic recast in contemporary terms.\n\nI was asked to participate by creating an entry which focuses on something that I do in solitude. I chose data collection / data analysis, i.e., data. The presentation of the collection and analysis is inspired by a project and book called Dear Data by Giorgia Lupi and Stefanie Posavec."
  },
  {
    "objectID": "blogs/2022-07-31-dear-diary-solitude/index.html#motivation",
    "href": "blogs/2022-07-31-dear-diary-solitude/index.html#motivation",
    "title": "Dear Data - Solitude",
    "section": "",
    "text": "In Spring / Summer 2022, the Benton Museum of Art at Pomona College set out to create a unique way to display the permanent collection.\n\nIn Here: Solitude through the Benton Museum of Art at Pomona College is an interdisciplinary creative project, culminating in a book that showcases the imagination and talents of the Pomona College community. Structured as an encyclopedia/abecedarium, the collection consists of meditations on the concept of solitude, all based in the art collection of the College and written by students, faculty, administrators, and museum staff and interns. Fresh, synthetic, and provocative, In Here is a thoughtful reflection through art on the past few years and an exploration of an ancient topic recast in contemporary terms.\n\nI was asked to participate by creating an entry which focuses on something that I do in solitude. I chose data collection / data analysis, i.e., data. The presentation of the collection and analysis is inspired by a project and book called Dear Data by Giorgia Lupi and Stefanie Posavec."
  },
  {
    "objectID": "blogs/2022-07-31-dear-diary-solitude/index.html#process",
    "href": "blogs/2022-07-31-dear-diary-solitude/index.html#process",
    "title": "Dear Data - Solitude",
    "section": "Process",
    "text": "Process\nI spent a few hours at the Benton collecting data on two of the current exhibits, Known & Understood and Each Day Begins with the Sun Rising. I collected many variables, but the ones recorded here and displayed below include:\n\n\n\n\n\n\n\n\nvariable\ntype\ndescription\n\n\n\n\ntitle-ish\ncharacter\nmostly the title, but sometimes a description if I didn’t remember to write down the title\n\n\nyear\nnumeric\nmostly the year, but a midpoint if the year was a range or a guess if the year was approximate\n\n\njo\ncharacter\nwhether I loved it, liked it, thought it was okay, or didn’t get it\n\n\nnature\ncharacter\neither outside, a natural setting (e.g., a movie theater), or something abstract\n\n\nsize\nnumeric\n1 = about a 3rd of a museum wall; I scaled the piece size on a range from 0.2 to 5\n\n\npeople\ncharacter\nwhether or not there were people represented in the piece\n\n\nmedium\ncharacter\nthe art medium, mostly taken from the description, but some that I made up\n\n\ncolor\ncharacter\nthe colors in the object, either: black & white, muted colors, or bright colors"
  },
  {
    "objectID": "blogs/2022-07-31-dear-diary-solitude/index.html#results",
    "href": "blogs/2022-07-31-dear-diary-solitude/index.html#results",
    "title": "Dear Data - Solitude",
    "section": "Results",
    "text": "Results\n\n\n\n\n\nEach rectangle represents a single art piece; the size of the rectangle is based on the piece’s actual size relative to a museum wall. The artistic medium that was used on the piece is written in each rectangle; the year of the piece is given by color shade. The pieces are broken down into two additional categorizations: first they are blocked into the four categories of my reaction to each one; second, they are grouped (solid black lines) into pieces that share a coloring scheme. The data graphic uses a specific set of rules to draw rectangles which are proportional to the piece’s real life size while also arranging the pieces into creating color groups. You might notice that some of the categories are difficult to read, which is unfortunate, but true to the algorithm used to create the data visualization.\nOne might notice that I don’t really love older pieces."
  },
  {
    "objectID": "blogs/2021-07-18-rr-and-or/index.html",
    "href": "blogs/2021-07-18-rr-and-or/index.html",
    "title": "Relative Risk and Odds Ratios",
    "section": "",
    "text": "There are many good reasons to choose a case control study as the experimental design. Most notably, in many scenarios, cases are somewhat difficult to come by, and if observations are determined by treatment / control (i.e., a cohort study) then the study can end up with too few cases observed for any type of conclusion (i.e., the study will be under-powered). See recent case-control studies here and here and here.\nHowever, when teaching about case-control studies, it is paramount to include a thorough dive into odds ratios and the need to use odds ratios (instead of relative risk or differences in proportions) to summarize case-control studies. There are many good resources for learning about case-control studies (e.g., here and here and here and here and here), but many of the ideas below come from the excellent introductory statistics textbook, Introduction to Statistical Concepts, Applications, and Methods by Chance and Rossman."
  },
  {
    "objectID": "blogs/2021-07-18-rr-and-or/index.html#introduction",
    "href": "blogs/2021-07-18-rr-and-or/index.html#introduction",
    "title": "Relative Risk and Odds Ratios",
    "section": "",
    "text": "There are many good reasons to choose a case control study as the experimental design. Most notably, in many scenarios, cases are somewhat difficult to come by, and if observations are determined by treatment / control (i.e., a cohort study) then the study can end up with too few cases observed for any type of conclusion (i.e., the study will be under-powered). See recent case-control studies here and here and here.\nHowever, when teaching about case-control studies, it is paramount to include a thorough dive into odds ratios and the need to use odds ratios (instead of relative risk or differences in proportions) to summarize case-control studies. There are many good resources for learning about case-control studies (e.g., here and here and here and here and here), but many of the ideas below come from the excellent introductory statistics textbook, Introduction to Statistical Concepts, Applications, and Methods by Chance and Rossman."
  },
  {
    "objectID": "blogs/2021-07-18-rr-and-or/index.html#definitions",
    "href": "blogs/2021-07-18-rr-and-or/index.html#definitions",
    "title": "Relative Risk and Odds Ratios",
    "section": "Definitions",
    "text": "Definitions\nA case-control study is one in which the observational units are selected in such a way that there are a set number of cases and a set number of controls. (As compared with a cohort study where the observational units are selected in such a way that there are a set number in treatment group 1 and a set number in treatment group 2.)\n\nTypes of Studies\n\nExplanatory variable is one that is a potential explanation for any changes in the response variable.\nResponse variable is the measured outcome of interest.\nCase-control study: identify observational units by response (i.e., case or control).\nCohort study: identify observational units by explanatory variable (i.e., treatment or placebo).\nCross-classification study: identify observational units regardless of levels of the variable.\n\n\n\nRelative Risk\nThe relative risk (RR) is the ratio of risks for each group. We say, “The risk of success is RR times for those in group 1 as compared to those in group 2.”\n\\[\n\\begin{aligned}\n\\mbox{relative risk} &= \\frac{\\mbox{risk group 1}}{\\mbox{risk group 2}}\\\\\n&=  \\frac{\\mbox{proportion of successes in group 1}}{\\mbox{proportion of successes in group 2}}\\\\\n\\mbox{RR} &= \\frac{p_1}{p_2} = \\frac{p_1}{p_2}\\\\\n\\hat{\\mbox{RR}} &= \\frac{\\hat{p}_1}{\\hat{p}_2}\n\\end{aligned}\n\\]\n\n\nOdds Ratio\nA related concept to risk is odds. It is often used in horse racing, where “success” is typically defined as losing. So, if the odds are 3 to 1 we would expect to lose 3/4 of the time. The odds ratio (OR) is the ratio of odds for each group. We say, “The odds of success is OR times for those in group 1 as compared to those group 2.”\n\\[\\begin{eqnarray*}\n\\mbox{odds} &=& \\frac{\\mbox{proportion of successes}}{\\mbox{proportion of failures}}\\\\\n&=& \\frac{\\mbox{number of successes}}{\\mbox{number of failures}} = \\theta\\\\\n\\hat{\\mbox{odds}} &=& \\hat{\\theta}\\\\\n\\mbox{odds ratio} &=& \\frac{\\mbox{odds group 1}}{\\mbox{odds group 2}} \\\\\n\\mbox{OR} &=& \\frac{\\theta_1}{\\theta_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}= \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\\\\n\\hat{\\mbox{OR}} &=& \\frac{\\hat{\\theta}_1}{\\hat{\\theta}_2} = \\frac{\\hat{p}_1/(1-\\hat{p}_1)}{\\hat{p}_2/(1-\\hat{p}_2)}\\\\\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "blogs/2021-07-18-rr-and-or/index.html#are-odds-difficult-to-understand",
    "href": "blogs/2021-07-18-rr-and-or/index.html#are-odds-difficult-to-understand",
    "title": "Relative Risk and Odds Ratios",
    "section": "Are odds difficult to understand?",
    "text": "Are odds difficult to understand?\nIf you, like me, grew up in a world of proportions and percentages, the first time you encounter odds, it might seem like an odd statistic. However, I’d like to argue that, fundamentally, the idea of odds is no different from the idea of risk (or proportion). The cognitive difficulty in remembering and communicating about odds comes with the fact that we’ve wired our brains so completely to think primarily about proportions.\nBut what if you had grown up thinking about odds? What if you had had a placement at your kitchen table describing the odds of an event (instead of the proportion of the event)? You might find that the odds are actually easier to interpret than a proportion.\nI posit that if you (or your students) had grown up with a kitchen table placemat as seen in Figure 2, you would find risk to be the odd concept and odds to be the intuitive idea.\n\n\n\n\n\nFigure 1: A child’s kitchen placemat designed to teach proportions, often called risk in medical studies.\n\n\n\n\n\n\n\n\n\nFigure 2: An alternative child’s kitchen placemat designed to teach odds."
  },
  {
    "objectID": "blogs/2021-07-18-rr-and-or/index.html#can-we-force-the-rr-to-be-anything-we-want",
    "href": "blogs/2021-07-18-rr-and-or/index.html#can-we-force-the-rr-to-be-anything-we-want",
    "title": "Relative Risk and Odds Ratios",
    "section": "Can we force the RR to be anything we want?",
    "text": "Can we force the RR to be anything we want?\nThe motivation for writing this blog entry came from the Shiny App below. It takes a little bit of thinking, but hopefully we can see that if we select observational units based on cases and controls, the individual risk (per treatment group) is not measurable. Why? Well, if we just keep selecting more cases, the risk in each group will keep going up! (Note: by selecting more cases, the odds will also keep going up.)\nWhat about relative risk and odds ratios? It turns out that with the case-control experimental design the calculation of the relative risk depends on which variable is explanatory and which variable is response. HOWEVER, the calculation of the odds ratio does not depend on which variable is explanatory and which variable is response.\nConclusion Regardless of how many cases or controls are sampled, the odds ratio calculated from data in a case control-study is a good estimate of the population odds ratio."
  },
  {
    "objectID": "blogs/2021-07-18-rr-and-or/index.html#more-thoughts-on-rr-and-or",
    "href": "blogs/2021-07-18-rr-and-or/index.html#more-thoughts-on-rr-and-or",
    "title": "Relative Risk and Odds Ratios",
    "section": "More thoughts on RR and OR",
    "text": "More thoughts on RR and OR\n\nOdds Ratios are hard to interpret\nAfter an odds ratio (of XXX) has been calculated, the correct interpretation is that the odds of success for group 1 are XXX times the odds of success for group 2. There might be a tendency to say that the probability of success (or risk of success) in group 1 are XXX times that of group 2. But remember, risk and odds are different numbers (see Figure 1 and Figure 2), so odds ratios and relative risk measure quotients of different things.\n\n\nCan you explain that calculation part one more time?\nExample taken from Introduction to Statistical Concepts, Applications, and Methods by Chance and Rossman.\nLet’s say we have a population of 1,000,000 people:\n\n\n\n\ncancer\nhealthy\n\n\n\n\n\nlight smoking\n49,000\n51,000\n100,000\n\n\nno smoking\n1,000\n899,000\n900,000\n\n\n\n50,000\n950,000\n1,000,000\n\n\n\n\\[\\begin{eqnarray*}\nP(\\mbox{light} | \\mbox{lung cancer}) &=& \\frac{49,000}{50,000} = 0.98\\\\\nP(\\mbox{lung cancer} | \\mbox{light}) &=& \\frac{49,000}{100,000} = 0.49\\\\\n\\end{eqnarray*}\\]\n\n\n\nGroup A\nGroup B\n\n\n\n\nexpl = smoking status\nexpl = lung cancer\n\n\nresp = lung cancer\nresp = smoking status\n\n\n\n\nGroup A: Calculate the relative risk and odds ratio under the setting that lung cancer is considered a success and no smoking is baseline:\n\n\\[\\begin{eqnarray*}\nRR &=& \\frac{49/100}{1/900} = 441\\\\\nOR &=& \\frac{49/51}{1/899} = 863.75\\\\\n\\end{eqnarray*}\\]\n\nGroup B: Calculate the relative risk and odds ratio under the setting that light smoking is considered a success and healthy is baseline:\n\n\\[\\begin{eqnarray*}\nRR &=& \\frac{49/50}{51/950} = 18.25\\\\\nOR &=& \\frac{49/1}{51/899} = 863.75\\\\\n\\end{eqnarray*}\\]\nOR is the same no matter which variable you choose as explanatory versus response!\n\n\nAre OR and RR ever numerically similar / equivalent?\nIf \\(p_1\\) and \\(p_2\\) are both very small, then \\[1-p_1 \\approx 1- p_2 \\approx 1\\] which gives:\n\\[RR = \\frac{p_1}{p_2} \\approx \\frac{p_1 / (1 - p_1)}{p_2/(1-p_2)} = OR.\\]\nIn situations of extremely rare diseases (and case-control studies), it makes sense to calculate the odds ratio and interpret the number as if it was relative risk.\n\n\nOR is always more extreme than RR\nWithout loss of generality, assume the true \\(RR &gt; 1\\), implying \\(p_1 / p_2 &gt; 1\\) and \\(p_1 &gt; p_2\\).\nNote the following sequence of consequences:\n\\[\\begin{eqnarray*}\nRR = \\frac{p_1}{p_2} &&gt;& 1\\\\\n\\frac{1 - p_1}{1 - p_2} &&lt;& 1\\\\\n\\frac{ 1 / (1 - p_1)}{1 / (1 - p_2)} &&gt;& 1\\\\\n\\frac{p_1}{p_2} \\cdot \\frac{ 1 / (1 - p_1)}{1 / (1 - p_2)} &&gt;& \\frac{p_1}{p_2}\\\\\nOR &&gt;& RR\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "form/contact.html",
    "href": "form/contact.html",
    "title": "Contact",
    "section": "",
    "text": "** Contact page don’t contain a body, just the front matter above. See form.html in the layouts folder **"
  },
  {
    "objectID": "projects/dei/index.html",
    "href": "projects/dei/index.html",
    "title": "Equity and Flourishing",
    "section": "",
    "text": "I believe that DEI work takes all of us contributing in myriad ways. One of the things I’ve realized recently is that there isn’t a magic bullet or a single effort which will ameliorate the centuries of problematic structures which have been created. I don’t pretend to have the answers. But I do continue to work hard to create environments where more and more of us feel welcome and heard. Below I’ve listed current activities, most of which I am very actively engaged. A few represent programs I work with peripherally and/or support students attending."
  },
  {
    "objectID": "projects/dei/index.html#department-of-mathematics-statistics",
    "href": "projects/dei/index.html#department-of-mathematics-statistics",
    "title": "Equity and Flourishing",
    "section": "Department of Mathematics & Statistics",
    "text": "Department of Mathematics & Statistics\nAs a department, we are involved in many fabulous programs.\n\nPomona Scholars of Mathematics (PSM) - PSM is a cohort program targeted at first year students who are interested in studying math or related disciplines (e.g., computer science, statistics, physics). Intensive one-on-one faculty-student advising, weekly group lunch meetings, and within-course clusters help the group build cohesion and navigate their first year on campus.\nLearning Communities (LiCMATH) - A learning community is a small group of students who are all enrolled in one particular class. They commit to work together and to support each other throughout the semester. A learning community is meant to become a supportive and safe space to work on homework problems, to discuss the lectures, and to bounce ideas off each other. The meetings take place outside of class times, and, at least initially, under the supervision of an upper class undergraduate student mentor.\nPomona Academy of Youth Success (PAYS) - PAYS is a Pomona College summer academic program for high school students. Each four week session is intensely academic, and its core consists of each cohort taking two classes that are taught by regular college faculty: a math class and a humanities/social sciences class. Afternoons are focused on working collaboratively on homework, workshops on college application processes, and enrichment activities. The faculty are aided by a group of dedicated undergraduate students who serve as teaching assistants to the faculty and as mentors to the students.\nAssociation for Women in Mathematics (AWM) Student Chapter - AWM is a professional organization designed to support women in mathematics. Our local chapter provides space for our students to flourish and feel supported.\nEnhancing Diversity in Graduate Education (EDGE) - EDGE is a summer program for women entering graduate school. Hosted regularly in Claremont with many of our faculty involved, the program balances academic rigor and intersectional support.\n\nMathematicians of the African Diaspora (MAD) - The MAD pages highlight work done by mathematicians who are members of the African diaspora. Working the comprehensively collect information, the pages are continually updated.\n\nPomona Research in Mathematics Experience (PRiME) - PRiME is an eight week intensive summer research experience in pure mathematics."
  },
  {
    "objectID": "projects/dei/index.html#pomona-college",
    "href": "projects/dei/index.html#pomona-college",
    "title": "Equity and Flourishing",
    "section": "Pomona College",
    "text": "Pomona College\n\nInclusive Excellence Committee\n\n\nThe mission of the Inclusive Excellence Committee will be to advance the practice of inclusive excellence at Pomona College. The Institute will achieve this mission through faculty professional development in inclusive teaching and mentorship, and through research that informs decision making and drives institutional change to further equity initiatives at the College.\n\n\nPhi Beta Kappa at Pomona College was recently recognized for diversity and inclusion efforts."
  },
  {
    "objectID": "projects/dei/index.html#professional-outreach",
    "href": "projects/dei/index.html#professional-outreach",
    "title": "Equity and Flourishing",
    "section": "Professional Outreach",
    "text": "Professional Outreach\n\nThe American Statistical Association has recently put together an outreach group focused on Justice, Equity, Diversity, and Inclusion. Read about the JEDI work here and follow us on  twitter.\nStatFest is a one-day conference focused on encouraging undergraduate students who are traditionally underrepresented in statistics to consider careers and graduate school in statistics. In 2018, Pomona College hosted a satellite StatFest program.\nIn 2021, the Association for Women in Mathematics launched its flagship journal, La Matematica. As an associate editor, I work to provide constructive and timely reviews with healthy feedback to the authors."
  },
  {
    "objectID": "projects/CURV/index.html",
    "href": "projects/CURV/index.html",
    "title": "CURV",
    "section": "",
    "text": "CURV is a project designed to connect statisticians and data scientists to undergraduate curricula. Amplifying voices which are often marginalized helps all of us to build a larger community of scholars inclusive of every voice.\nIn particular, one of the major goals of the database is to lower the barrier to presenting examples of all types of scholars to our students. You might use the database with a “Statistician of the Day” activity. Or you might have students bring into the classroom one idea connecting a scholar to the class content.\nSee the CURV blog entry for motivation and use in your classroom.\n\nContribute? Yes, please!\nCertainly, if you are here, then you have ideas which could be added to make the CURV resource even better. Feel free to peruse the CURV GitHub repo. I welcome pull requests, or create an issue and I’ll incorporate your suggestions directly into the database. Thank you in advance!"
  },
  {
    "objectID": "projects/IMS/index.html#introduction-to-modern-statistics",
    "href": "projects/IMS/index.html#introduction-to-modern-statistics",
    "title": "IMS",
    "section": "Introduction to Modern Statistics",
    "text": "Introduction to Modern Statistics\nIntroduction to Modern Statistics is now out! See the web version at https://openintro.org/book/ims/online and information on how to find the PDF and paperback versions at https://openintro.org/book/ims/.\nIntroduction to Modern Statistics puts a heavy emphasis on exploratory data analysis (specifically exploring multivariate relationships using visualization, summarization, and descriptive models) and provides a thorough discussion of simulation-based inference using randomization and bootstrapping, followed by a presentation of the related Central Limit Theorem based approaches.\nA few more highlights from the book include:\n\nEmphasis on multivariable relationships, particularly using data visualization.\nEarly introduction to descriptive models and a second look at models for inference and model validation.\nA case study accompanying each part.\nInteractive R tutorials and R labs presented alongside the related content.\nCompelling exploratory data analysis of relevant datasets and with modern visualizations.\n\nThe text is suitable for use in introductory statistics and data science courses as well as an upper-level course that dives deeper into comparisons among computational and mathematical methods presented in the book.\nYou can read more about our motivation and vision for the book at https://www.openintro.org/blog/article/2021-06-27-computational-and-mathematical-models-in-introductory-statistics/.\nThanks go to many people who made the book possible:\n\nDavid Diez & Christopher Barr who contributed to the previous incarnation, Introduction to Statistics through Randomization and Simulation,\nBen Baumer, Andrew Bray, Yanina Bellini Saibene, Florencia D’Andrea, and Roxana Noelia Villafañe for work on the R tutorials,\nBen Feder for updates to the R labs,\nMeenal Patel and Müge Çetinkaya for their creativity and design work,\nWill Gray for the fantastic visuals,\nAllison Theobold, Melinda Yager, and Randy Prium for their valuable feedback and review of the book,\nColin Rundel for technical and non-technical support along the way,\nChristophe Dervieux for help with multi-output R Markdown."
  },
  {
    "objectID": "about/main/index.html",
    "href": "about/main/index.html",
    "title": "Jo Hardin",
    "section": "",
    "text": "** index doesn’t contain a body, just front matter above. See about/list.html in the layouts folder **"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "projects",
    "section": "",
    "text": "CURV\n\n\na database of scholars to highlight in the classroom\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEquity and Flourishing\n\n\na collection of resources relating to diversity, equity, and inclusion initiatives\n\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIMS\n\n\na free, open-source, online textbook for introductory statistics with an emphasis on simulation based approaches\n\n\n\nMine Çentinkaya-Rundel and Jo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJEDI-CAUSE website\n\n\nresources for Justice, Equity, Diversity, and Inclusion (JEDI) infused teaching.\n\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeach Data Science\n\n\na data science blog - 2019 & 2020\n\n\n\nHunter Glanz, Jo Hardin, and Nick Horton\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday adventures\n\n\na collection of TidyTuesday plots and models\n\n\n\nJo Hardin\n\n\n\n\n\n\n\n\n\n\n\n\nresearch interests\n\n\nso many fun problems, so little time\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "Hi and welcome to my site!\nSince 2002, I have been at Pomona College where I teach lots of different kinds of statistics, taught a little bit of math once, love teaching writing with statistics, and hope to soon teach some data science.\n\nBackground\n\nMy undergraduate degree in Mathematics is also from Pomona College, where I worked with Don Bentley. I did my PhD in Statistics at UC Davis with David Rocke. I was interviewed (August 2020) for Pomona College’s Sagecast where you can hear me talk about my path.\n\nHere to learn?\n\nMe too! So many good things to learn. I’ve posted all of my course materials freely, and I hope they give you inspiration either as a teacher or a student. I’ve also written an OpenIntro  textbook with the fantastic Mine Çentinkaya-Rundel. Introduction to Modern Statistics focuses on computational inference and multivariable modeling & visualizing, and it is available for free online.\n\nInterested in my research?\n\nOne of the best things about being a statistician is the many different subject areas to pursue. My research projects are posted, but if you have time, it’s really my students’ research projects that are worth investigating. I highly recommend working with undergraduates on research as it is among the most fun and rewarding parts of my day.\nMy areas of expertise include statistical analysis of high-throughput genetic data which don’t conform to technical conditions in standard methods. I work on problems of normalizing data structures, clustering and classifying time course profiles, and creating metrics to measure a variety of signals. I chose to become a statistician because of the myriad potential collaborations across many fields. I have worked with medical doctors, biologists, geologists, and physicists in my research.\nAnother area of my research focuses on the statistics and data science undergraduate curriculum – making it more modern and more accessible. Through new ventures into data science (both research and teaching), I am currently exploring ways that today’s extensive data (both in scale and in occurrence) are shaping science and the world around us.\n\nWant to know what I’m up to?\n\nBeyond teaching and research, I am fortunate to be able to fit in a few hours here and there on some of my passion projects. Almost every Tuesday, I wrangle a bit of TidyTuesday data. I’m also compiling a list of scholars who are traditionally underrepresented in the statistics and data science curriculum. Feel free to use the list for your own “scholar of the day” classroom activity. And please submit a pull request or a GitHub issue if you have names to add to the database!"
  },
  {
    "objectID": "courses/M158-linmodels/index.html",
    "href": "courses/M158-linmodels/index.html",
    "title": "Math 158: Linear Models",
    "section": "",
    "text": "Art by @allison_horst\n\n\nLinear Models is a second course in statistics that builds on introductory statistics using mathematical tools (including calculus and linear algebra). The simple linear regression model will be expanded to multiple linear regression which will see an in-depth analysis. We will investigate the impact of residuals, and we will use graphical tools to enhance both understanding and communication of the models. For data with many explanatory variables, we will use ridge regression and Lasso for predictive modeling. The statistical software R will be used for all analyses, homework, and projects. Focus will be on understanding the methods and interpreting results; we will discuss good modeling practices, ideas of which extend beyond linear models to any types of inference or prediction."
  },
  {
    "objectID": "courses/M158-linmodels/index.html#the-course",
    "href": "courses/M158-linmodels/index.html#the-course",
    "title": "Math 158: Linear Models",
    "section": "",
    "text": "Art by @allison_horst\n\n\nLinear Models is a second course in statistics that builds on introductory statistics using mathematical tools (including calculus and linear algebra). The simple linear regression model will be expanded to multiple linear regression which will see an in-depth analysis. We will investigate the impact of residuals, and we will use graphical tools to enhance both understanding and communication of the models. For data with many explanatory variables, we will use ridge regression and Lasso for predictive modeling. The statistical software R will be used for all analyses, homework, and projects. Focus will be on understanding the methods and interpreting results; we will discuss good modeling practices, ideas of which extend beyond linear models to any types of inference or prediction."
  },
  {
    "objectID": "courses/M158-linmodels/index.html#student-learning-outcomes.",
    "href": "courses/M158-linmodels/index.html#student-learning-outcomes.",
    "title": "Math 158: Linear Models",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the semester, students will be able to do the following:\n\nunderstand the structure of a linear model, including: simple linear regression, multiple linear regression, ridge regression, Lasso, and splines.\nknow when a linear model is appropriate and what conclusions can be drawn given a particular dataset, including: when are p-values appropriate to use? when is prediction more appropriate? when can or cannot causation be implied?\nuse graphical tools to investigate models associated with the data at hand, including: exploring data graphically, using graphics to understand leverage and influence values, visualizing smooth models.\ncommunicate results effectively."
  },
  {
    "objectID": "courses/M158-linmodels/index.html#course-website",
    "href": "courses/M158-linmodels/index.html#course-website",
    "title": "Math 158: Linear Models",
    "section": "Course website",
    "text": "Course website\nLinear Models was last taught in Spring 2022, materials can be found on the course website."
  },
  {
    "objectID": "courses/M152-stattheory/index.html",
    "href": "courses/M152-stattheory/index.html",
    "title": "Math 152: Statistical Theory",
    "section": "",
    "text": "Art by @allison_horst\n\n\nStatistical Theory is an introduction to statistics for students with a background in probability theory, calculus, and linear algebra. There is no statistics prerequisite for this class. The course will be focused on the theoretical aspects of the material, though there will be some real world applications in class and in the homework assignments. The idea is to have a strong mathematical understanding of the concepts while also understanding how the concepts are applied in the real world."
  },
  {
    "objectID": "courses/M152-stattheory/index.html#the-course",
    "href": "courses/M152-stattheory/index.html#the-course",
    "title": "Math 152: Statistical Theory",
    "section": "",
    "text": "Art by @allison_horst\n\n\nStatistical Theory is an introduction to statistics for students with a background in probability theory, calculus, and linear algebra. There is no statistics prerequisite for this class. The course will be focused on the theoretical aspects of the material, though there will be some real world applications in class and in the homework assignments. The idea is to have a strong mathematical understanding of the concepts while also understanding how the concepts are applied in the real world."
  },
  {
    "objectID": "courses/M152-stattheory/index.html#student-learning-outcomes.",
    "href": "courses/M152-stattheory/index.html#student-learning-outcomes.",
    "title": "Math 152: Statistical Theory",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nAt the completion of this course, students will:\n\nbe able to derive the methods from introductory statistics using tools from mathematics (i.e., calculus and probability).\nbe able to justify the use of a particular method (technical conditions).\nbe able to weigh advantages and disadvantages of different estimation techniques (e.g., bias, variability, resistance to outliers).\nknow to and how to communicate results effectively."
  },
  {
    "objectID": "courses/M152-stattheory/index.html#course-website",
    "href": "courses/M152-stattheory/index.html#course-website",
    "title": "Math 152: Statistical Theory",
    "section": "Course website",
    "text": "Course website\nStatistical Theory was last taught in Fall 2022, materials can be found on the course website."
  },
  {
    "objectID": "courses/M57-thinkingdata/index.html",
    "href": "courses/M57-thinkingdata/index.html",
    "title": "Math 057: Thinking with Data",
    "section": "",
    "text": "Art by @allison_horst\n\n\nThinking with Data is a course designed to help you understand statistical reasoning. The emphasis will be on statistical thinking – how to reason through the numbers you see in the media, in advertising, associated with medical claims, and from other sources. The applications of statistics to real-world problems go beyond using formulas on a dataset. Statisticians become involved in research problems at the initial stages of formulating the research hypotheses to be addressed and continue their involvement through the design and presentation of the results. This course exposes the student to the complete spectrum of activities in which a statistician is involved. Many topics from introductory statistics will be covered including conditional probability, sampling, hypothesis testing, and ethical reporting. Each topic will be contextualized within a context of interest where we see how data, analyses, and statistics generally can have large impacts on real lives. After taking Thinking with Data, you will, hopefully, encounter numbers much differently."
  },
  {
    "objectID": "courses/M57-thinkingdata/index.html#the-course",
    "href": "courses/M57-thinkingdata/index.html#the-course",
    "title": "Math 057: Thinking with Data",
    "section": "",
    "text": "Art by @allison_horst\n\n\nThinking with Data is a course designed to help you understand statistical reasoning. The emphasis will be on statistical thinking – how to reason through the numbers you see in the media, in advertising, associated with medical claims, and from other sources. The applications of statistics to real-world problems go beyond using formulas on a dataset. Statisticians become involved in research problems at the initial stages of formulating the research hypotheses to be addressed and continue their involvement through the design and presentation of the results. This course exposes the student to the complete spectrum of activities in which a statistician is involved. Many topics from introductory statistics will be covered including conditional probability, sampling, hypothesis testing, and ethical reporting. Each topic will be contextualized within a context of interest where we see how data, analyses, and statistics generally can have large impacts on real lives. After taking Thinking with Data, you will, hopefully, encounter numbers much differently."
  },
  {
    "objectID": "courses/M57-thinkingdata/index.html#student-learning-outcomes.",
    "href": "courses/M57-thinkingdata/index.html#student-learning-outcomes.",
    "title": "Math 057: Thinking with Data",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nthe goal of the course is for students to learn to critically evaluate numbers and related claims that are presented to them. To meet the goal, students will demonstrate their ability to achieve the following objectives:\n\nGiven a report on a set of data, identify the population from which the data were collected and whether the sampling frame is the same as the population of interest.\nIdentify whether a study is experimental or observational. List possible confounding variables and alternative causal mechanisms.\nDescribe aspects of a graph which are informative and those which are misleading.\nCharacterize different psychological aspects of probability estimation, and identify when those aspects are being used in reporting.\nArticulate different ethical aspects of the data collection, modeling, or reporting from a given data analysis."
  },
  {
    "objectID": "courses/M57-thinkingdata/index.html#course-website",
    "href": "courses/M57-thinkingdata/index.html#course-website",
    "title": "Math 057: Thinking with Data",
    "section": "Course website",
    "text": "Course website\nThinking with Data was last taught in Fall 2022, materials can be found on the course website."
  },
  {
    "objectID": "courses/ID1-statsworld/index.html",
    "href": "courses/ID1-statsworld/index.html",
    "title": "ID1: Statistics in the World",
    "section": "",
    "text": "Art by @allison_horst\n\n\nThe main idea behind this course is to get the participants (that’s you) to leave in December questioning every number you come across: in the media, at sporting events, when researching for another class, when carrying out your own research, etc. Certainly there are some good numbers out there, but I hope that you will start asking yourself questions like “where did that come from?”, “what if you looked at it from another angle?”, “what if we knew the rest of the information/data?” We’ll look at sources that range from journalism to scholarly writing to fiction, and we’ll see how statistics are used and misused. As in many ID1 courses, the goal is for you to become critical inquirers."
  },
  {
    "objectID": "courses/ID1-statsworld/index.html#the-course",
    "href": "courses/ID1-statsworld/index.html#the-course",
    "title": "ID1: Statistics in the World",
    "section": "",
    "text": "Art by @allison_horst\n\n\nThe main idea behind this course is to get the participants (that’s you) to leave in December questioning every number you come across: in the media, at sporting events, when researching for another class, when carrying out your own research, etc. Certainly there are some good numbers out there, but I hope that you will start asking yourself questions like “where did that come from?”, “what if you looked at it from another angle?”, “what if we knew the rest of the information/data?” We’ll look at sources that range from journalism to scholarly writing to fiction, and we’ll see how statistics are used and misused. As in many ID1 courses, the goal is for you to become critical inquirers."
  },
  {
    "objectID": "courses/ID1-statsworld/index.html#student-learning-outcomes.",
    "href": "courses/ID1-statsworld/index.html#student-learning-outcomes.",
    "title": "ID1: Statistics in the World",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the semester, students will be able to:\n\ndescribe the inherent and natural variability in the world around them.\nargue thoughtfully that models produce information about trends and not individuals.\narticulate the ways in which data are hard to collect (bias, opinions change, genetic info, sparse availability,…).\ncombine current and historical documents to understand some of the negative impacts on society due to the statistical sciences.\nidentify ways in which graphs are effectively and ineffectively used to communicate.\nunderstand the writing process and know of concrete ways they can improve as writers.\naccess various resources around campus to enhance their educational path."
  },
  {
    "objectID": "courses/ID1-statsworld/index.html#course-website",
    "href": "courses/ID1-statsworld/index.html#course-website",
    "title": "ID1: Statistics in the World",
    "section": "Course website",
    "text": "Course website\nStatistics in the World was last taught in Fall 2021, materials can be found on the course website."
  },
  {
    "objectID": "letters.html",
    "href": "letters.html",
    "title": "letters of recommendation",
    "section": "",
    "text": "Almost surely, no problem. I would be happy to write you a letter. Help me, help you. The more information you can provide for me, the better my letter will be. Also, send the same information about your situation to your other letter writers. It will make their letters better, too. You don’t need to send me long answers to every single question. However, the more you can expand on (particularly with specifics I can use in a letter), the better."
  },
  {
    "objectID": "letters.html#would-you-like-a-letter-of-recommendation",
    "href": "letters.html#would-you-like-a-letter-of-recommendation",
    "title": "letters of recommendation",
    "section": "",
    "text": "Almost surely, no problem. I would be happy to write you a letter. Help me, help you. The more information you can provide for me, the better my letter will be. Also, send the same information about your situation to your other letter writers. It will make their letters better, too. You don’t need to send me long answers to every single question. However, the more you can expand on (particularly with specifics I can use in a letter), the better."
  },
  {
    "objectID": "letters.html#who-sends-the-letter-to-the-organization",
    "href": "letters.html#who-sends-the-letter-to-the-organization",
    "title": "letters of recommendation",
    "section": "who sends the letter to the organization?",
    "text": "who sends the letter to the organization?\nExcept in rare situations, I should be the one submitting the letter directly to the organization.\n\nThe ideal situation is for you to provide me a link (email address, web form, email from the organization, etc.) where I can post / submit the letter.\nIf the organization has asked you to submit the letter, please reach out to the organization asking whether they will make an exception to their policy so as to recieve the letter directly from me. When you submit the rest of the materials below, please include the response you’ve gotten from the organization about their policy on recieving a letter directly from me (instead of from you)."
  },
  {
    "objectID": "letters.html#send-to-me",
    "href": "letters.html#send-to-me",
    "title": "letters of recommendation",
    "section": "send to me:",
    "text": "send to me:\nIf I have agreed to write a recommendation for you, please provide me with as much of the following as possible:\n\na unofficial copy of your transcript,\na copy of your personal statement (if applicable), and\nany necessary forms\n\nFurthermore, at least two weeks before the first letter is due, e-mail me your answers to the following questions (the more details the better):\n\nWhat are your name, pronouns, year, and major?\nFor what are you applying? (scholarship, graduate school, etc.)\nList the programs to which you are applying, together with due dates.\nHow long have I known you (years/months), and what is my relationship(s) to you (instructor, advisor, etc.)? Have you graded or mentored for me? If so, for what class(es) and when?\nFor what class(es) have I had you, what final grade(s) did you earn, and how did you distinguish yourself in my class(es)?\nDid you do a project in my class? What was it? Did it have a “new” component? What did you do for the “new” component? What did you learn from doing the project?\nHow would you describe yourself?\nWhat are some of your academic accomplishments?\nWhat are some of your nonacademic accomplishments?\nWhat makes me particularly qualified to write a letter for you?\nWhat makes you particularly qualified for this position/honor/award?\nWhat are your long term goals and will this position/honor/award help? If so, how?\nAdditional comments (REU’s, summer research, interesting jobs, hobbies, etc.)?\n\nPlease send me e-mail reminder(s) as deadlines approach, and feel free to chat with me about other ways you can make the letter writing process go as smoothly as possible for you and your letter writers. Good luck!\nThanks to Mike Orrison at HMC for the above ideas.\nSee Mine Dogucu’s blog post which includes extensive tips for both students and instructors on getting to excellent recommendation letters."
  },
  {
    "objectID": "courses/SDS261-sql/index.html",
    "href": "courses/SDS261-sql/index.html",
    "title": "SDS 261: Data Science, the SQL",
    "section": "",
    "text": "Art by @allison_horst\n\n\nData Science, the SQL is a continuation of ideas learned in Foundations of Data Science. The course develops abilities for using SQL databases within the data science pipeline. The core of the course will focus on the why and the how associated with writing SELECT queries in SQL. Additional topics will include subqueries, indexes, keys, and regular expressions. Students will learn how to run SQL queries from both the RStudio IDE as well as from a relational database management system client like DBeaver or DuckDB."
  },
  {
    "objectID": "courses/SDS261-sql/index.html#the-course",
    "href": "courses/SDS261-sql/index.html#the-course",
    "title": "SDS 261: Data Science, the SQL",
    "section": "",
    "text": "Art by @allison_horst\n\n\nData Science, the SQL is a continuation of ideas learned in Foundations of Data Science. The course develops abilities for using SQL databases within the data science pipeline. The core of the course will focus on the why and the how associated with writing SELECT queries in SQL. Additional topics will include subqueries, indexes, keys, and regular expressions. Students will learn how to run SQL queries from both the RStudio IDE as well as from a relational database management system client like DBeaver or DuckDB."
  },
  {
    "objectID": "courses/SDS261-sql/index.html#student-learning-outcomes.",
    "href": "courses/SDS261-sql/index.html#student-learning-outcomes.",
    "title": "SDS 261: Data Science, the SQL",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the term, students will:\n\nDatabase Concepts: be able to explain basic database concepts such as tables, records, fields, and relationships.\nIntroduction to SQL: gain a fundamental understanding of Structured Query Language (SQL), including its history, purpose, and key components.\nSQL Querying:\n\nWriting SQL Queries: learn how to write basic SQL queries to retrieve data from a single table.\nFiltering and Sorting Data: be able to use SQL to filter and sort data based on specific criteria.\nJoining Tables: understand how to perform inner and outer joins to combine data from multiple tables.\n\nCreating Tables: be able to create a SQL database with multiple tables that link to one another using DuckDB.\nInserting and Updating Data: be able to use SQL to insert new records into a table and update existing records. Use SQL to delete records from a table.\nBasics of Regular Expressions: understand the fundamental concepts of regular expressions. Identify and use basic metacharacters for pattern matching to write simple regular expressions for text search and matching."
  },
  {
    "objectID": "courses/SDS261-sql/index.html#course-website",
    "href": "courses/SDS261-sql/index.html#course-website",
    "title": "SDS 261: Data Science, the SQL",
    "section": "Course website",
    "text": "Course website\nData Science, the SQL was last taught in January 2024 at Smith College. Materials can be found on the course website."
  },
  {
    "objectID": "blogs/2024-02-01-shimsham/index.html",
    "href": "blogs/2024-02-01-shimsham/index.html",
    "title": "Learning is humbling… and necessary for educators",
    "section": "",
    "text": "Association for Women in Mathematics\n\n\nThe following entry originally appeared in the 2024 March-April Newsletter for the Association for Women in Mathematics.\nLet’s start with what we all know: learning is hard. It takes effort, practice, and focus. As educators, we want our students to work harder and to work smarter. We have a laundry list of ways in which they can be more effective in their learning: put in the hours, go through more questions, come to office hours, talk in community about the problem set, … But when was the last time you learned something new? I mean really new? When was the last time you attempted to learn something unfamiliar? In such a way that you didn’t even know the tools that would help you put in the effort, the practice, and the focus? When was the last time you were a student?\nLately, I’ve taken up a few new challenges that have given me an enhanced perspective on learning. The adventures have humbled me greatly, but even more importantly, they’ve given me a window into the strange and daunting student experience."
  },
  {
    "objectID": "blogs/2024-02-01-shimsham/index.html#tap-dancing",
    "href": "blogs/2024-02-01-shimsham/index.html#tap-dancing",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Tap dancing",
    "text": "Tap dancing\nWhile maybe not fair to consider it as a “new experience” (I’ve danced on and off since I was young), the first novel adventure I’d like to discuss is a tap class (that’s right, tap dancing). Bluntly, the class is out of my league. Everyone else in the class either studies or teaches dance professionally (I’m a statistician). It is the “advanced” class, and it moves quickly both in terms of the steps as well as the music. Most weeks, I leave class close to tears. You might be wondering: why do you go? Because I love tap dancing, and I love the challenge. You might be wondering: why are you close to tears? Let me tell you about the Shim Sham.\nThe Shim Sham is not a difficult tap dance. In fact, it is considered tap dancing’s national anthem. All different levels of tap dancers know and perform the dance regularly at competitions, performances, and generally anywhere tap dancers gather. But I don’t know the Shim Sham. I’ve never learned the Shim Sham. In my class, each week we dance the Shim Sham exactly once as part of the warm-up. I’ve caught on to about ⅔ of it, for some of it I can fumble through, and for some of it I just stand and watch my peers dance. One day in class, my teacher expressed that our class would be dancing (with other classes) the Shim Sham at the upcoming recital. No way am I going to dance the Shim Sham in front of other people. I don’t know the Shim Sham!\nWhen we dance the Shim Sham in class, I get incredibly frustrated. Quite a few thoughts contribute to that sentiment. I think a lot about how I should know the Shim Sham because it is a reasonably easy dance. I think about how I’m in an advanced class, where everyone already (expectedly) knows the Shim Sham. I also wonder whose responsibility it is for me to learn the Shim Sham? If the class is advanced, does that mean I’m supposed to learn the Shim Sham on my own? Or is it the teacher’s responsibility to teach me the Shim Sham because she is the TEACHER? Doesn’t she notice that I always stop halfway through and look around because I don’t know the steps? If it is my responsibility to learn the Shim Sham on my own, how do I learn it? An internet search shows many different variations on the Shim Sham, different enough to make it difficult to learn the version we dance in class. And the videos I can watch online don’t really teach the Shim Sham, they just show people dancing.\nAll of this gets my brain really focused, again, on how I don’t know the Shim Sham. And I’m frustrated with the teacher, I’m disappointed at the lack of resources for learning the Shim Sham, and most of all, I feel terrible about myself because I don’t know the Shim Sham. And guess what? At this point in class, ten minutes later, we’ve moved on to something else with the majority of my brain space being taken up by my feelings of inadequacy. When I refocus, I have no idea what the teacher is explaining. I find myself completely lost, and now there are new tap steps being covered that I don’t know. The learning has continued without me. Sigh. Figure 1 shows two versions of me as a tap dancer: one lost and one confident.\n\n\n\n\n\nFigure 1: Screen shots from a video of a recent tap performance I did with a friend. Left panel, me (on the left) totally lost, having forgotten the steps, looking to my friend to figure it out. Right panel, my friend and I, in sync and dancing confidently.\n\n\n\n\nFortunately for me, the class is only an hour per week and nothing about my livelihood depends on my learning the Shim Sham. I don’t actually have to take the final exam (that is, dance in the recital), and I get to choose how much I want out of the experience. Still, my discomfort leaves me thinking a lot about my students and how they experience learning when they feel similarly inexperienced, unqualified, and/or distracted by the plethora of other things occupying their own brain space, sometimes rendering them unable to fully engage with the class. Unfortunately, for them, usually, learning in my classroom matters."
  },
  {
    "objectID": "blogs/2024-02-01-shimsham/index.html#sql",
    "href": "blogs/2024-02-01-shimsham/index.html#sql",
    "title": "Learning is humbling… and necessary for educators",
    "section": "SQL",
    "text": "SQL\nThe second adventure I’ve embarked on recently is learning SQL (a programming language primarily used to access and wrangle data from large databases). I offered to teach a two week intensive short course on SQL, partly to force myself to engage with it. Before embarking on learning SQL, I had used SQL a few times, and it also has similarities to a programming language with which I am very familiar (wrangling data using the tidyverse in R). So I thought that learning SQL couldn’t be that hard. But learning a new tool to use and learning a new tool to teach are two completely different tasks.\nIn R, a data frame is a compilation of individual observations we can investigate as a complete object (for example, we can easily determine how many rows and columns it has). In SQL, the datasets can be large enough that they aren’t easy to treat as an object to examine. While it may seem like a minor distinction, many of the data wrangling skills I have previously developed fall short when working with SQL tables. Consequently, I’m led to question my background preparation for learning SQL. That is, I thought SQL would build from my R skills, but instead, I find myself needing different skills. As a mere beginner, I am challenged with the daunting task of understanding the larger structure in which SQL and R are different and similar.\nLike the Shim Sham, I am also lost when it comes to using resources to determine what I need to know to successfully prepare my curricular materials. Recently I spent a few hours doing internet searches to figure out a reasonably basic SQL task. I wanted to rename a variable in the SELECT command and then take the difference between the two variables. After multiple dead-end searches, I asked ChatGPT, which happily and confidently provided me with the wrong answer. However, because I had been reading help forums for hours, I immediately knew that ChatGPT was wrong and what the SQL error would be. I explained the problem to ChatGPT which apologized and proceeded to give me exactly the answer I was looking for. It took ChatGPT and me, working together, about 20 seconds to get to the correct answer. It probably would have taken much longer if I hadn’t already spent the hours reading many posts on how to solve SQL problems. Figure 2 and Figure 3 show my “conversation” with ChatGPT.\n\n\n\n\n\nFigure 2: I ask ChatGPT how to do a reasonably straightforward query. I inform ChatGPT that its suggested code is wrong (does not work).\n\n\n\n\n\n\n\n\n\nFigure 3: After learning that the code didn’t work, ChatGPT apologies and provides a correct solution.\n\n\n\n\nLearning SQL has helped me reflect on how hard it is to learn how to learn a new idea. I ask myself whether I am efficiently using tools at my disposal. For example, what is the best way for me to understand the role of variables in a SQL table? Are the internet searches only surface level learning, or am I getting a deeper understanding by beating my head against the wall for hours? How do I learn how to learn smarter? How do I teach how to learn smarter?\nDoes ChatGPT help me understand SQL or does it just help me solve the specific problem I need to know? To be honest, in my very specific example, I think that ChatGPT did help me understand SQL more deeply than I had before. After seeing the correct answer, I finally understood the difference between a variable in the original dataset and a variable in the results set. Our students use ChatGPT in all the aforementioned ways. As educators, we need to embrace its use and recognize that it can sometimes help the learning process. Yes, yes, of course, it can also hinder the learning process. But before casting judgment about ChatGPT, perhaps you might try learning something completely new where it might be useful. Work on the new idea for hours or days or weeks. And then switch to using generative AI. Reflect on how your learning changes and whether your learning is more superficial, deeper, correct, or incorrect. All of the above? Know that your students are learning in the same way you are learning, and your job remains the same, even in a new world of generative AI: to teach."
  },
  {
    "objectID": "blogs/2024-02-01-shimsham/index.html#lessons",
    "href": "blogs/2024-02-01-shimsham/index.html#lessons",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Lessons",
    "text": "Lessons\nI thought I was embarking on two quests: to learn some tap dancing and some SQL. Enough, at least, to dance in the recital and to teach others SQL with some semblance of confidence. Along the way, I learned a lot about being a student (again). It is extremely refreshing and frustrating to be on the other side, with very little knowledge of the content or the system.\nWe as educators should continue to learn. There are new ways to learn, which students are utilizing (i.e., ChatGPT). We should not shy away from them. Instead, I encourage interacting with and understanding such new tools so they can be at our disposal, too.\nAs I gear up to teach again in a few weeks, I’ll try to implement some of the lessons that I’ve learned as a renewed student and longtime educator. In particular, I plan to:\n\npay attention. What are the signs that a student is struggling or not following the material?\ntalk to the students. Ask them how I can best support their learning. Ask them where they get stuck. Ask them what their in-class experience is like. Ask them what they’d like to get out of the class.\nbe flexible. Recognize that I’m teaching a range of students with a range of different backgrounds and experiences who are all trying to accommodate my teaching style. I’ll try to meet them half-way, how can I achieve the same rigor of instruction while allowing them leniency?\nbe approachable. Look for ways to make students feel empowered in their resources, advocacy, and access to help.\ndiscover what success means to my students. For some, success will mean complete mastery of the nuanced details. For others, it will mean passing the class. Or it might be for them to figure out how to apply the ideas to the outside world. Understanding what a student wants to get out of the class will allow me to be a better teacher to their desired learning outcomes.\n\nLearning is humbling, because it is frustrating, hard, and consistently reminds us what we do not know. But learning is also rewarding and provides us the ability to continuously expand our knowledge. Students grapple with such conflicting sentiments every day in our classrooms. Once in a while, it’s useful for us educators to remind ourselves of them, too. Sometimes, the best way to help our students is to once again, be a student.\nMy journey isn’t done. Part of the joy of being an academic is that I can be a life-long learner. At this moment, I don’t have to know everything or to be the perfect teacher. But I do need to think about ways I can continue to improve and grow, and facilitate the same for my students. In that light, I remind myself of the things I’m still learning, including:\n\nhow different students engage differently with the material, the classroom, and college in general;\nhow to use generative AI to enhance student learning; and\nof course, how to dance the Shim Sham."
  },
  {
    "objectID": "blogs/2024-03-01-shimsham/index.html",
    "href": "blogs/2024-03-01-shimsham/index.html",
    "title": "Learning is humbling… and necessary for educators",
    "section": "",
    "text": "Association for Women in Mathematics\n\n\nThe following entry originally appeared in the 2024 March-April Newsletter for the Association for Women in Mathematics.\nLet’s start with what we all know: learning is hard. It takes effort, practice, and focus. As educators, we want our students to work harder and to work smarter. We have a laundry list of ways in which they can be more effective in their learning: put in the hours, go through more questions, come to office hours, talk in community about the problem set, … But when was the last time you learned something new? I mean really new? When was the last time you attempted to learn something unfamiliar? In such a way that you didn’t even know the tools that would help you put in the effort, the practice, and the focus? When was the last time you were a student?\nLately, I’ve taken up a few new challenges that have given me an enhanced perspective on learning. The adventures have humbled me greatly, but even more importantly, they’ve given me a window into the strange and daunting student experience."
  },
  {
    "objectID": "blogs/2024-03-01-shimsham/index.html#tap-dancing",
    "href": "blogs/2024-03-01-shimsham/index.html#tap-dancing",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Tap dancing",
    "text": "Tap dancing\nWhile maybe not fair to consider it as a “new experience” (I’ve danced on and off since I was young), the first novel adventure I’d like to discuss is a tap class (that’s right, tap dancing). Bluntly, the class is out of my league. Everyone else in the class either studies or teaches dance professionally (I’m a statistician). It is the “advanced” class, and it moves quickly both in terms of the steps as well as the music. Most weeks, I leave class close to tears. You might be wondering: why do you go? Because I love tap dancing, and I love the challenge. You might be wondering: why are you close to tears? Let me tell you about the Shim Sham.\nThe Shim Sham is not a difficult tap dance. In fact, it is considered tap dancing’s national anthem. All different levels of tap dancers know and perform the dance regularly at competitions, performances, and generally anywhere tap dancers gather. But I don’t know the Shim Sham. I’ve never learned the Shim Sham. In my class, each week we dance the Shim Sham exactly once as part of the warm-up. I’ve caught on to about ⅔ of it, for some of it I can fumble through, and for some of it I just stand and watch my peers dance. One day in class, my teacher expressed that our class would be dancing (with other classes) the Shim Sham at the upcoming recital. No way am I going to dance the Shim Sham in front of other people. I don’t know the Shim Sham!\nWhen we dance the Shim Sham in class, I get incredibly frustrated. Quite a few thoughts contribute to that sentiment. I think a lot about how I should know the Shim Sham because it is a reasonably easy dance. I think about how I’m in an advanced class, where everyone already (expectedly) knows the Shim Sham. I also wonder whose responsibility it is for me to learn the Shim Sham? If the class is advanced, does that mean I’m supposed to learn the Shim Sham on my own? Or is it the teacher’s responsibility to teach me the Shim Sham because she is the TEACHER? Doesn’t she notice that I always stop halfway through and look around because I don’t know the steps? If it is my responsibility to learn the Shim Sham on my own, how do I learn it? An internet search shows many different variations on the Shim Sham, different enough to make it difficult to learn the version we dance in class. And the videos I can watch online don’t really teach the Shim Sham, they just show people dancing.\nAll of this gets my brain really focused, again, on how I don’t know the Shim Sham. And I’m frustrated with the teacher, I’m disappointed at the lack of resources for learning the Shim Sham, and most of all, I feel terrible about myself because I don’t know the Shim Sham. And guess what? At this point in class, ten minutes later, we’ve moved on to something else with the majority of my brain space being taken up by my feelings of inadequacy. When I refocus, I have no idea what the teacher is explaining. I find myself completely lost, and now there are new tap steps being covered that I don’t know. The learning has continued without me. Sigh. Figure 1 shows two versions of me as a tap dancer: one lost and one confident.\n\n\n\n\n\nFigure 1: Screen shots from a video of a recent tap performance I did with a friend. Left panel, me (on the left) totally lost, having forgotten the steps, looking to my friend to figure it out. Right panel, my friend and I, in sync and dancing confidently.\n\n\n\n\nFortunately for me, the class is only an hour per week and nothing about my livelihood depends on my learning the Shim Sham. I don’t actually have to take the final exam (that is, dance in the recital), and I get to choose how much I want out of the experience. Still, my discomfort leaves me thinking a lot about my students and how they experience learning when they feel similarly inexperienced, unqualified, and/or distracted by the plethora of other things occupying their own brain space, sometimes rendering them unable to fully engage with the class. Unfortunately, for them, usually, learning in my classroom matters."
  },
  {
    "objectID": "blogs/2024-03-01-shimsham/index.html#sql",
    "href": "blogs/2024-03-01-shimsham/index.html#sql",
    "title": "Learning is humbling… and necessary for educators",
    "section": "SQL",
    "text": "SQL\nThe second adventure I’ve embarked on recently is learning SQL (a programming language primarily used to access and wrangle data from large databases). I offered to teach a two week intensive short course on SQL, partly to force myself to engage with it. Before embarking on learning SQL, I had used SQL a few times, and it also has similarities to a programming language with which I am very familiar (wrangling data using the tidyverse in R). So I thought that learning SQL couldn’t be that hard. But learning a new tool to use and learning a new tool to teach are two completely different tasks.\nIn R, a data frame is a compilation of individual observations we can investigate as a complete object (for example, we can easily determine how many rows and columns it has). In SQL, the datasets can be large enough that they aren’t easy to treat as an object to examine. While it may seem like a minor distinction, many of the data wrangling skills I have previously developed fall short when working with SQL tables. Consequently, I’m led to question my background preparation for learning SQL. That is, I thought SQL would build from my R skills, but instead, I find myself needing different skills. As a mere beginner, I am challenged with the daunting task of understanding the larger structure in which SQL and R are different and similar.\nLike the Shim Sham, I am also lost when it comes to using resources to determine what I need to know to successfully prepare my curricular materials. Recently I spent a few hours doing internet searches to figure out a reasonably basic SQL task. I wanted to rename a variable in the SELECT command and then take the difference between the two variables. After multiple dead-end searches, I asked ChatGPT, which happily and confidently provided me with the wrong answer. However, because I had been reading help forums for hours, I immediately knew that ChatGPT was wrong and what the SQL error would be. I explained the problem to ChatGPT which apologized and proceeded to give me exactly the answer I was looking for. It took ChatGPT and me, working together, about 20 seconds to get to the correct answer. It probably would have taken much longer if I hadn’t already spent the hours reading many posts on how to solve SQL problems. Figure 2 and Figure 3 show my “conversation” with ChatGPT.\n\n\n\n\n\nFigure 2: I ask ChatGPT how to do a reasonably straightforward query. I inform ChatGPT that its suggested code is wrong (does not work).\n\n\n\n\n\n\n\n\n\nFigure 3: After learning that the code didn’t work, ChatGPT apologies and provides a correct solution.\n\n\n\n\nLearning SQL has helped me reflect on how hard it is to learn how to learn a new idea. I ask myself whether I am efficiently using tools at my disposal. For example, what is the best way for me to understand the role of variables in a SQL table? Are the internet searches only surface level learning, or am I getting a deeper understanding by beating my head against the wall for hours? How do I learn how to learn smarter? How do I teach how to learn smarter?\nDoes ChatGPT help me understand SQL or does it just help me solve the specific problem I need to know? To be honest, in my very specific example, I think that ChatGPT did help me understand SQL more deeply than I had before. After seeing the correct answer, I finally understood the difference between a variable in the original dataset and a variable in the results set. Our students use ChatGPT in all the aforementioned ways. As educators, we need to embrace its use and recognize that it can sometimes help the learning process. Yes, yes, of course, it can also hinder the learning process. But before casting judgment about ChatGPT, perhaps you might try learning something completely new where it might be useful. Work on the new idea for hours or days or weeks. And then switch to using generative AI. Reflect on how your learning changes and whether your learning is more superficial, deeper, correct, or incorrect. All of the above? Know that your students are learning in the same way you are learning, and your job remains the same, even in a new world of generative AI: to teach."
  },
  {
    "objectID": "blogs/2024-03-01-shimsham/index.html#lessons",
    "href": "blogs/2024-03-01-shimsham/index.html#lessons",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Lessons1",
    "text": "Lessons1\nI thought I was embarking on two quests: to learn some tap dancing and some SQL. Enough, at least, to dance in the recital and to teach others SQL with some semblance of confidence. Along the way, I learned a lot about being a student (again). It is extremely refreshing and frustrating to be on the other side, with very little knowledge of the content or the system.\nWe as educators should continue to learn. There are new ways to learn, which students are utilizing (i.e., ChatGPT). We should not shy away from them. Instead, I encourage interacting with and understanding such new tools so they can be at our disposal, too.\nAs I gear up to teach again in a few weeks, I’ll try to implement some of the lessons that I’ve learned as a renewed student and longtime educator. In particular, I plan to:\n\npay attention. What are the signs that a student is struggling or not following the material?\ntalk to the students. Ask them how I can best support their learning. Ask them where they get stuck. Ask them what their in-class experience is like. Ask them what they’d like to get out of the class.\nbe flexible. Recognize that I’m teaching a range of students with a range of different backgrounds and experiences who are all trying to accommodate my teaching style. I’ll try to meet them half-way, how can I achieve the same rigor of instruction while allowing them leniency?\nbe approachable. Look for ways to make students feel empowered in their resources, advocacy, and access to help.\ndiscover what success means to my students. For some, success will mean complete mastery of the nuanced details. For others, it will mean passing the class. Or it might be for them to figure out how to apply the ideas to the outside world. Understanding what a student wants to get out of the class will allow me to be a better teacher to their desired learning outcomes.\n\nLearning is humbling, because it is frustrating, hard, and consistently reminds us what we do not know. But learning is also rewarding and provides us the ability to continuously expand our knowledge. Students grapple with such conflicting sentiments every day in our classrooms. Once in a while, it’s useful for us educators to remind ourselves of them, too. Sometimes, the best way to help our students is to once again, be a student.\nMy journey isn’t done. Part of the joy of being an academic is that I can be a life-long learner. At this moment, I don’t have to know everything or to be the perfect teacher. But I do need to think about ways I can continue to improve and grow, and facilitate the same for my students. In that light, I remind myself of the things I’m still learning, including:\n\nhow different students engage differently with the material, the classroom, and college in general;\nhow to use generative AI to enhance student learning; and\nof course, how to dance the Shim Sham."
  },
  {
    "objectID": "blogs.html#footnotes",
    "href": "blogs.html#footnotes",
    "title": "blog",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nwith thanks to Lauren Quesada for edits on the first draft and for being a student who makes me a better teacher.↩︎"
  },
  {
    "objectID": "blogs/2024-03-01-shimsham/index.html#footnotes",
    "href": "blogs/2024-03-01-shimsham/index.html#footnotes",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nwith thanks to Lauren Quesada for edits on the first draft and for being a student who makes me a better teacher.↩︎"
  },
  {
    "objectID": "blogs/2024-01-01-jedicause/index.html",
    "href": "blogs/2024-01-01-jedicause/index.html",
    "title": "Resources for JEDI-Informed Teaching of Statistics and Data Science",
    "section": "",
    "text": "Amstat News\n\n\nThe following entry originally appeared in the January 2024 issue of Amstat News, the monthly membership magazine of the American Statistical Association."
  },
  {
    "objectID": "blogs/2024-01-01-jedicause/index.html#tap-dancing",
    "href": "blogs/2024-01-01-jedicause/index.html#tap-dancing",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Tap dancing",
    "text": "Tap dancing\nWhile maybe not fair to consider it as a “new experience” (I’ve danced on and off since I was young), the first novel adventure I’d like to discuss is a tap class (that’s right, tap dancing). Bluntly, the class is out of my league. Everyone else in the class either studies or teaches dance professionally (I’m a statistician). It is the “advanced” class, and it moves quickly both in terms of the steps as well as the music. Most weeks, I leave class close to tears. You might be wondering: why do you go? Because I love tap dancing, and I love the challenge. You might be wondering: why are you close to tears? Let me tell you about the Shim Sham.\nThe Shim Sham is not a difficult tap dance. In fact, it is considered tap dancing’s national anthem. All different levels of tap dancers know and perform the dance regularly at competitions, performances, and generally anywhere tap dancers gather. But I don’t know the Shim Sham. I’ve never learned the Shim Sham. In my class, each week we dance the Shim Sham exactly once as part of the warm-up. I’ve caught on to about ⅔ of it, for some of it I can fumble through, and for some of it I just stand and watch my peers dance. One day in class, my teacher expressed that our class would be dancing (with other classes) the Shim Sham at the upcoming recital. No way am I going to dance the Shim Sham in front of other people. I don’t know the Shim Sham!\nWhen we dance the Shim Sham in class, I get incredibly frustrated. Quite a few thoughts contribute to that sentiment. I think a lot about how I should know the Shim Sham because it is a reasonably easy dance. I think about how I’m in an advanced class, where everyone already (expectedly) knows the Shim Sham. I also wonder whose responsibility it is for me to learn the Shim Sham? If the class is advanced, does that mean I’m supposed to learn the Shim Sham on my own? Or is it the teacher’s responsibility to teach me the Shim Sham because she is the TEACHER? Doesn’t she notice that I always stop halfway through and look around because I don’t know the steps? If it is my responsibility to learn the Shim Sham on my own, how do I learn it? An internet search shows many different variations on the Shim Sham, different enough to make it difficult to learn the version we dance in class. And the videos I can watch online don’t really teach the Shim Sham, they just show people dancing.\nAll of this gets my brain really focused, again, on how I don’t know the Shim Sham. And I’m frustrated with the teacher, I’m disappointed at the lack of resources for learning the Shim Sham, and most of all, I feel terrible about myself because I don’t know the Shim Sham. And guess what? At this point in class, ten minutes later, we’ve moved on to something else with the majority of my brain space being taken up by my feelings of inadequacy. When I refocus, I have no idea what the teacher is explaining. I find myself completely lost, and now there are new tap steps being covered that I don’t know. The learning has continued without me. Sigh. Figure 1 shows two versions of me as a tap dancer: one lost and one confident.\n\n\n\n\n\nFigure 1: Screen shots from a video of a recent tap performance I did with a friend. Left panel, me (on the left) totally lost, having forgotten the steps, looking to my friend to figure it out. Right panel, my friend and I, in sync and dancing confidently.\n\n\n\n\nFortunately for me, the class is only an hour per week and nothing about my livelihood depends on my learning the Shim Sham. I don’t actually have to take the final exam (that is, dance in the recital), and I get to choose how much I want out of the experience. Still, my discomfort leaves me thinking a lot about my students and how they experience learning when they feel similarly inexperienced, unqualified, and/or distracted by the plethora of other things occupying their own brain space, sometimes rendering them unable to fully engage with the class. Unfortunately, for them, usually, learning in my classroom matters."
  },
  {
    "objectID": "blogs/2024-01-01-jedicause/index.html#sql",
    "href": "blogs/2024-01-01-jedicause/index.html#sql",
    "title": "Learning is humbling… and necessary for educators",
    "section": "SQL",
    "text": "SQL\nThe second adventure I’ve embarked on recently is learning SQL (a programming language primarily used to access and wrangle data from large databases). I offered to teach a two week intensive short course on SQL, partly to force myself to engage with it. Before embarking on learning SQL, I had used SQL a few times, and it also has similarities to a programming language with which I am very familiar (wrangling data using the tidyverse in R). So I thought that learning SQL couldn’t be that hard. But learning a new tool to use and learning a new tool to teach are two completely different tasks.\nIn R, a data frame is a compilation of individual observations we can investigate as a complete object (for example, we can easily determine how many rows and columns it has). In SQL, the datasets can be large enough that they aren’t easy to treat as an object to examine. While it may seem like a minor distinction, many of the data wrangling skills I have previously developed fall short when working with SQL tables. Consequently, I’m led to question my background preparation for learning SQL. That is, I thought SQL would build from my R skills, but instead, I find myself needing different skills. As a mere beginner, I am challenged with the daunting task of understanding the larger structure in which SQL and R are different and similar.\nLike the Shim Sham, I am also lost when it comes to using resources to determine what I need to know to successfully prepare my curricular materials. Recently I spent a few hours doing internet searches to figure out a reasonably basic SQL task. I wanted to rename a variable in the SELECT command and then take the difference between the two variables. After multiple dead-end searches, I asked ChatGPT, which happily and confidently provided me with the wrong answer. However, because I had been reading help forums for hours, I immediately knew that ChatGPT was wrong and what the SQL error would be. I explained the problem to ChatGPT which apologized and proceeded to give me exactly the answer I was looking for. It took ChatGPT and me, working together, about 20 seconds to get to the correct answer. It probably would have taken much longer if I hadn’t already spent the hours reading many posts on how to solve SQL problems. Figure 2 and Figure 3 show my “conversation” with ChatGPT.\n\n\n\n\n\nFigure 2: I ask ChatGPT how to do a reasonably straightforward query. I inform ChatGPT that its suggested code is wrong (does not work).\n\n\n\n\n\n\n\n\n\nFigure 3: After learning that the code didn’t work, ChatGPT apologies and provides a correct solution.\n\n\n\n\nLearning SQL has helped me reflect on how hard it is to learn how to learn a new idea. I ask myself whether I am efficiently using tools at my disposal. For example, what is the best way for me to understand the role of variables in a SQL table? Are the internet searches only surface level learning, or am I getting a deeper understanding by beating my head against the wall for hours? How do I learn how to learn smarter? How do I teach how to learn smarter?\nDoes ChatGPT help me understand SQL or does it just help me solve the specific problem I need to know? To be honest, in my very specific example, I think that ChatGPT did help me understand SQL more deeply than I had before. After seeing the correct answer, I finally understood the difference between a variable in the original dataset and a variable in the results set. Our students use ChatGPT in all the aforementioned ways. As educators, we need to embrace its use and recognize that it can sometimes help the learning process. Yes, yes, of course, it can also hinder the learning process. But before casting judgment about ChatGPT, perhaps you might try learning something completely new where it might be useful. Work on the new idea for hours or days or weeks. And then switch to using generative AI. Reflect on how your learning changes and whether your learning is more superficial, deeper, correct, or incorrect. All of the above? Know that your students are learning in the same way you are learning, and your job remains the same, even in a new world of generative AI: to teach."
  },
  {
    "objectID": "blogs/2024-01-01-jedicause/index.html#lessons",
    "href": "blogs/2024-01-01-jedicause/index.html#lessons",
    "title": "Learning is humbling… and necessary for educators",
    "section": "Lessons",
    "text": "Lessons\nI thought I was embarking on two quests: to learn some tap dancing and some SQL. Enough, at least, to dance in the recital and to teach others SQL with some semblance of confidence. Along the way, I learned a lot about being a student (again). It is extremely refreshing and frustrating to be on the other side, with very little knowledge of the content or the system.\nWe as educators should continue to learn. There are new ways to learn, which students are utilizing (i.e., ChatGPT). We should not shy away from them. Instead, I encourage interacting with and understanding such new tools so they can be at our disposal, too.\nAs I gear up to teach again in a few weeks, I’ll try to implement some of the lessons that I’ve learned as a renewed student and longtime educator. In particular, I plan to:\n\npay attention. What are the signs that a student is struggling or not following the material?\ntalk to the students. Ask them how I can best support their learning. Ask them where they get stuck. Ask them what their in-class experience is like. Ask them what they’d like to get out of the class.\nbe flexible. Recognize that I’m teaching a range of students with a range of different backgrounds and experiences who are all trying to accommodate my teaching style. I’ll try to meet them half-way, how can I achieve the same rigor of instruction while allowing them leniency?\nbe approachable. Look for ways to make students feel empowered in their resources, advocacy, and access to help.\ndiscover what success means to my students. For some, success will mean complete mastery of the nuanced details. For others, it will mean passing the class. Or it might be for them to figure out how to apply the ideas to the outside world. Understanding what a student wants to get out of the class will allow me to be a better teacher to their desired learning outcomes.\n\nLearning is humbling, because it is frustrating, hard, and consistently reminds us what we do not know. But learning is also rewarding and provides us the ability to continuously expand our knowledge. Students grapple with such conflicting sentiments every day in our classrooms. Once in a while, it’s useful for us educators to remind ourselves of them, too. Sometimes, the best way to help our students is to once again, be a student.\nMy journey isn’t done. Part of the joy of being an academic is that I can be a life-long learner. At this moment, I don’t have to know everything or to be the perfect teacher. But I do need to think about ways I can continue to improve and grow, and facilitate the same for my students. In that light, I remind myself of the things I’m still learning, including:\n\nhow different students engage differently with the material, the classroom, and college in general;\nhow to use generative AI to enhance student learning; and\nof course, how to dance the Shim Sham."
  },
  {
    "objectID": "blogs/2024-01-01-jedicause/index.html#what-materials-are-on-the-jedi-cause-website",
    "href": "blogs/2024-01-01-jedicause/index.html#what-materials-are-on-the-jedi-cause-website",
    "title": "Resources for JEDI-Informed Teaching of Statistics and Data Science",
    "section": "What materials are on the JEDI-CAUSE website?",
    "text": "What materials are on the JEDI-CAUSE website?\nEach entry on the JEDI-CAUSE website is an item that is relevant to statistics and data science education and has a JEDI theme. The entries are broken down into classroom areas such as examples, data, professional development, activities, pedagogy, and humanizing edutainment. The entries are also broken down by JEDI content areas such as racial discrimination, climate change, criminal justice, gender discrimination, and bias.\nTo get the user started, the top of the page provides a list of the most common searches. Additionally, by random selection, the website spotlights a few entries from the database. Some of the entries are classroom activities, some are datasets, some are professional resources. We welcome all different types of entries and have provided a few examples that might be relevant to your teaching.\n\n\n\n\n\nFigure 1: Entry Example 1 shows the entry that takes us to a 2017 paper in the Journal of Statistics and Data Science Education on ‘Critical Values and Transforming Data: Teaching Statistics with Social Justice.’\n\n\n\n\n\n\n\n\n\nFigure 2: Entry Example 2 provides a classroom activity to discuss ethical implications in data analyses. Interestingly, the participants in the study selected their gender from four options: Male, Female, Non-Binary, and Other.\n\n\n\n\n\n\n\n\n\nFigure 3: Entry Example 3 provides a reading list for learning about DEI issues.\n\n\n\n\nThe entries found on the JEDI-CAUSE website are varied. One can find curated lists of resources, activities geared to a specific topic, data sets, and links to resources found on other websites."
  },
  {
    "objectID": "blogs/2024-01-01-jedicause/index.html#how-can-i-contribute",
    "href": "blogs/2024-01-01-jedicause/index.html#how-can-i-contribute",
    "title": "Resources for JEDI-Informed Teaching of Statistics and Data Science",
    "section": "How can I contribute?",
    "text": "How can I contribute?\nWe hope that the JEDI-CAUSE website will be helpful for you as you rethink your classroom and the experience of your students. If you have materials to contribute, submitting content is very easy! You can submit online where you will be asked a few details about yourself, the title & description of the entry, and a link to materials (optional) or files to upload (optional).\nAlternatively, Is there a resource you’d like to see on the JEDI-CAUSE website but you don’t have materials to share? Feel free to use this google form to send us ideas for good JEDI-related resources for teaching statistics and data science.\nSpecial shout-out to Andrew Ferguson at Penn State who has tirelessly put together the website for us. Thank you, Andrew!"
  },
  {
    "objectID": "projects/IMS/index.html",
    "href": "projects/IMS/index.html",
    "title": "IMS",
    "section": "",
    "text": "https://openintro-ims.netlify.app/"
  },
  {
    "objectID": "courses/DS002R-fds/index.html",
    "href": "courses/DS002R-fds/index.html",
    "title": "DS 002R: Foundations of Data Science in R",
    "section": "",
    "text": "Art by @allison_horst\n\n\nFoundations of Data Science in R is a first course in data science. Data play an increasingly important role in many fields. Being able to understand data and the ethical implications in data driven decisions is paramount to being an informed member of society. As an introduction to data science with R, this course will introduce students to basic data science concepts. Prerequisite: CSCI004 or CSCI005 or CSCI051 or equivalent experience in programming."
  },
  {
    "objectID": "courses/DS002R-fds/index.html#the-course",
    "href": "courses/DS002R-fds/index.html#the-course",
    "title": "DS 002R: Foundations of Data Science in R",
    "section": "",
    "text": "Art by @allison_horst\n\n\nFoundations of Data Science in R is a first course in data science. Data play an increasingly important role in many fields. Being able to understand data and the ethical implications in data driven decisions is paramount to being an informed member of society. As an introduction to data science with R, this course will introduce students to basic data science concepts. Prerequisite: CSCI004 or CSCI005 or CSCI051 or equivalent experience in programming."
  },
  {
    "objectID": "courses/DS002R-fds/index.html#student-learning-outcomes.",
    "href": "courses/DS002R-fds/index.html#student-learning-outcomes.",
    "title": "DS 002R: Foundations of Data Science in R",
    "section": "Student Learning Outcomes.",
    "text": "Student Learning Outcomes.\nBy the end of the term, students will be able to:\n\nscrape, process, and clean data from the web\nwrangle data in a variety of formats\ncontextualize variation in data\nconstruct point and interval estimates using resampling techniques\ndesign accurate, clear and appropriate data graphics\nquery large relational databases (using SQL)\nwork fluently with regular expression\ncommunicate data-driven decisions"
  },
  {
    "objectID": "courses/DS002R-fds/index.html#course-website",
    "href": "courses/DS002R-fds/index.html#course-website",
    "title": "DS 002R: Foundations of Data Science in R",
    "section": "Course website",
    "text": "Course website\nFoundations of Data Science in R was last taught in Spring 2025 at Pomona College. Materials can be found on the course website."
  },
  {
    "objectID": "license_OG.html",
    "href": "license_OG.html",
    "title": "License",
    "section": "",
    "text": "All my web content is released under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. __Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "blogs/2025-01-03-sportsgambling/index.html",
    "href": "blogs/2025-01-03-sportsgambling/index.html",
    "title": "Let’s teach them what they need to know",
    "section": "",
    "text": "Association for Women in Mathematics\n\n\nThe following entry originally appeared in the 2025 March-April Newsletter for the Association for Women in Mathematics.\nI don’t know the full history or choices along the way that built the 20th and 21st century math curriculum in California public schools, or anywhere else, for that matter. But I do know that the space race in the 1950s and 60s and the related Cold War throughout the second half of the 20th century drew the best and the brightest of our students into physics. In terms of mathematics, calculus is fundamental to understanding physics and working in any of the related fields, including astronomy and engineering. So it doesn’t surprise me that our public schools contain mathematics curricula that build directly toward the top students completing a two-course sequence of Calculus 1 and Calculus 2 by the time they graduate from high school.\nBut there is a case to be made that our national interests have changed, and it might be in our best interests to take domestic threats more seriously. In particular, I believe that our we do a disservice to our high school students when they graduate without having engaged with statistics, modeling, or really any data analysis at all.\nBelow I detail some of the ongoing debates happening in the state of California. I also describe one of our newest threats to poverty and income inequality: online sports gambling. And while I know that we need to continue to train some of our students in calculus (we still need physicists, after all!), I would like to see the structure of the curriculum flipped so that most students are focused on data acumen skills and some students are focused on calculus skills."
  },
  {
    "objectID": "blogs/2025-01-03-sportsgambling/index.html#the-california-debate",
    "href": "blogs/2025-01-03-sportsgambling/index.html#the-california-debate",
    "title": "Let’s teach them what they need to know",
    "section": "The California Debate",
    "text": "The California Debate\nIn 2020, the UC Board of Admissions and Relations with Schools (BOARS) for the University of California system (including UC Berkeley and UCLA) decided that the Algebra II requirement could be fulfilled instead by students who had taken Data Science or Statistics. While the 2020 BOARS decision was grounded in being an “equity issue”, they also “strongly encouraged [students] to consider a math course sequence that prepares them for calculus.” Which reads as if they still believe that calculus should be the pinnacle of high school mathematics but that not everyone has access to get there.\nRecently, BOARS has revisited their 2020 decision, spurred on partly by mathematicians who believe data science is dumbing down the mathematics curriculum. In 2023, more that four hundred faculty from California institutions signed on to an open letter, which argues, among other things, that the only reasonable path for any STEM major is the Algebra II to Calculus pathway. In contrast, David Bressoud (DeWitt Wallace Professor Emeritus, Macalester College) explained in 2020 how broken the calculus pathway really is, and he argues for a “truly co-equal path that develops computational and data skills.” In 2024, BOARS reversed their 2020 decision and reverted to requiring Algebra II as a requirement to attend a University of California institution."
  },
  {
    "objectID": "blogs/2025-01-03-sportsgambling/index.html#sports-gambling",
    "href": "blogs/2025-01-03-sportsgambling/index.html#sports-gambling",
    "title": "Let’s teach them what they need to know",
    "section": "Sports Gambling",
    "text": "Sports Gambling\nThe high school / university curricular debate aside, it is worth considering why the debate feels so important. The Stanford History Education Group did an extensive analysis to assess college students’ online reasoning. They found that their ability to reason about information on the internet was “bleak”. The students were unable to reason through why they should or shouldn’t believe a particular online claim. The study found that students accepted as truth the information presented to them, even when there was no supporting evidence or citations.\nIn May 2018, the US Supreme Court struck down the Professional and Amateur Sports Protection Act (PASPA), a law that prevented gambling on both collegiate and professional sports. In the wake of that decision, sports gambling has become ubiquitous, particularly within online platforms. That is, the dismantling of the regulation opened the doors, but online technology opened the flood gates. Websites like FanDuel and DraftKings make it remarkably simply to connect your bank account to the gambling platform, and they bombard you with exciting opportunities to win big.\nOne of the main ways that online gambling platforms makes money is through something called a parlay bet. A parlay is a type of bet in which multiple selections are made on different events (e.g., LA Dodgers win the game and Ohtani hits a home run at some point during the game and someone scores in the first inning). It is difficult to win a parlay bet because each event must come out in your favor in order to win. On the flip side, the platform pays long odds (extra money) for those times when the parlay does win. The long odds make the bet seem like a good idea. Unsurprisingly to mathematicians, however, “the bookmakers are taking advantage of the increased risk involved in a parlay by offering lower odds” than would be reasonable. And certainly, the platform would not allow you to take the other side of the parlay bet. That is, the platform offers a big payout if your parlay wins, but if the betting market were even somewhat close to fair, the offer should be for a truly ginormous payout if your parlay wins.\nUnderstanding the concept of expected value (the long run average on the return of, say, a parlay bet) is paramount to being able to know whether the online gaming platforms are taking advantage of their users (spoiler: they are). Season 4 of Michael Lewis’ podcast, Against the Rules, walks through how being data illiterate leaves you open to being taken advantage of by online gaming platforms. He describes the tactics that the industries use (e.g., not allowing large bets from individuals who win) that take advantage of a population of people who are not trained to understand critical reasoning through data. The podcast serves as a warning for anyone considering online sports gambling, but it is only one small directive in a sea of industries set up to take advantage of people who are not trained to understand data, evidence, and reasoning. All important concepts taught in a data science course."
  },
  {
    "objectID": "blogs/2025-01-03-sportsgambling/index.html#recommendation",
    "href": "blogs/2025-01-03-sportsgambling/index.html#recommendation",
    "title": "Let’s teach them what they need to know",
    "section": "Recommendation",
    "text": "Recommendation\nIn the end, I find the debate between Algebra II and Data Science to be distracting. I think the material in both classes is incredibly important. But when it comes to serving the vast majority of high school students in California public schools, I believe that the material in a data science or statistics courses is more incredibly important. That is, I’d like to see us focus on how we can get every single high school student graduating with some kind of training in data. While I recognize that there is only so much space in a high school curriculum, I advocate for data training above most other things. I worry that we do our students a disservice when we send them out into a world designed and optimized to take advantage of them. It is in our national interest to train students to be wary consumers who understand how the data around them is being used purposefully to enrich large corporations and their CEOs. Let’s take care of each other and teach our students what they need to know."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html",
    "href": "blogs/2025-03-01-sportsgambling/index.html",
    "title": "Let’s teach them what they need to know",
    "section": "",
    "text": "Association for Women in Mathematics\n\n\nThe following entry originally appeared in the 2025 March-April Newsletter for the Association for Women in Mathematics.\nI don’t know the full history or choices along the way that built the 20th and 21st century math curriculum in California public schools, or anywhere else, for that matter. But I do know that the space race in the 1950s and 60s and the related Cold War throughout the second half of the 20th century drew the best and the brightest of our students into physics (Hilborn and Howes 2003, fig. 1; Lövheim 2021). In terms of mathematics, calculus is fundamental to understanding physics and working in any of the related fields, including astronomy and engineering. So, it doesn’t surprise me that our public-school mathematics curricula builds directly toward having the top students complete a two-course sequence of Calculus I and Calculus II by the time they graduate from high school. But there is a case to be made that our national interests have changed, and I believe that we do a disservice to our high school students when they graduate without having engaged with statistics, modeling, or really any data analysis at all.\nBelow I detail some of the ongoing debates happening in the state of California. I also describe one of our newest threats to poverty and income inequality: online sports gambling. And while I wholeheartedly agree that we need to continue to offer some of our students calculus (we still need physicists, after all!), I would like to see the structure of the curriculum flipped to focus most students on data acumen skills and only some students on calculus skills."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html#the-california-debate",
    "href": "blogs/2025-03-01-sportsgambling/index.html#the-california-debate",
    "title": "Let’s teach them what they need to know",
    "section": "The California debate",
    "text": "The California debate\nFor admission to the University of California (UC) system1, three years of college-preparatory mathematics that include the topics covered in elementary and advanced algebra and two- and three-dimensional geometry are required; a fourth year of math is strongly recommended. The course sequence Algebra I, Geometry, and Algebra II is the typical way, in California, to fulfill the requirement.\nIn 2020, the UC Board of Admissions and Relations with Schools (BOARS) for the University of California system (including UC Berkeley and UCLA) officially confirmed long-standing practice that the Algebra II requirement could be validated2 by students who had taken Statistics (BOARS (2020)). The 2020 BOARS decision was grounded in being an “equity issue”, where they state, “By clarifying the definition of college math readiness and expanding the choices of area C math courses students can take to be eligible for UC admissions, students should be encouraged to pursue the mathematics education most relevant to their academic and career goals.”3 However, they seem to undermine the equity issue with the following statement: “Students who are interested in pursuing a college major in science, technology, engineering or math (STEM), or data science and the social sciences, are strongly encouraged to consider a math course sequence that prepares them for calculus, either during high school or in their first year at UC.” Which reads as if they still believe that calculus should be the pinnacle of mathematics regardless of whether or not calculus is the most important mathematics course for a particular student (STEM or not).\nRecently, BOARS has revisited their 2020 decision, spurred on partly by complaints from mathematicians who believe data science, which is classified as a statistics course, is dumbing down the mathematics curriculum. In 2023, more than 400 faculty from California institutions signed an open letter (Charikar et al. 2023), which argues, among other things, that the only reasonable path for any STEM major is the Algebra II to Calculus pathway. Roughly 55% of UC students are not, however, STEM majors (University of California 2024). The result was that in 2024, BOARS and UCOP (UC Office of the President) reversed their 2020 decision and declared that beginning with Fall 2025, only courses, such as Pre-Calculus or AP Calculus, that have elementary and advanced algebra and geometry as prerequisites, can be used to validate Algebra II (BOARS (2024)).\nThe UC system doubled down on the calculus pathway, despite observations like those of mathematician David Bressoud (DeWitt Wallace Professor Emeritus, Macalester College) who explains how broken the calculus pathway really is. Bressoud recognizes that the “singular focus on calculus sucks the oxygen out of” building a strong curriculum for statistics and data science. He argues that a “truly co-equal path that develops computational and data skills” is needed (Bressoud 2020).\n\n\nThe consequences of the recent UC decision are that many school districts are dropping statistics and data science (and some computer science) courses. The hierarchy of courses (some validate and some don’t) discourages school districts from spending money on courses that don’t validate the UC Area C requirement. Unfortunately, in California, the UC requirements drive the high school curricula, and the recent BOARS decisions will not be good for statistics and data science course offerings throughout the public schools."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html#sports-gambling",
    "href": "blogs/2025-03-01-sportsgambling/index.html#sports-gambling",
    "title": "Let’s teach them what they need to know",
    "section": "Sports Gambling",
    "text": "Sports Gambling\nThe high school / university curricular debate aside, it is worth considering why the debate feels so important. The Stanford History Education Group did an extensive analysis to assess college students’ online reasoning skills. The researchers found that the students’ ability to reason about information on the internet was “bleak”. The students were unable to reason through why they should or shouldn’t believe a particular online claim. The study found that students accepted as truth the information presented to them, even when there was no supporting evidence or citations. (Stanford History Education Group 2016) In many scenarios, an inability to discern online truths will not negatively impact one’s life. There are some situations, however, where having a good sense of online scams can lead to keeping oneself out of bankruptcy.\nIn May 2018, the US Supreme Court struck down the Professional and Amateur Sports Protection Act (PASPA), a law that prevented gambling on both collegiate and professional sports. In the wake of that decision, sports gambling has become ubiquitous, particularly within online platforms. That is, the dismantling of the regulation opened the doors, but online technology opened the flood gates. Websites like FanDuel and DraftKings make it remarkably simple to connect your bank account to the gambling platform, and they bombard you with exciting opportunities to win big.\nOne of the ways that online gambling platforms make money is through something called a parlay bet. A parlay is a type of bet in which multiple selections are made on different events (e.g., LA Dodgers win the game and Ohtani hits a home run at some point during the game and the total score of the game is fewer than 7.5 runs). It is difficult to win a parlay bet because each event must come out in your favor in order to win. As such, the platform offers long odds (extra payouts) for those rare occasions when a parlay bet succeeds. The long odds make the bet seem like a good idea to the average amateur gambler. Unsurprisingly to mathematicians, however, “the bookmakers are taking advantage of the increased risk involved in a parlay by offering lower odds” than the probability calculation would suggest (LeansAI, n.d.). And certainly, the platform would not allow you to take the other side of the parlay bet. That is, the platform offers a big payout if your parlay wins, but if the betting market were even somewhat close to fair, the offer should be for a truly ginormous payout if your parlay wins.\nUnderstanding the concept of expected value (the long run average on the return of, say, a parlay bet) is paramount to being able to know whether the online gaming platforms are taking advantage of their users (spoiler: they are). Season 5 of Michael Lewis’ podcast, Against the Rules, walks through how being data illiterate leaves you open to getting taken advantage of by online gaming platforms. He describes the tactics that the industry uses (e.g., not allowing large bets from individuals who win) to take advantage of a population of people who are not trained to understand critical reasoning through data. The podcast serves as a warning for anyone considering online sports gambling, but it is only one voice in a sea of industries set up to take advantage of people who are not trained to understand data, evidence, and reasoning – all important concepts taught in a data science course."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html#recommendation",
    "href": "blogs/2025-03-01-sportsgambling/index.html#recommendation",
    "title": "Let’s teach them what they need to know",
    "section": "Recommendation",
    "text": "Recommendation\nIn the end, I find the curricular part of the debate between Algebra II and Data Science to be distracting. The material in both classes is equally important. But I believe that the material in data science and statistics courses is more equally important, especially when it comes to serving the vast majority of high school students in California public schools. That is, I’d like to see us focus on how we can get every single high school student graduating with some kind of training in data. While I recognize that there is only so much space in a high school curriculum, I advocate for statistics and data training above most other things, including Algebra II. I worry that we do our students a disservice when we send them insufficiently prepared into a world optimized to take advantage of them. It is in our national interest to minimize the information asymmetry between the average patron and the industries who are using data against consumers. Let’s teach our students what they need to know."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html#footnotes",
    "href": "blogs/2025-03-01-sportsgambling/index.html#footnotes",
    "title": "Let’s teach them what they need to know",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 23 California State University campuses follow the same requirements.↩︎\n“validate” is the formal term used to indicate fulfilling a particular requirement.↩︎\nArea C represents the high school mathematics subject requirements for admission into the University of California system.↩︎\navailable at: https://www.pushkin.fm/podcasts/against-the-rules↩︎"
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html",
    "href": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html",
    "title": "Let’s teach them what they need to know",
    "section": "",
    "text": "I don’t know the full history or choices along the way that built the 20th and 21st century math curriculum in California public schools, or anywhere else, for that matter. But I do know that the space race in the 1950s and 60s and the related Cold War throughout the second half of the 20th century drew the best and the brightest of our students into physics. In terms of mathematics, calculus is fundamental to understanding physics and working in any of the related fields, including astronomy and engineering. So, it doesn’t surprise me that our public school mathematics curricula builds directly toward having the top students completing a two-course sequence of Calculus 1 and Calculus 2 by the time they graduate from high school. But there is a case to be made that our national interests have changed, and I believe that we do a disservice to our high school students when they graduate without having engaged with statistics, modeling, or really any data analysis at all.\nBelow I detail some of the ongoing debates happening in the state of California. I also describe one of our newest threats to poverty and income inequality: online sports gambling. And while I know that we need to continue to offer some of our students calculus (we still need physicists, after all!), I would like to see the structure of the curriculum flipped to focus most students on data acumen skills and only some students on calculus skills."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#the-california-debate",
    "href": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#the-california-debate",
    "title": "Let’s teach them what they need to know",
    "section": "The California Debate",
    "text": "The California Debate\nIn 2020, the UC Board of Admissions and Relations with Schools (BOARS) for the University of California system (including UC Berkeley and UCLA) confirmed long-standing practice (BOARS (2020)) that the Algebra II requirement could be validated1 by students who had taken Statistics. The 2020 BOARS decision was grounded in being an “equity issue”, where they state, “By clarifying the definition of college math readiness and expanding the choices of area C math courses students can take to be eligible for UC admissions, students should be encouraged to pursue the mathematics education most relevant to their academic and career goals.” However, in the same document, they seem to undermine the equity issue by “strongly encourag[ing] [students] to consider a math course sequence that prepares them for calculus.” Which reads as if they still believe that calculus should be the pinnacle of high school mathematics but that not everyone has access to get there.\nRecently, BOARS has revisited their 2020 decision, spurred on partly by complaints from mathematicians who believe data science is dumbing down the mathematics curriculum. In 2023, more than 400 faculty from California institutions signed an open letter (Charikar et al. 2023), which argues, among other things, that the only reasonable path for any STEM major is the Algebra II to Calculus pathway. Roughly 55% of UC students are not, however, STEM majors. (University of California 2024) The result was that in 2024, BOARS and UCOP (UC Office of the President) reversed their 2020 decision and declared that beginning with Fall 2025, only calculus-based courses will validate Algebra II (BOARS (2024)).\nDespite the UC system doubling down on the calculus pathway, David Bressoud (DeWitt Wallace Professor Emeritus, Macalester College) explains how broken the calculus pathway really is. He recognizes that the “singular focus on calculus sucks the oxygen out of” building a strong curriculum for statistics and data science. He argues that what is needed is a “truly co-equal path that develops computational and data skills.” (Bressoud 2020)\nIn 1982, Robert Moses founded the “Algebra Project” which helps middle school students learn the foundational mathematical skills needed for college-preparatory mathematics. Working in low-income communities with high proportions of students of color, the Algebra Project has benefited many thousands of students toward mathematics proficiency. The fundamental tenets of the program are aligned with a shifting mindset toward statistics as important college-preparatory mathematics. For example, the Algebra Project’s Five-Step Curricular Process includes: A shared concrete event, A picture / model, People Talk, Feature Talk, and Symbolic Representation (Crombie 2022). Their curricular process provides a pedagogical approach that grabs students’ attention and gets them to care about problem solving. Engaging students in data driven problems is congruous to Moses’ work, providing students with a pathway toward success in mathematics and quantitative literacy.\nIn November of 2024, BOARS and UCOP went one step further to announce that, starting in August 2025, fourth year mathematics courses will now belong to one of two categories. “Category 3” courses build substantially upon the content of Algebra II and can be used to validate Algebra II. “Category 4” courses are all other “advanced” courses.\n\nThe consequences of the UC decision are that many school districts are dropping statistics and data science (and some computer science) courses. The two tiers (Category 3 and Category 4) of fourth-year math courses add a hierarchy which discourages school districts from spending money on lower tier courses. UCOP has countered that they will not publicize which course is in which category, except that pre-calculus and calculus are both in Category 3. But that, of course, just reinforces what risk-adverse school districts may already think: no need to take a chance on statistics."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#sports-gambling",
    "href": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#sports-gambling",
    "title": "Let’s teach them what they need to know",
    "section": "Sports Gambling",
    "text": "Sports Gambling\nThe high school / university curricular debate aside, it is worth considering why the debate feels so important. The Stanford History Education Group did an extensive analysis to assess college students’ online reasoning. They found that their ability to reason about information on the internet was “bleak”. The students were unable to reason through why they should or shouldn’t believe a particular online claim. The study found that students accepted as truth the information presented to them, even when there was no supporting evidence or citations. In many scenarios, an inability to discern online truths will not negatively impact one’s life. But there are some situations, however, where having a good sense of online scams can lead to keeping oneself out of bankruptcy. (Stanford History Education Group 2016)\nIn May 2018, the US Supreme Court struck down the Professional and Amateur Sports Protection Act (PASPA), a law that prevented gambling on both collegiate and professional sports. In the wake of that decision, sports gambling has become ubiquitous, particularly within online platforms. That is, the dismantling of the regulation opened the doors, but online technology opened the flood gates. Websites like FanDuel and DraftKings make it remarkably simply to connect your bank account to the gambling platform, and they bombard you with exciting opportunities to win big.\nOne of the ways that online gambling platforms make money is through something called a parlay bet. A parlay is a type of bet in which multiple selections are made on different events (e.g., LA Dodgers win the game and Ohtani hits a home run at some point during the game and the total score of the game is fewer than 7.5 runs). It is difficult to win a parlay bet because each event must come out in your favor in order to win. As such, the platform offers long odds (extra payouts) for those rare occasions when a parlay bet succeeds. The long odds make the bet seem like a good idea to the average amateur gambler. Unsurprisingly to mathematicians, however, “the bookmakers are taking advantage of the increased risk involved in a parlay by offering lower odds” than the probability calculation would suggest (LeansAI, n.d.). And certainly, the platform would not allow you to take the other side of the parlay bet. That is, the platform offers a big payout if your parlay wins, but if the betting market were even somewhat close to fair, the offer should be for a truly ginormous payout if your parlay wins.\nUnderstanding the concept of expected value (the long run average on the return of, say, a parlay bet) is paramount to being able to know whether the online gaming platforms are taking advantage of their users (spoiler: they are). Season 4 of Michael Lewis’ podcast, Against the Rules, walks through how being data illiterate leaves you open to getting taken advantage of by online gaming platforms. He describes the tactics that the industry uses (e.g., not allowing large bets from individuals who win) to take advantage of a population of people who are not trained to understand critical reasoning through data. The podcast serves as a warning for anyone considering online sports gambling, but it is only one voice in a sea of industries set up to take advantage of people who are not trained to understand data, evidence, and reasoning – all important concepts taught in a data science course."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#recommendation",
    "href": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#recommendation",
    "title": "Let’s teach them what they need to know",
    "section": "Recommendation",
    "text": "Recommendation\nIn the end, I find the curricular part of the debate between Algebra II and Data Science to be distracting. The material in both classes is equally important. But I believe that the material in data science and statistics courses is more equally important, especially when it comes to serving the vast majority of high school students in California public schools. That is, I’d like to see us focus on how we can get every single high school student graduating with some kind of training in data. While I recognize that there is only so much space in a high school curriculum, I advocate for data training above most other things. I worry that we do our students a disservice when we send them insufficiently prepared into a world optimized to take advantage of them. It is in our national interest to minimize the information asymmetry between the average patron and the industries who are using data against consumers. Let’s teach our students what they need to know."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#footnotes",
    "href": "blogs/2025-03-01-sportsgambling/sportsgambling_word.html#footnotes",
    "title": "Let’s teach them what they need to know",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n“validate” is the formal term used to indicate fulfilling a particular requirement.↩︎"
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html#why-the-debate-matters-sports-gambling",
    "href": "blogs/2025-03-01-sportsgambling/index.html#why-the-debate-matters-sports-gambling",
    "title": "Let’s teach them what they need to know",
    "section": "Why the debate matters: sports gambling",
    "text": "Why the debate matters: sports gambling\nThe high school / university curricular debate aside, it is worth considering why the debate feels so important. The Stanford History Education Group did an extensive analysis to assess college students’ online reasoning skills. The researchers found that the students’ ability to reason about information on the internet was “bleak”. The students were unable to reason through why they should or shouldn’t believe a particular online claim. The study found that students accepted as truth the information presented to them, even when there was no supporting evidence or citations (Stanford History Education Group 2016). In many scenarios, an inability to discern online truths will not negatively impact one’s life. There are some situations, however, where having a good sense of online scams can help a person avoid bankruptcy.\nIn May 2018, the US Supreme Court struck down the Professional and Amateur Sports Protection Act (PASPA), a law that prevented gambling on both collegiate and professional sports. In the wake of that decision, sports gambling has become ubiquitous, particularly within online platforms. That is, the dismantling of the regulation opened the doors, but online technology opened the flood gates. Websites like FanDuel and DraftKings make it remarkably simple to connect your bank account to the gambling platform, and they bombard you with exciting opportunities to win big.\nOne of the ways that online gambling platforms make money is through something called a parlay bet. A parlay is a type of bet in which multiple selections are made on different events (e.g., LA Dodgers win the game and Ohtani hits a home run at some point during the game and the total score of the game is fewer than 7.5 runs). It is difficult to win a parlay bet because each event must come out in your favor in order to win. As such, the platform offers long odds (extra payouts) for those rare occasions when a parlay bet succeeds. The long odds make the bet seem like a good idea to the average amateur gambler. Unsurprisingly to mathematicians, however, “the bookmakers are taking advantage of the increased risk involved in a parlay by offering lower odds” than the probability calculation would suggest (LeansAI, n.d.). And certainly, the platform would not allow you to take the other side of the parlay bet. That is, the platform offers a big payout if your parlay wins, but if the betting market were even somewhat close to fair, the offer should be for a truly enormous payout if your parlay wins.\nUnderstanding the concept of expected value (the long run average on the return of, say, a parlay bet) is paramount to being able to know whether the online gaming platforms are taking advantage of their users (spoiler: they are). Season 5 of Michael Lewis’ podcast, Against the Rules3, walks through how being data illiterate leaves a person open to getting taken advantage of by online gaming platforms. He describes the tactics that the industry uses (e.g., not allowing large bets from individuals who win) to take advantage of a population of people who are not trained to understand critical reasoning through data. The podcast serves as a warning for anyone considering online sports gambling, but it is only one voice in a sea of industries set up to take advantage of people who are not trained to understand data, evidence, and reasoning–all important concepts taught in a data science course."
  },
  {
    "objectID": "blogs/2025-03-01-sportsgambling/index.html#why-the-debate-matters-consider-sports-gambling",
    "href": "blogs/2025-03-01-sportsgambling/index.html#why-the-debate-matters-consider-sports-gambling",
    "title": "Let’s teach them what they need to know",
    "section": "Why the debate matters: consider sports gambling",
    "text": "Why the debate matters: consider sports gambling\nThe high school / university curricular debate aside, it is worth considering why the debate feels so important. The Stanford History Education Group did an extensive analysis to assess college students’ online reasoning skills. The researchers found that the students’ ability to reason about information on the internet was “bleak”. The students were unable to reason through why they should or shouldn’t believe a particular online claim. The study found that students accepted as truth the information presented to them, even when there was no supporting evidence or citations (Stanford History Education Group 2016). In many scenarios, an inability to discern online truths will not negatively impact one’s life. There are some situations, however, where having a good sense of online scams can help a person avoid bankruptcy.\nIn May 2018, the US Supreme Court struck down the Professional and Amateur Sports Protection Act (PASPA), a law that prevented gambling on both collegiate and professional sports. In the wake of that decision, sports gambling has become ubiquitous, particularly within online platforms. That is, the dismantling of the regulation opened the doors, but online technology opened the flood gates. Websites like FanDuel and DraftKings make it remarkably simple to connect your bank account to the gambling platform, and they bombard you with exciting opportunities to win big.\nOne of the ways that online gambling platforms make money is through something called a parlay bet. A parlay is a type of bet in which multiple selections are made on different events (e.g., LA Dodgers win the game and Ohtani hits a home run at some point during the game and the total score of the game is fewer than 7.5 runs). It is difficult to win a parlay bet because each event must come out in your favor in order to win. As such, the platform offers long odds (extra payouts) for those rare occasions when a parlay bet succeeds. The long odds make the bet seem like a good idea to the average amateur gambler. Unsurprisingly to mathematicians, however, “the bookmakers are taking advantage of the increased risk involved in a parlay by offering lower odds” than the probability calculation would suggest (Leans.AI, n.d.). And certainly, the platform would not allow you to take the other side of the parlay bet. That is, the platform offers a big payout if your parlay wins, but if the betting market were even somewhat close to fair, the offer should be for a truly enormous payout if your parlay wins.\nUnderstanding the concept of expected value (the long run average on the return of, say, a parlay bet) is paramount to being able to know whether the online gaming platforms are taking advantage of their users (spoiler: they are). Season 5 of Michael Lewis’ podcast, Against the Rules4, walks through how being data illiterate leaves a person open to getting taken advantage of by online gaming platforms. He describes the tactics that the industry uses (e.g., not allowing large bets from individuals who win) to take advantage of a population of people who are not trained to understand critical reasoning through data. The podcast serves as a warning for anyone considering online sports gambling, but it is only one voice in a sea of industries set up to take advantage of people who are not trained to understand data, evidence, and reasoning–all important concepts taught in a data science course."
  },
  {
    "objectID": "projects/jedi-cause/index.html",
    "href": "projects/jedi-cause/index.html",
    "title": "JEDI-CAUSE website",
    "section": "",
    "text": "With Tyler George, Jess Kunke, Lauren Quesada, and Jennifer Ward, we have put together a set of resources to support, encourage, and recognize the need of Justice, Equity, Diversity, and Inclusion (JEDI) in the practice and teaching of statistics and data science. The JEDI-CAUSE website is hosted by Consortium for the Advancement of Undergraduate Statistics Education (CAUSE).\nJennifer and I wrote about the website and how to use it. But to get you started, we recommend:\n\nbrowse categories and explore what’s here, click on the Search button in the top right corner.\nshare some materials, click on the Submit Content button in the top right corner. An entry is not a formal write-up or manuscript, but instead, it is a way to share JEDI teaching.\nlook for a class activity, such as one that could be modified to fit your unique classroom, click on the Search button in the top right corner, and then filter the responses by Classroom Activities.\nexplore a particular topic, and to see how other people have used the topic in class, click on the Search button found in the top right corner, and then filter the responses by Social Justice.\nlocate data sets, click on the Search button in the top right corner, and then filter the responses by Data.\nfind resources for growing personally or professionally, click on the Search button in the top right corner, and then filter the responses by Professional Development.\njump in somewhere right away, click on the Surprise Me! button in the top right corner to be taken to a random resource!"
  }
]